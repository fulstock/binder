{
    "epoch": 46.46,
    "eval_AGE-f1": 0.9142857142857143,
    "eval_AGE-fn": 9.0,
    "eval_AGE-fp": 15.0,
    "eval_AGE-precision": 0.8951048951048951,
    "eval_AGE-recall": 0.9343065693430657,
    "eval_AGE-tp": 128.0,
    "eval_AWARD-f1": 0.6881720430107527,
    "eval_AWARD-fn": 9.0,
    "eval_AWARD-fp": 20.0,
    "eval_AWARD-precision": 0.6153846153846154,
    "eval_AWARD-recall": 0.7804878048780488,
    "eval_AWARD-tp": 32.0,
    "eval_CITY-f1": 0.9227166276346604,
    "eval_CITY-fn": 11.0,
    "eval_CITY-fp": 22.0,
    "eval_CITY-precision": 0.8995433789954338,
    "eval_CITY-recall": 0.9471153846153846,
    "eval_CITY-tp": 197.0,
    "eval_COUNTRY-f1": 0.9439775910364145,
    "eval_COUNTRY-fn": 18.0,
    "eval_COUNTRY-fp": 22.0,
    "eval_COUNTRY-precision": 0.9387186629526463,
    "eval_COUNTRY-recall": 0.9492957746478873,
    "eval_COUNTRY-tp": 337.0,
    "eval_CRIME-f1": 0.496,
    "eval_CRIME-fn": 24.0,
    "eval_CRIME-fp": 39.0,
    "eval_CRIME-precision": 0.44285714285714284,
    "eval_CRIME-recall": 0.5636363636363636,
    "eval_CRIME-tp": 31.0,
    "eval_DATE-f1": 0.8935762224352828,
    "eval_DATE-fn": 58.0,
    "eval_DATE-fp": 53.0,
    "eval_DATE-precision": 0.8978805394990366,
    "eval_DATE-recall": 0.8893129770992366,
    "eval_DATE-tp": 466.0,
    "eval_DISEASE-f1": 0.5897435897435898,
    "eval_DISEASE-fn": 43.0,
    "eval_DISEASE-fp": 53.0,
    "eval_DISEASE-precision": 0.5655737704918032,
    "eval_DISEASE-recall": 0.6160714285714286,
    "eval_DISEASE-tp": 69.0,
    "eval_DISTRICT-f1": 0.5641025641025641,
    "eval_DISTRICT-fn": 6.0,
    "eval_DISTRICT-fp": 11.0,
    "eval_DISTRICT-precision": 0.5,
    "eval_DISTRICT-recall": 0.6470588235294118,
    "eval_DISTRICT-tp": 11.0,
    "eval_EVENT-f1": 0.653250773993808,
    "eval_EVENT-fn": 259.0,
    "eval_EVENT-fp": 189.0,
    "eval_EVENT-precision": 0.690671031096563,
    "eval_EVENT-recall": 0.6196769456681351,
    "eval_EVENT-tp": 422.0,
    "eval_FACILITY-f1": 0.5868263473053892,
    "eval_FACILITY-fn": 35.0,
    "eval_FACILITY-fp": 34.0,
    "eval_FACILITY-precision": 0.5903614457831325,
    "eval_FACILITY-recall": 0.5833333333333334,
    "eval_FACILITY-tp": 49.0,
    "eval_FAMILY-f1": 0.6153846153846154,
    "eval_FAMILY-fn": 2.0,
    "eval_FAMILY-fp": 3.0,
    "eval_FAMILY-precision": 0.5714285714285714,
    "eval_FAMILY-recall": 0.6666666666666666,
    "eval_FAMILY-tp": 4.0,
    "eval_IDEOLOGY-f1": 0.7605633802816901,
    "eval_IDEOLOGY-fn": 9.0,
    "eval_IDEOLOGY-fp": 8.0,
    "eval_IDEOLOGY-precision": 0.7714285714285715,
    "eval_IDEOLOGY-recall": 0.75,
    "eval_IDEOLOGY-tp": 27.0,
    "eval_LANGUAGE-f1": 0.5,
    "eval_LANGUAGE-fn": 4.0,
    "eval_LANGUAGE-fp": 2.0,
    "eval_LANGUAGE-precision": 0.6,
    "eval_LANGUAGE-recall": 0.42857142857142855,
    "eval_LANGUAGE-tp": 3.0,
    "eval_LAW-f1": 0.6845637583892618,
    "eval_LAW-fn": 32.0,
    "eval_LAW-fp": 15.0,
    "eval_LAW-precision": 0.7727272727272727,
    "eval_LAW-recall": 0.6144578313253012,
    "eval_LAW-tp": 51.0,
    "eval_LOCATION-f1": 0.7777777777777778,
    "eval_LOCATION-fn": 15.0,
    "eval_LOCATION-fp": 13.0,
    "eval_LOCATION-precision": 0.7903225806451613,
    "eval_LOCATION-recall": 0.765625,
    "eval_LOCATION-tp": 49.0,
    "eval_MONEY-f1": 0.847457627118644,
    "eval_MONEY-fn": 4.0,
    "eval_MONEY-fp": 5.0,
    "eval_MONEY-precision": 0.8333333333333334,
    "eval_MONEY-recall": 0.8620689655172413,
    "eval_MONEY-tp": 25.0,
    "eval_NATIONALITY-f1": 0.8245614035087719,
    "eval_NATIONALITY-fn": 11.0,
    "eval_NATIONALITY-fp": 9.0,
    "eval_NATIONALITY-precision": 0.8392857142857143,
    "eval_NATIONALITY-recall": 0.8103448275862069,
    "eval_NATIONALITY-tp": 47.0,
    "eval_NUMBER-f1": 0.8977272727272727,
    "eval_NUMBER-fn": 26.0,
    "eval_NUMBER-fp": 10.0,
    "eval_NUMBER-precision": 0.9404761904761905,
    "eval_NUMBER-recall": 0.8586956521739131,
    "eval_NUMBER-tp": 158.0,
    "eval_ORDINAL-f1": 0.85,
    "eval_ORDINAL-fn": 16.0,
    "eval_ORDINAL-fp": 14.0,
    "eval_ORDINAL-precision": 0.8585858585858586,
    "eval_ORDINAL-recall": 0.8415841584158416,
    "eval_ORDINAL-tp": 85.0,
    "eval_ORGANIZATION-f1": 0.8629600626468285,
    "eval_ORGANIZATION-fn": 65.0,
    "eval_ORGANIZATION-fp": 110.0,
    "eval_ORGANIZATION-precision": 0.8335854765506808,
    "eval_ORGANIZATION-recall": 0.8944805194805194,
    "eval_ORGANIZATION-tp": 551.0,
    "eval_PENALTY-f1": 0.6923076923076923,
    "eval_PENALTY-fn": 21.0,
    "eval_PENALTY-fp": 11.0,
    "eval_PENALTY-precision": 0.7659574468085106,
    "eval_PENALTY-recall": 0.631578947368421,
    "eval_PENALTY-tp": 36.0,
    "eval_PERCENT-f1": 0.9,
    "eval_PERCENT-fn": 0.0,
    "eval_PERCENT-fp": 2.0,
    "eval_PERCENT-precision": 0.8181818181818182,
    "eval_PERCENT-recall": 1.0,
    "eval_PERCENT-tp": 9.0,
    "eval_PERSON-f1": 0.9688325409403064,
    "eval_PERSON-fn": 32.0,
    "eval_PERSON-fp": 27.0,
    "eval_PERSON-precision": 0.9713983050847458,
    "eval_PERSON-recall": 0.9662802950474183,
    "eval_PERSON-tp": 917.0,
    "eval_PRODUCT-f1": 0.6582278481012658,
    "eval_PRODUCT-fn": 4.0,
    "eval_PRODUCT-fp": 23.0,
    "eval_PRODUCT-precision": 0.5306122448979592,
    "eval_PRODUCT-recall": 0.8666666666666667,
    "eval_PRODUCT-tp": 26.0,
    "eval_PROFESSION-f1": 0.8619883040935673,
    "eval_PROFESSION-fn": 116.0,
    "eval_PROFESSION-fp": 120.0,
    "eval_PROFESSION-precision": 0.8599766627771295,
    "eval_PROFESSION-recall": 0.8640093786635404,
    "eval_PROFESSION-tp": 737.0,
    "eval_RELIGION-f1": 0.8,
    "eval_RELIGION-fn": 3.0,
    "eval_RELIGION-fp": 0.0,
    "eval_RELIGION-precision": 1.0,
    "eval_RELIGION-recall": 0.6666666666666666,
    "eval_RELIGION-tp": 6.0,
    "eval_STATE_OR_PROVINCE-f1": 0.8787878787878788,
    "eval_STATE_OR_PROVINCE-fn": 12.0,
    "eval_STATE_OR_PROVINCE-fp": 12.0,
    "eval_STATE_OR_PROVINCE-precision": 0.8787878787878788,
    "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
    "eval_STATE_OR_PROVINCE-tp": 87.0,
    "eval_TIME-f1": 0.847457627118644,
    "eval_TIME-fn": 4.0,
    "eval_TIME-fp": 5.0,
    "eval_TIME-precision": 0.8333333333333334,
    "eval_TIME-recall": 0.8620689655172413,
    "eval_TIME-tp": 25.0,
    "eval_WORK_OF_ART-f1": 0.8416289592760181,
    "eval_WORK_OF_ART-fn": 11.0,
    "eval_WORK_OF_ART-fp": 24.0,
    "eval_WORK_OF_ART-precision": 0.7948717948717948,
    "eval_WORK_OF_ART-recall": 0.8942307692307693,
    "eval_WORK_OF_ART-tp": 93.0,
    "eval_f1": 0.769754421448566,
    "eval_macro-f1": 0.769754421448566,
    "eval_macro-precision": 0.7689789150472343,
    "eval_macro-recall": 0.7811406904485524,
    "eval_micro-f1": 0.8439473209453364,
    "eval_micro-precision": 0.8430347810416291,
    "eval_micro-recall": 0.844861838540726,
    "eval_precision": 0.7689789150472343,
    "eval_recall": 0.7811406904485524,
    "eval_samples": 190
}