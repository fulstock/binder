{
  "best_metric": 0.769754421448566,
  "best_model_checkpoint": "./checkpoints/NEREL/kw/full/33/checkpoint-2600",
  "epoch": 46.464646464646464,
  "global_step": 4600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.1,
      "learning_rate": 2.996685606060606e-05,
      "loss": 5.8455,
      "step": 10
    },
    {
      "epoch": 0.2,
      "learning_rate": 2.9919507575757577e-05,
      "loss": 3.7661,
      "step": 20
    },
    {
      "epoch": 0.3,
      "learning_rate": 2.987215909090909e-05,
      "loss": 3.1356,
      "step": 30
    },
    {
      "epoch": 0.4,
      "learning_rate": 2.9824810606060605e-05,
      "loss": 2.4291,
      "step": 40
    },
    {
      "epoch": 0.51,
      "learning_rate": 2.9777462121212123e-05,
      "loss": 2.0105,
      "step": 50
    },
    {
      "epoch": 0.61,
      "learning_rate": 2.9730113636363636e-05,
      "loss": 1.7553,
      "step": 60
    },
    {
      "epoch": 0.71,
      "learning_rate": 2.9682765151515154e-05,
      "loss": 1.5949,
      "step": 70
    },
    {
      "epoch": 0.81,
      "learning_rate": 2.9635416666666668e-05,
      "loss": 1.4535,
      "step": 80
    },
    {
      "epoch": 0.91,
      "learning_rate": 2.9588068181818185e-05,
      "loss": 1.3256,
      "step": 90
    },
    {
      "epoch": 1.01,
      "learning_rate": 2.95407196969697e-05,
      "loss": 1.2628,
      "step": 100
    },
    {
      "epoch": 1.01,
      "eval_AGE-f1": 0.6237623762376238,
      "eval_AGE-fn": 74.0,
      "eval_AGE-fp": 2.0,
      "eval_AGE-precision": 0.9692307692307692,
      "eval_AGE-recall": 0.45985401459854014,
      "eval_AGE-tp": 63.0,
      "eval_AWARD-f1": 0.0,
      "eval_AWARD-fn": 41.0,
      "eval_AWARD-fp": 0.0,
      "eval_AWARD-precision": 0.0,
      "eval_AWARD-recall": 0.0,
      "eval_AWARD-tp": 0.0,
      "eval_CITY-f1": 0.8314087759815243,
      "eval_CITY-fn": 28.0,
      "eval_CITY-fp": 45.0,
      "eval_CITY-precision": 0.8,
      "eval_CITY-recall": 0.8653846153846154,
      "eval_CITY-tp": 180.0,
      "eval_COUNTRY-f1": 0.7985781990521327,
      "eval_COUNTRY-fn": 18.0,
      "eval_COUNTRY-fp": 152.0,
      "eval_COUNTRY-precision": 0.689161554192229,
      "eval_COUNTRY-recall": 0.9492957746478873,
      "eval_COUNTRY-tp": 337.0,
      "eval_CRIME-f1": 0.0,
      "eval_CRIME-fn": 55.0,
      "eval_CRIME-fp": 0.0,
      "eval_CRIME-precision": 0.0,
      "eval_CRIME-recall": 0.0,
      "eval_CRIME-tp": 0.0,
      "eval_DATE-f1": 0.7932647333956969,
      "eval_DATE-fn": 100.0,
      "eval_DATE-fp": 121.0,
      "eval_DATE-precision": 0.7779816513761468,
      "eval_DATE-recall": 0.8091603053435115,
      "eval_DATE-tp": 424.0,
      "eval_DISEASE-f1": 0.0,
      "eval_DISEASE-fn": 112.0,
      "eval_DISEASE-fp": 0.0,
      "eval_DISEASE-precision": 0.0,
      "eval_DISEASE-recall": 0.0,
      "eval_DISEASE-tp": 0.0,
      "eval_DISTRICT-f1": 0.0,
      "eval_DISTRICT-fn": 17.0,
      "eval_DISTRICT-fp": 0.0,
      "eval_DISTRICT-precision": 0.0,
      "eval_DISTRICT-recall": 0.0,
      "eval_DISTRICT-tp": 0.0,
      "eval_EVENT-f1": 0.5239477503628447,
      "eval_EVENT-fn": 320.0,
      "eval_EVENT-fp": 336.0,
      "eval_EVENT-precision": 0.5179340028694405,
      "eval_EVENT-recall": 0.5301027900146843,
      "eval_EVENT-tp": 361.0,
      "eval_FACILITY-f1": 0.0,
      "eval_FACILITY-fn": 84.0,
      "eval_FACILITY-fp": 0.0,
      "eval_FACILITY-precision": 0.0,
      "eval_FACILITY-recall": 0.0,
      "eval_FACILITY-tp": 0.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.05405405405405406,
      "eval_IDEOLOGY-fn": 35.0,
      "eval_IDEOLOGY-fp": 0.0,
      "eval_IDEOLOGY-precision": 1.0,
      "eval_IDEOLOGY-recall": 0.027777777777777776,
      "eval_IDEOLOGY-tp": 1.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.023809523809523808,
      "eval_LAW-fn": 82.0,
      "eval_LAW-fp": 0.0,
      "eval_LAW-precision": 1.0,
      "eval_LAW-recall": 0.012048192771084338,
      "eval_LAW-tp": 1.0,
      "eval_LOCATION-f1": 0.0,
      "eval_LOCATION-fn": 64.0,
      "eval_LOCATION-fp": 0.0,
      "eval_LOCATION-precision": 0.0,
      "eval_LOCATION-recall": 0.0,
      "eval_LOCATION-tp": 0.0,
      "eval_MONEY-f1": 0.0,
      "eval_MONEY-fn": 29.0,
      "eval_MONEY-fp": 0.0,
      "eval_MONEY-precision": 0.0,
      "eval_MONEY-recall": 0.0,
      "eval_MONEY-tp": 0.0,
      "eval_NATIONALITY-f1": 0.125,
      "eval_NATIONALITY-fn": 54.0,
      "eval_NATIONALITY-fp": 2.0,
      "eval_NATIONALITY-precision": 0.6666666666666666,
      "eval_NATIONALITY-recall": 0.06896551724137931,
      "eval_NATIONALITY-tp": 4.0,
      "eval_NUMBER-f1": 0.7321428571428571,
      "eval_NUMBER-fn": 61.0,
      "eval_NUMBER-fp": 29.0,
      "eval_NUMBER-precision": 0.8092105263157895,
      "eval_NUMBER-recall": 0.6684782608695652,
      "eval_NUMBER-tp": 123.0,
      "eval_ORDINAL-f1": 0.3548387096774194,
      "eval_ORDINAL-fn": 79.0,
      "eval_ORDINAL-fp": 1.0,
      "eval_ORDINAL-precision": 0.9565217391304348,
      "eval_ORDINAL-recall": 0.21782178217821782,
      "eval_ORDINAL-tp": 22.0,
      "eval_ORGANIZATION-f1": 0.6999325691166555,
      "eval_ORGANIZATION-fn": 97.0,
      "eval_ORGANIZATION-fp": 348.0,
      "eval_ORGANIZATION-precision": 0.5986159169550173,
      "eval_ORGANIZATION-recall": 0.8425324675324676,
      "eval_ORGANIZATION-tp": 519.0,
      "eval_PENALTY-f1": 0.0,
      "eval_PENALTY-fn": 57.0,
      "eval_PENALTY-fp": 0.0,
      "eval_PENALTY-precision": 0.0,
      "eval_PENALTY-recall": 0.0,
      "eval_PENALTY-tp": 0.0,
      "eval_PERCENT-f1": 0.0,
      "eval_PERCENT-fn": 9.0,
      "eval_PERCENT-fp": 0.0,
      "eval_PERCENT-precision": 0.0,
      "eval_PERCENT-recall": 0.0,
      "eval_PERCENT-tp": 0.0,
      "eval_PERSON-f1": 0.8395522388059702,
      "eval_PERSON-fn": 49.0,
      "eval_PERSON-fp": 295.0,
      "eval_PERSON-precision": 0.7531380753138075,
      "eval_PERSON-recall": 0.9483667017913593,
      "eval_PERSON-tp": 900.0,
      "eval_PRODUCT-f1": 0.0,
      "eval_PRODUCT-fn": 30.0,
      "eval_PRODUCT-fp": 0.0,
      "eval_PRODUCT-precision": 0.0,
      "eval_PRODUCT-recall": 0.0,
      "eval_PRODUCT-tp": 0.0,
      "eval_PROFESSION-f1": 0.5950540958268934,
      "eval_PROFESSION-fn": 83.0,
      "eval_PROFESSION-fp": 965.0,
      "eval_PROFESSION-precision": 0.4438040345821326,
      "eval_PROFESSION-recall": 0.902696365767878,
      "eval_PROFESSION-tp": 770.0,
      "eval_RELIGION-f1": 0.0,
      "eval_RELIGION-fn": 9.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 0.0,
      "eval_RELIGION-recall": 0.0,
      "eval_RELIGION-tp": 0.0,
      "eval_STATE_OR_PROVINCE-f1": 0.0,
      "eval_STATE_OR_PROVINCE-fn": 99.0,
      "eval_STATE_OR_PROVINCE-fp": 0.0,
      "eval_STATE_OR_PROVINCE-precision": 0.0,
      "eval_STATE_OR_PROVINCE-recall": 0.0,
      "eval_STATE_OR_PROVINCE-tp": 0.0,
      "eval_TIME-f1": 0.0,
      "eval_TIME-fn": 29.0,
      "eval_TIME-fp": 0.0,
      "eval_TIME-precision": 0.0,
      "eval_TIME-recall": 0.0,
      "eval_TIME-tp": 0.0,
      "eval_WORK_OF_ART-f1": 0.0,
      "eval_WORK_OF_ART-fn": 104.0,
      "eval_WORK_OF_ART-fp": 0.0,
      "eval_WORK_OF_ART-precision": 0.0,
      "eval_WORK_OF_ART-recall": 0.0,
      "eval_WORK_OF_ART-tp": 0.0,
      "eval_f1": 0.2412188235676964,
      "eval_macro-f1": 0.2412188235676964,
      "eval_macro-precision": 0.3442160322976701,
      "eval_macro-recall": 0.2518098126178955,
      "eval_micro-f1": 0.642225689027561,
      "eval_micro-precision": 0.6173971004832528,
      "eval_micro-recall": 0.6691349106014087,
      "eval_precision": 0.3442160322976701,
      "eval_recall": 0.2518098126178955,
      "step": 100
    },
    {
      "epoch": 1.11,
      "learning_rate": 2.9493371212121213e-05,
      "loss": 1.1622,
      "step": 110
    },
    {
      "epoch": 1.21,
      "learning_rate": 2.944602272727273e-05,
      "loss": 1.0765,
      "step": 120
    },
    {
      "epoch": 1.31,
      "learning_rate": 2.9398674242424244e-05,
      "loss": 1.0286,
      "step": 130
    },
    {
      "epoch": 1.41,
      "learning_rate": 2.935132575757576e-05,
      "loss": 1.0218,
      "step": 140
    },
    {
      "epoch": 1.52,
      "learning_rate": 2.9303977272727275e-05,
      "loss": 0.9045,
      "step": 150
    },
    {
      "epoch": 1.62,
      "learning_rate": 2.925662878787879e-05,
      "loss": 0.9079,
      "step": 160
    },
    {
      "epoch": 1.72,
      "learning_rate": 2.9209280303030306e-05,
      "loss": 0.9246,
      "step": 170
    },
    {
      "epoch": 1.82,
      "learning_rate": 2.9161931818181817e-05,
      "loss": 0.8802,
      "step": 180
    },
    {
      "epoch": 1.92,
      "learning_rate": 2.9114583333333334e-05,
      "loss": 0.791,
      "step": 190
    },
    {
      "epoch": 2.02,
      "learning_rate": 2.9067234848484848e-05,
      "loss": 0.8115,
      "step": 200
    },
    {
      "epoch": 2.02,
      "eval_AGE-f1": 0.9084249084249084,
      "eval_AGE-fn": 13.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9117647058823529,
      "eval_AGE-recall": 0.9051094890510949,
      "eval_AGE-tp": 124.0,
      "eval_AWARD-f1": 0.5428571428571428,
      "eval_AWARD-fn": 22.0,
      "eval_AWARD-fp": 10.0,
      "eval_AWARD-precision": 0.6551724137931034,
      "eval_AWARD-recall": 0.4634146341463415,
      "eval_AWARD-tp": 19.0,
      "eval_CITY-f1": 0.8761467889908257,
      "eval_CITY-fn": 17.0,
      "eval_CITY-fp": 37.0,
      "eval_CITY-precision": 0.8377192982456141,
      "eval_CITY-recall": 0.9182692307692307,
      "eval_CITY-tp": 191.0,
      "eval_COUNTRY-f1": 0.8984700973574409,
      "eval_COUNTRY-fn": 32.0,
      "eval_COUNTRY-fp": 41.0,
      "eval_COUNTRY-precision": 0.8873626373626373,
      "eval_COUNTRY-recall": 0.9098591549295775,
      "eval_COUNTRY-tp": 323.0,
      "eval_CRIME-f1": 0.3157894736842105,
      "eval_CRIME-fn": 43.0,
      "eval_CRIME-fp": 9.0,
      "eval_CRIME-precision": 0.5714285714285714,
      "eval_CRIME-recall": 0.21818181818181817,
      "eval_CRIME-tp": 12.0,
      "eval_DATE-f1": 0.864244741873805,
      "eval_DATE-fn": 72.0,
      "eval_DATE-fp": 70.0,
      "eval_DATE-precision": 0.8659003831417624,
      "eval_DATE-recall": 0.8625954198473282,
      "eval_DATE-tp": 452.0,
      "eval_DISEASE-f1": 0.2047244094488189,
      "eval_DISEASE-fn": 99.0,
      "eval_DISEASE-fp": 2.0,
      "eval_DISEASE-precision": 0.8666666666666667,
      "eval_DISEASE-recall": 0.11607142857142858,
      "eval_DISEASE-tp": 13.0,
      "eval_DISTRICT-f1": 0.0,
      "eval_DISTRICT-fn": 17.0,
      "eval_DISTRICT-fp": 0.0,
      "eval_DISTRICT-precision": 0.0,
      "eval_DISTRICT-recall": 0.0,
      "eval_DISTRICT-tp": 0.0,
      "eval_EVENT-f1": 0.6101694915254238,
      "eval_EVENT-fn": 303.0,
      "eval_EVENT-fp": 180.0,
      "eval_EVENT-precision": 0.6774193548387096,
      "eval_EVENT-recall": 0.5550660792951542,
      "eval_EVENT-tp": 378.0,
      "eval_FACILITY-f1": 0.1875,
      "eval_FACILITY-fn": 75.0,
      "eval_FACILITY-fp": 3.0,
      "eval_FACILITY-precision": 0.75,
      "eval_FACILITY-recall": 0.10714285714285714,
      "eval_FACILITY-tp": 9.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.6101694915254238,
      "eval_IDEOLOGY-fn": 18.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.782608695652174,
      "eval_IDEOLOGY-recall": 0.5,
      "eval_IDEOLOGY-tp": 18.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.4,
      "eval_LAW-fn": 62.0,
      "eval_LAW-fp": 1.0,
      "eval_LAW-precision": 0.9545454545454546,
      "eval_LAW-recall": 0.25301204819277107,
      "eval_LAW-tp": 21.0,
      "eval_LOCATION-f1": 0.27848101265822783,
      "eval_LOCATION-fn": 53.0,
      "eval_LOCATION-fp": 4.0,
      "eval_LOCATION-precision": 0.7333333333333333,
      "eval_LOCATION-recall": 0.171875,
      "eval_LOCATION-tp": 11.0,
      "eval_MONEY-f1": 0.43478260869565216,
      "eval_MONEY-fn": 19.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.5882352941176471,
      "eval_MONEY-recall": 0.3448275862068966,
      "eval_MONEY-tp": 10.0,
      "eval_NATIONALITY-f1": 0.6821705426356589,
      "eval_NATIONALITY-fn": 14.0,
      "eval_NATIONALITY-fp": 27.0,
      "eval_NATIONALITY-precision": 0.6197183098591549,
      "eval_NATIONALITY-recall": 0.7586206896551724,
      "eval_NATIONALITY-tp": 44.0,
      "eval_NUMBER-f1": 0.798941798941799,
      "eval_NUMBER-fn": 33.0,
      "eval_NUMBER-fp": 43.0,
      "eval_NUMBER-precision": 0.7783505154639175,
      "eval_NUMBER-recall": 0.8206521739130435,
      "eval_NUMBER-tp": 151.0,
      "eval_ORDINAL-f1": 0.7699530516431925,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 30.0,
      "eval_ORDINAL-precision": 0.7321428571428571,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.7786476868327402,
      "eval_ORGANIZATION-fn": 69.0,
      "eval_ORGANIZATION-fp": 242.0,
      "eval_ORGANIZATION-precision": 0.6932826362484157,
      "eval_ORGANIZATION-recall": 0.887987012987013,
      "eval_ORGANIZATION-tp": 547.0,
      "eval_PENALTY-f1": 0.2153846153846154,
      "eval_PENALTY-fn": 50.0,
      "eval_PENALTY-fp": 1.0,
      "eval_PENALTY-precision": 0.875,
      "eval_PENALTY-recall": 0.12280701754385964,
      "eval_PENALTY-tp": 7.0,
      "eval_PERCENT-f1": 0.5,
      "eval_PERCENT-fn": 6.0,
      "eval_PERCENT-fp": 0.0,
      "eval_PERCENT-precision": 1.0,
      "eval_PERCENT-recall": 0.3333333333333333,
      "eval_PERCENT-tp": 3.0,
      "eval_PERSON-f1": 0.9458023379383634,
      "eval_PERSON-fn": 59.0,
      "eval_PERSON-fp": 43.0,
      "eval_PERSON-precision": 0.9539121114683816,
      "eval_PERSON-recall": 0.9378292939936775,
      "eval_PERSON-tp": 890.0,
      "eval_PRODUCT-f1": 0.56,
      "eval_PRODUCT-fn": 16.0,
      "eval_PRODUCT-fp": 6.0,
      "eval_PRODUCT-precision": 0.7,
      "eval_PRODUCT-recall": 0.4666666666666667,
      "eval_PRODUCT-tp": 14.0,
      "eval_PROFESSION-f1": 0.7953216374269005,
      "eval_PROFESSION-fn": 105.0,
      "eval_PROFESSION-fp": 280.0,
      "eval_PROFESSION-precision": 0.7276264591439688,
      "eval_PROFESSION-recall": 0.876905041031653,
      "eval_PROFESSION-tp": 748.0,
      "eval_RELIGION-f1": 0.0,
      "eval_RELIGION-fn": 9.0,
      "eval_RELIGION-fp": 1.0,
      "eval_RELIGION-precision": 0.0,
      "eval_RELIGION-recall": 0.0,
      "eval_RELIGION-tp": 0.0,
      "eval_STATE_OR_PROVINCE-f1": 0.7752808988764045,
      "eval_STATE_OR_PROVINCE-fn": 30.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8734177215189873,
      "eval_STATE_OR_PROVINCE-recall": 0.696969696969697,
      "eval_STATE_OR_PROVINCE-tp": 69.0,
      "eval_TIME-f1": 0.17647058823529413,
      "eval_TIME-fn": 26.0,
      "eval_TIME-fp": 2.0,
      "eval_TIME-precision": 0.6,
      "eval_TIME-recall": 0.10344827586206896,
      "eval_TIME-tp": 3.0,
      "eval_WORK_OF_ART-f1": 0.8247422680412371,
      "eval_WORK_OF_ART-fn": 24.0,
      "eval_WORK_OF_ART-fp": 10.0,
      "eval_WORK_OF_ART-precision": 0.8888888888888888,
      "eval_WORK_OF_ART-recall": 0.7692307692307693,
      "eval_WORK_OF_ART-tp": 80.0,
      "eval_f1": 0.5156715721723477,
      "eval_macro-f1": 0.5156715721723477,
      "eval_macro-precision": 0.6732584934049172,
      "eval_macro-recall": 0.47971572088414705,
      "eval_micro-f1": 0.7789881831610044,
      "eval_micro-precision": 0.7967894239848914,
      "eval_micro-recall": 0.761964962976341,
      "eval_precision": 0.6732584934049172,
      "eval_recall": 0.47971572088414705,
      "step": 200
    },
    {
      "epoch": 2.12,
      "learning_rate": 2.9019886363636362e-05,
      "loss": 0.7196,
      "step": 210
    },
    {
      "epoch": 2.22,
      "learning_rate": 2.897253787878788e-05,
      "loss": 0.6906,
      "step": 220
    },
    {
      "epoch": 2.32,
      "learning_rate": 2.8925189393939393e-05,
      "loss": 0.6935,
      "step": 230
    },
    {
      "epoch": 2.42,
      "learning_rate": 2.887784090909091e-05,
      "loss": 0.6555,
      "step": 240
    },
    {
      "epoch": 2.53,
      "learning_rate": 2.8830492424242424e-05,
      "loss": 0.684,
      "step": 250
    },
    {
      "epoch": 2.63,
      "learning_rate": 2.8783143939393938e-05,
      "loss": 0.6557,
      "step": 260
    },
    {
      "epoch": 2.73,
      "learning_rate": 2.8735795454545455e-05,
      "loss": 0.6079,
      "step": 270
    },
    {
      "epoch": 2.83,
      "learning_rate": 2.868844696969697e-05,
      "loss": 0.6125,
      "step": 280
    },
    {
      "epoch": 2.93,
      "learning_rate": 2.8641098484848487e-05,
      "loss": 0.6426,
      "step": 290
    },
    {
      "epoch": 3.03,
      "learning_rate": 2.859375e-05,
      "loss": 0.5578,
      "step": 300
    },
    {
      "epoch": 3.03,
      "eval_AGE-f1": 0.9084249084249084,
      "eval_AGE-fn": 13.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9117647058823529,
      "eval_AGE-recall": 0.9051094890510949,
      "eval_AGE-tp": 124.0,
      "eval_AWARD-f1": 0.5925925925925926,
      "eval_AWARD-fn": 17.0,
      "eval_AWARD-fp": 16.0,
      "eval_AWARD-precision": 0.6,
      "eval_AWARD-recall": 0.5853658536585366,
      "eval_AWARD-tp": 24.0,
      "eval_CITY-f1": 0.9004739336492891,
      "eval_CITY-fn": 18.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8878504672897196,
      "eval_CITY-recall": 0.9134615384615384,
      "eval_CITY-tp": 190.0,
      "eval_COUNTRY-f1": 0.9301675977653632,
      "eval_COUNTRY-fn": 22.0,
      "eval_COUNTRY-fp": 28.0,
      "eval_COUNTRY-precision": 0.9224376731301939,
      "eval_COUNTRY-recall": 0.9380281690140845,
      "eval_COUNTRY-tp": 333.0,
      "eval_CRIME-f1": 0.37142857142857144,
      "eval_CRIME-fn": 42.0,
      "eval_CRIME-fp": 2.0,
      "eval_CRIME-precision": 0.8666666666666667,
      "eval_CRIME-recall": 0.23636363636363636,
      "eval_CRIME-tp": 13.0,
      "eval_DATE-f1": 0.8619091751621872,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 90.0,
      "eval_DATE-precision": 0.8378378378378378,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.35374149659863946,
      "eval_DISEASE-fn": 86.0,
      "eval_DISEASE-fp": 9.0,
      "eval_DISEASE-precision": 0.7428571428571429,
      "eval_DISEASE-recall": 0.23214285714285715,
      "eval_DISEASE-tp": 26.0,
      "eval_DISTRICT-f1": 0.0,
      "eval_DISTRICT-fn": 17.0,
      "eval_DISTRICT-fp": 0.0,
      "eval_DISTRICT-precision": 0.0,
      "eval_DISTRICT-recall": 0.0,
      "eval_DISTRICT-tp": 0.0,
      "eval_EVENT-f1": 0.6336173508907823,
      "eval_EVENT-fn": 272.0,
      "eval_EVENT-fp": 201.0,
      "eval_EVENT-precision": 0.6704918032786885,
      "eval_EVENT-recall": 0.6005873715124816,
      "eval_EVENT-tp": 409.0,
      "eval_FACILITY-f1": 0.5670103092783505,
      "eval_FACILITY-fn": 29.0,
      "eval_FACILITY-fp": 55.0,
      "eval_FACILITY-precision": 0.5,
      "eval_FACILITY-recall": 0.6547619047619048,
      "eval_FACILITY-tp": 55.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.6410256410256411,
      "eval_IDEOLOGY-fn": 11.0,
      "eval_IDEOLOGY-fp": 17.0,
      "eval_IDEOLOGY-precision": 0.5952380952380952,
      "eval_IDEOLOGY-recall": 0.6944444444444444,
      "eval_IDEOLOGY-tp": 25.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.5806451612903226,
      "eval_LAW-fn": 47.0,
      "eval_LAW-fp": 5.0,
      "eval_LAW-precision": 0.8780487804878049,
      "eval_LAW-recall": 0.43373493975903615,
      "eval_LAW-tp": 36.0,
      "eval_LOCATION-f1": 0.5769230769230769,
      "eval_LOCATION-fn": 34.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.75,
      "eval_LOCATION-recall": 0.46875,
      "eval_LOCATION-tp": 30.0,
      "eval_MONEY-f1": 0.7213114754098361,
      "eval_MONEY-fn": 7.0,
      "eval_MONEY-fp": 10.0,
      "eval_MONEY-precision": 0.6875,
      "eval_MONEY-recall": 0.7586206896551724,
      "eval_MONEY-tp": 22.0,
      "eval_NATIONALITY-f1": 0.6722689075630253,
      "eval_NATIONALITY-fn": 18.0,
      "eval_NATIONALITY-fp": 21.0,
      "eval_NATIONALITY-precision": 0.6557377049180327,
      "eval_NATIONALITY-recall": 0.6896551724137931,
      "eval_NATIONALITY-tp": 40.0,
      "eval_NUMBER-f1": 0.8514285714285714,
      "eval_NUMBER-fn": 35.0,
      "eval_NUMBER-fp": 17.0,
      "eval_NUMBER-precision": 0.8975903614457831,
      "eval_NUMBER-recall": 0.8097826086956522,
      "eval_NUMBER-tp": 149.0,
      "eval_ORDINAL-f1": 0.78125,
      "eval_ORDINAL-fn": 26.0,
      "eval_ORDINAL-fp": 16.0,
      "eval_ORDINAL-precision": 0.8241758241758241,
      "eval_ORDINAL-recall": 0.7425742574257426,
      "eval_ORDINAL-tp": 75.0,
      "eval_ORGANIZATION-f1": 0.846703733121525,
      "eval_ORGANIZATION-fn": 83.0,
      "eval_ORGANIZATION-fp": 110.0,
      "eval_ORGANIZATION-precision": 0.8289269051321928,
      "eval_ORGANIZATION-recall": 0.8652597402597403,
      "eval_ORGANIZATION-tp": 533.0,
      "eval_PENALTY-f1": 0.64,
      "eval_PENALTY-fn": 25.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7441860465116279,
      "eval_PENALTY-recall": 0.5614035087719298,
      "eval_PENALTY-tp": 32.0,
      "eval_PERCENT-f1": 0.9411764705882353,
      "eval_PERCENT-fn": 1.0,
      "eval_PERCENT-fp": 0.0,
      "eval_PERCENT-precision": 1.0,
      "eval_PERCENT-recall": 0.8888888888888888,
      "eval_PERCENT-tp": 8.0,
      "eval_PERSON-f1": 0.9529914529914529,
      "eval_PERSON-fn": 57.0,
      "eval_PERSON-fp": 31.0,
      "eval_PERSON-precision": 0.9664138678223185,
      "eval_PERSON-recall": 0.9399367755532139,
      "eval_PERSON-tp": 892.0,
      "eval_PRODUCT-f1": 0.6666666666666666,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 16.0,
      "eval_PRODUCT-precision": 0.5897435897435898,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8394077448747153,
      "eval_PROFESSION-fn": 116.0,
      "eval_PROFESSION-fp": 166.0,
      "eval_PROFESSION-precision": 0.8161683277962348,
      "eval_PROFESSION-recall": 0.8640093786635404,
      "eval_PROFESSION-tp": 737.0,
      "eval_RELIGION-f1": 0.0,
      "eval_RELIGION-fn": 9.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 0.0,
      "eval_RELIGION-recall": 0.0,
      "eval_RELIGION-tp": 0.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8476190476190476,
      "eval_STATE_OR_PROVINCE-fn": 10.0,
      "eval_STATE_OR_PROVINCE-fp": 22.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8018018018018018,
      "eval_STATE_OR_PROVINCE-recall": 0.898989898989899,
      "eval_STATE_OR_PROVINCE-tp": 89.0,
      "eval_TIME-f1": 0.3902439024390244,
      "eval_TIME-fn": 21.0,
      "eval_TIME-fp": 4.0,
      "eval_TIME-precision": 0.6666666666666666,
      "eval_TIME-recall": 0.27586206896551724,
      "eval_TIME-tp": 8.0,
      "eval_WORK_OF_ART-f1": 0.8341708542713567,
      "eval_WORK_OF_ART-fn": 21.0,
      "eval_WORK_OF_ART-fp": 12.0,
      "eval_WORK_OF_ART-precision": 0.8736842105263158,
      "eval_WORK_OF_ART-recall": 0.7980769230769231,
      "eval_WORK_OF_ART-tp": 83.0,
      "eval_f1": 0.6173516773104545,
      "eval_macro-f1": 0.6173516773104545,
      "eval_macro-precision": 0.6729582234209962,
      "eval_macro-recall": 0.600340736632723,
      "eval_micro-f1": 0.8139556292000368,
      "eval_micro-precision": 0.8300788584303417,
      "eval_micro-recall": 0.7984468123532599,
      "eval_precision": 0.6729582234209962,
      "eval_recall": 0.600340736632723,
      "step": 300
    },
    {
      "epoch": 3.13,
      "learning_rate": 2.8546401515151514e-05,
      "loss": 0.5076,
      "step": 310
    },
    {
      "epoch": 3.23,
      "learning_rate": 2.849905303030303e-05,
      "loss": 0.5053,
      "step": 320
    },
    {
      "epoch": 3.33,
      "learning_rate": 2.8451704545454546e-05,
      "loss": 0.5049,
      "step": 330
    },
    {
      "epoch": 3.43,
      "learning_rate": 2.8404356060606063e-05,
      "loss": 0.5059,
      "step": 340
    },
    {
      "epoch": 3.54,
      "learning_rate": 2.8357007575757577e-05,
      "loss": 0.5238,
      "step": 350
    },
    {
      "epoch": 3.64,
      "learning_rate": 2.830965909090909e-05,
      "loss": 0.4946,
      "step": 360
    },
    {
      "epoch": 3.74,
      "learning_rate": 2.8262310606060608e-05,
      "loss": 0.4887,
      "step": 370
    },
    {
      "epoch": 3.84,
      "learning_rate": 2.8214962121212122e-05,
      "loss": 0.491,
      "step": 380
    },
    {
      "epoch": 3.94,
      "learning_rate": 2.816761363636364e-05,
      "loss": 0.5098,
      "step": 390
    },
    {
      "epoch": 4.04,
      "learning_rate": 2.8120265151515153e-05,
      "loss": 0.4692,
      "step": 400
    },
    {
      "epoch": 4.04,
      "eval_AGE-f1": 0.9328358208955224,
      "eval_AGE-fn": 12.0,
      "eval_AGE-fp": 6.0,
      "eval_AGE-precision": 0.9541984732824428,
      "eval_AGE-recall": 0.9124087591240876,
      "eval_AGE-tp": 125.0,
      "eval_AWARD-f1": 0.6153846153846154,
      "eval_AWARD-fn": 21.0,
      "eval_AWARD-fp": 4.0,
      "eval_AWARD-precision": 0.8333333333333334,
      "eval_AWARD-recall": 0.4878048780487805,
      "eval_AWARD-tp": 20.0,
      "eval_CITY-f1": 0.9129411764705883,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8940092165898618,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.935933147632312,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 27.0,
      "eval_COUNTRY-precision": 0.9256198347107438,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.4842105263157895,
      "eval_CRIME-fn": 32.0,
      "eval_CRIME-fp": 17.0,
      "eval_CRIME-precision": 0.575,
      "eval_CRIME-recall": 0.41818181818181815,
      "eval_CRIME-tp": 23.0,
      "eval_DATE-f1": 0.8716026241799437,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 78.0,
      "eval_DATE-precision": 0.856353591160221,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.4222222222222222,
      "eval_DISEASE-fn": 74.0,
      "eval_DISEASE-fp": 30.0,
      "eval_DISEASE-precision": 0.5588235294117647,
      "eval_DISEASE-recall": 0.3392857142857143,
      "eval_DISEASE-tp": 38.0,
      "eval_DISTRICT-f1": 0.1111111111111111,
      "eval_DISTRICT-fn": 16.0,
      "eval_DISTRICT-fp": 0.0,
      "eval_DISTRICT-precision": 1.0,
      "eval_DISTRICT-recall": 0.058823529411764705,
      "eval_DISTRICT-tp": 1.0,
      "eval_EVENT-f1": 0.646481178396072,
      "eval_EVENT-fn": 286.0,
      "eval_EVENT-fp": 146.0,
      "eval_EVENT-precision": 0.7301293900184843,
      "eval_EVENT-recall": 0.580029368575624,
      "eval_EVENT-tp": 395.0,
      "eval_FACILITY-f1": 0.5271317829457365,
      "eval_FACILITY-fn": 50.0,
      "eval_FACILITY-fp": 11.0,
      "eval_FACILITY-precision": 0.7555555555555555,
      "eval_FACILITY-recall": 0.40476190476190477,
      "eval_FACILITY-tp": 34.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.7619047619047619,
      "eval_IDEOLOGY-fn": 12.0,
      "eval_IDEOLOGY-fp": 3.0,
      "eval_IDEOLOGY-precision": 0.8888888888888888,
      "eval_IDEOLOGY-recall": 0.6666666666666666,
      "eval_IDEOLOGY-tp": 24.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.6086956521739131,
      "eval_LAW-fn": 41.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.7636363636363637,
      "eval_LAW-recall": 0.5060240963855421,
      "eval_LAW-tp": 42.0,
      "eval_LOCATION-f1": 0.6363636363636364,
      "eval_LOCATION-fn": 29.0,
      "eval_LOCATION-fp": 11.0,
      "eval_LOCATION-precision": 0.7608695652173914,
      "eval_LOCATION-recall": 0.546875,
      "eval_LOCATION-tp": 35.0,
      "eval_MONEY-f1": 0.7719298245614035,
      "eval_MONEY-fn": 7.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.7857142857142857,
      "eval_MONEY-recall": 0.7586206896551724,
      "eval_MONEY-tp": 22.0,
      "eval_NATIONALITY-f1": 0.7142857142857143,
      "eval_NATIONALITY-fn": 18.0,
      "eval_NATIONALITY-fp": 14.0,
      "eval_NATIONALITY-precision": 0.7407407407407407,
      "eval_NATIONALITY-recall": 0.6896551724137931,
      "eval_NATIONALITY-tp": 40.0,
      "eval_NUMBER-f1": 0.8563049853372434,
      "eval_NUMBER-fn": 38.0,
      "eval_NUMBER-fp": 11.0,
      "eval_NUMBER-precision": 0.9299363057324841,
      "eval_NUMBER-recall": 0.7934782608695652,
      "eval_NUMBER-tp": 146.0,
      "eval_ORDINAL-f1": 0.81,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 18.0,
      "eval_ORDINAL-precision": 0.8181818181818182,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8406466512702079,
      "eval_ORGANIZATION-fn": 70.0,
      "eval_ORGANIZATION-fp": 137.0,
      "eval_ORGANIZATION-precision": 0.7994143484626647,
      "eval_ORGANIZATION-recall": 0.8863636363636364,
      "eval_ORGANIZATION-tp": 546.0,
      "eval_PENALTY-f1": 0.6326530612244898,
      "eval_PENALTY-fn": 26.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.7560975609756098,
      "eval_PENALTY-recall": 0.543859649122807,
      "eval_PENALTY-tp": 31.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9590207557211282,
      "eval_PERSON-fn": 48.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9688172043010753,
      "eval_PERSON-recall": 0.9494204425711275,
      "eval_PERSON-tp": 901.0,
      "eval_PRODUCT-f1": 0.6285714285714286,
      "eval_PRODUCT-fn": 8.0,
      "eval_PRODUCT-fp": 18.0,
      "eval_PRODUCT-precision": 0.55,
      "eval_PRODUCT-recall": 0.7333333333333333,
      "eval_PRODUCT-tp": 22.0,
      "eval_PROFESSION-f1": 0.8313513513513513,
      "eval_PROFESSION-fn": 84.0,
      "eval_PROFESSION-fp": 228.0,
      "eval_PROFESSION-precision": 0.7713139418254764,
      "eval_PROFESSION-recall": 0.9015240328253223,
      "eval_PROFESSION-tp": 769.0,
      "eval_RELIGION-f1": 0.0,
      "eval_RELIGION-fn": 9.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 0.0,
      "eval_RELIGION-recall": 0.0,
      "eval_RELIGION-tp": 0.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8516746411483254,
      "eval_STATE_OR_PROVINCE-fn": 10.0,
      "eval_STATE_OR_PROVINCE-fp": 21.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8090909090909091,
      "eval_STATE_OR_PROVINCE-recall": 0.898989898989899,
      "eval_STATE_OR_PROVINCE-tp": 89.0,
      "eval_TIME-f1": 0.5,
      "eval_TIME-fn": 18.0,
      "eval_TIME-fp": 4.0,
      "eval_TIME-precision": 0.7333333333333333,
      "eval_TIME-recall": 0.3793103448275862,
      "eval_TIME-tp": 11.0,
      "eval_WORK_OF_ART-f1": 0.8383838383838383,
      "eval_WORK_OF_ART-fn": 21.0,
      "eval_WORK_OF_ART-fp": 11.0,
      "eval_WORK_OF_ART-precision": 0.8829787234042553,
      "eval_WORK_OF_ART-recall": 0.7980769230769231,
      "eval_WORK_OF_ART-tp": 83.0,
      "eval_f1": 0.6430692734104823,
      "eval_macro-f1": 0.6430692734104823,
      "eval_macro-precision": 0.7221392039161277,
      "eval_macro-recall": 0.6145534509860443,
      "eval_micro-f1": 0.8226872246696035,
      "eval_micro-precision": 0.8363500653106923,
      "eval_micro-recall": 0.8094636084522304,
      "eval_precision": 0.7221392039161277,
      "eval_recall": 0.6145534509860443,
      "step": 400
    },
    {
      "epoch": 4.14,
      "learning_rate": 2.8072916666666667e-05,
      "loss": 0.4019,
      "step": 410
    },
    {
      "epoch": 4.24,
      "learning_rate": 2.8025568181818184e-05,
      "loss": 0.4066,
      "step": 420
    },
    {
      "epoch": 4.34,
      "learning_rate": 2.7978219696969698e-05,
      "loss": 0.4033,
      "step": 430
    },
    {
      "epoch": 4.44,
      "learning_rate": 2.7930871212121215e-05,
      "loss": 0.4261,
      "step": 440
    },
    {
      "epoch": 4.55,
      "learning_rate": 2.788352272727273e-05,
      "loss": 0.4114,
      "step": 450
    },
    {
      "epoch": 4.65,
      "learning_rate": 2.7836174242424243e-05,
      "loss": 0.4062,
      "step": 460
    },
    {
      "epoch": 4.75,
      "learning_rate": 2.7788825757575757e-05,
      "loss": 0.3929,
      "step": 470
    },
    {
      "epoch": 4.85,
      "learning_rate": 2.774147727272727e-05,
      "loss": 0.3998,
      "step": 480
    },
    {
      "epoch": 4.95,
      "learning_rate": 2.7694128787878788e-05,
      "loss": 0.3452,
      "step": 490
    },
    {
      "epoch": 5.05,
      "learning_rate": 2.7646780303030302e-05,
      "loss": 0.3681,
      "step": 500
    },
    {
      "epoch": 5.05,
      "eval_AGE-f1": 0.9230769230769231,
      "eval_AGE-fn": 11.0,
      "eval_AGE-fp": 10.0,
      "eval_AGE-precision": 0.9264705882352942,
      "eval_AGE-recall": 0.9197080291970803,
      "eval_AGE-tp": 126.0,
      "eval_AWARD-f1": 0.6666666666666666,
      "eval_AWARD-fn": 14.0,
      "eval_AWARD-fp": 13.0,
      "eval_AWARD-precision": 0.675,
      "eval_AWARD-recall": 0.6585365853658537,
      "eval_AWARD-tp": 27.0,
      "eval_CITY-f1": 0.9138755980861244,
      "eval_CITY-fn": 17.0,
      "eval_CITY-fp": 19.0,
      "eval_CITY-precision": 0.9095238095238095,
      "eval_CITY-recall": 0.9182692307692307,
      "eval_CITY-tp": 191.0,
      "eval_COUNTRY-f1": 0.9398280802292264,
      "eval_COUNTRY-fn": 27.0,
      "eval_COUNTRY-fp": 15.0,
      "eval_COUNTRY-precision": 0.956268221574344,
      "eval_COUNTRY-recall": 0.923943661971831,
      "eval_COUNTRY-tp": 328.0,
      "eval_CRIME-f1": 0.5168539325842697,
      "eval_CRIME-fn": 32.0,
      "eval_CRIME-fp": 11.0,
      "eval_CRIME-precision": 0.6764705882352942,
      "eval_CRIME-recall": 0.41818181818181815,
      "eval_CRIME-tp": 23.0,
      "eval_DATE-f1": 0.892960462873674,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 50.0,
      "eval_DATE-precision": 0.9025341130604289,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.42857142857142855,
      "eval_DISEASE-fn": 73.0,
      "eval_DISEASE-fp": 31.0,
      "eval_DISEASE-precision": 0.5571428571428572,
      "eval_DISEASE-recall": 0.3482142857142857,
      "eval_DISEASE-tp": 39.0,
      "eval_DISTRICT-f1": 0.45454545454545453,
      "eval_DISTRICT-fn": 12.0,
      "eval_DISTRICT-fp": 0.0,
      "eval_DISTRICT-precision": 1.0,
      "eval_DISTRICT-recall": 0.29411764705882354,
      "eval_DISTRICT-tp": 5.0,
      "eval_EVENT-f1": 0.6225402504472272,
      "eval_EVENT-fn": 333.0,
      "eval_EVENT-fp": 89.0,
      "eval_EVENT-precision": 0.7963386727688787,
      "eval_EVENT-recall": 0.5110132158590308,
      "eval_EVENT-tp": 348.0,
      "eval_FACILITY-f1": 0.5401459854014599,
      "eval_FACILITY-fn": 47.0,
      "eval_FACILITY-fp": 16.0,
      "eval_FACILITY-precision": 0.6981132075471698,
      "eval_FACILITY-recall": 0.44047619047619047,
      "eval_FACILITY-tp": 37.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.7352941176470589,
      "eval_IDEOLOGY-fn": 11.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.78125,
      "eval_IDEOLOGY-recall": 0.6944444444444444,
      "eval_IDEOLOGY-tp": 25.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.5454545454545454,
      "eval_LAW-fn": 50.0,
      "eval_LAW-fp": 5.0,
      "eval_LAW-precision": 0.868421052631579,
      "eval_LAW-recall": 0.39759036144578314,
      "eval_LAW-tp": 33.0,
      "eval_LOCATION-f1": 0.6407766990291263,
      "eval_LOCATION-fn": 31.0,
      "eval_LOCATION-fp": 6.0,
      "eval_LOCATION-precision": 0.8461538461538461,
      "eval_LOCATION-recall": 0.515625,
      "eval_LOCATION-tp": 33.0,
      "eval_MONEY-f1": 0.7857142857142857,
      "eval_MONEY-fn": 7.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8148148148148148,
      "eval_MONEY-recall": 0.7586206896551724,
      "eval_MONEY-tp": 22.0,
      "eval_NATIONALITY-f1": 0.7244094488188977,
      "eval_NATIONALITY-fn": 12.0,
      "eval_NATIONALITY-fp": 23.0,
      "eval_NATIONALITY-precision": 0.6666666666666666,
      "eval_NATIONALITY-recall": 0.7931034482758621,
      "eval_NATIONALITY-tp": 46.0,
      "eval_NUMBER-f1": 0.8650137741046832,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 22.0,
      "eval_NUMBER-precision": 0.8770949720670391,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8148148148148148,
      "eval_ORDINAL-fn": 24.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.875,
      "eval_ORDINAL-recall": 0.7623762376237624,
      "eval_ORDINAL-tp": 77.0,
      "eval_ORGANIZATION-f1": 0.8436532507739938,
      "eval_ORGANIZATION-fn": 71.0,
      "eval_ORGANIZATION-fp": 131.0,
      "eval_ORGANIZATION-precision": 0.8062130177514792,
      "eval_ORGANIZATION-recall": 0.8847402597402597,
      "eval_ORGANIZATION-tp": 545.0,
      "eval_PENALTY-f1": 0.6067415730337079,
      "eval_PENALTY-fn": 30.0,
      "eval_PENALTY-fp": 5.0,
      "eval_PENALTY-precision": 0.84375,
      "eval_PENALTY-recall": 0.47368421052631576,
      "eval_PENALTY-tp": 27.0,
      "eval_PERCENT-f1": 1.0,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 0.0,
      "eval_PERCENT-precision": 1.0,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9597883597883597,
      "eval_PERSON-fn": 42.0,
      "eval_PERSON-fp": 34.0,
      "eval_PERSON-precision": 0.9638682252922423,
      "eval_PERSON-recall": 0.9557428872497366,
      "eval_PERSON-tp": 907.0,
      "eval_PRODUCT-f1": 0.53125,
      "eval_PRODUCT-fn": 13.0,
      "eval_PRODUCT-fp": 17.0,
      "eval_PRODUCT-precision": 0.5,
      "eval_PRODUCT-recall": 0.5666666666666667,
      "eval_PRODUCT-tp": 17.0,
      "eval_PROFESSION-f1": 0.8532423208191127,
      "eval_PROFESSION-fn": 103.0,
      "eval_PROFESSION-fp": 155.0,
      "eval_PROFESSION-precision": 0.8287292817679558,
      "eval_PROFESSION-recall": 0.8792497069167644,
      "eval_PROFESSION-tp": 750.0,
      "eval_RELIGION-f1": 0.36363636363636365,
      "eval_RELIGION-fn": 7.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.2222222222222222,
      "eval_RELIGION-tp": 2.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8426395939086294,
      "eval_STATE_OR_PROVINCE-fn": 16.0,
      "eval_STATE_OR_PROVINCE-fp": 15.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8469387755102041,
      "eval_STATE_OR_PROVINCE-recall": 0.8383838383838383,
      "eval_STATE_OR_PROVINCE-tp": 83.0,
      "eval_TIME-f1": 0.5333333333333333,
      "eval_TIME-fn": 17.0,
      "eval_TIME-fp": 4.0,
      "eval_TIME-precision": 0.75,
      "eval_TIME-recall": 0.41379310344827586,
      "eval_TIME-tp": 12.0,
      "eval_WORK_OF_ART-f1": 0.8341232227488151,
      "eval_WORK_OF_ART-fn": 16.0,
      "eval_WORK_OF_ART-fp": 19.0,
      "eval_WORK_OF_ART-precision": 0.822429906542056,
      "eval_WORK_OF_ART-recall": 0.8461538461538461,
      "eval_WORK_OF_ART-tp": 88.0,
      "eval_f1": 0.6682396719347647,
      "eval_macro-f1": 0.6682396719347647,
      "eval_macro-precision": 0.7651445730098607,
      "eval_macro-recall": 0.6266105601093742,
      "eval_micro-f1": 0.8284910965323337,
      "eval_micro-precision": 0.8610948762906683,
      "eval_micro-recall": 0.7982662091385226,
      "eval_precision": 0.7651445730098607,
      "eval_recall": 0.6266105601093742,
      "step": 500
    },
    {
      "epoch": 5.15,
      "learning_rate": 2.7599431818181816e-05,
      "loss": 0.3237,
      "step": 510
    },
    {
      "epoch": 5.25,
      "learning_rate": 2.7552083333333333e-05,
      "loss": 0.3341,
      "step": 520
    },
    {
      "epoch": 5.35,
      "learning_rate": 2.7504734848484847e-05,
      "loss": 0.3292,
      "step": 530
    },
    {
      "epoch": 5.45,
      "learning_rate": 2.7457386363636365e-05,
      "loss": 0.3272,
      "step": 540
    },
    {
      "epoch": 5.56,
      "learning_rate": 2.741003787878788e-05,
      "loss": 0.3203,
      "step": 550
    },
    {
      "epoch": 5.66,
      "learning_rate": 2.7362689393939396e-05,
      "loss": 0.32,
      "step": 560
    },
    {
      "epoch": 5.76,
      "learning_rate": 2.731534090909091e-05,
      "loss": 0.3312,
      "step": 570
    },
    {
      "epoch": 5.86,
      "learning_rate": 2.7267992424242423e-05,
      "loss": 0.3191,
      "step": 580
    },
    {
      "epoch": 5.96,
      "learning_rate": 2.722064393939394e-05,
      "loss": 0.3155,
      "step": 590
    },
    {
      "epoch": 6.06,
      "learning_rate": 2.7173295454545455e-05,
      "loss": 0.2976,
      "step": 600
    },
    {
      "epoch": 6.06,
      "eval_AGE-f1": 0.9214285714285714,
      "eval_AGE-fn": 8.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.9020979020979021,
      "eval_AGE-recall": 0.9416058394160584,
      "eval_AGE-tp": 129.0,
      "eval_AWARD-f1": 0.6666666666666666,
      "eval_AWARD-fn": 13.0,
      "eval_AWARD-fp": 15.0,
      "eval_AWARD-precision": 0.6511627906976745,
      "eval_AWARD-recall": 0.6829268292682927,
      "eval_AWARD-tp": 28.0,
      "eval_CITY-f1": 0.9036697247706422,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 31.0,
      "eval_CITY-precision": 0.8640350877192983,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.9372384937238494,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 26.0,
      "eval_COUNTRY-precision": 0.9281767955801105,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.4714285714285714,
      "eval_CRIME-fn": 22.0,
      "eval_CRIME-fp": 52.0,
      "eval_CRIME-precision": 0.38823529411764707,
      "eval_CRIME-recall": 0.6,
      "eval_CRIME-tp": 33.0,
      "eval_DATE-f1": 0.8767377201112141,
      "eval_DATE-fn": 51.0,
      "eval_DATE-fp": 82.0,
      "eval_DATE-precision": 0.8522522522522522,
      "eval_DATE-recall": 0.9026717557251909,
      "eval_DATE-tp": 473.0,
      "eval_DISEASE-f1": 0.4785714285714286,
      "eval_DISEASE-fn": 45.0,
      "eval_DISEASE-fp": 101.0,
      "eval_DISEASE-precision": 0.39880952380952384,
      "eval_DISEASE-recall": 0.5982142857142857,
      "eval_DISEASE-tp": 67.0,
      "eval_DISTRICT-f1": 0.4864864864864865,
      "eval_DISTRICT-fn": 8.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.45,
      "eval_DISTRICT-recall": 0.5294117647058824,
      "eval_DISTRICT-tp": 9.0,
      "eval_EVENT-f1": 0.6604215456674473,
      "eval_EVENT-fn": 258.0,
      "eval_EVENT-fp": 177.0,
      "eval_EVENT-precision": 0.705,
      "eval_EVENT-recall": 0.6211453744493393,
      "eval_EVENT-tp": 423.0,
      "eval_FACILITY-f1": 0.5401459854014599,
      "eval_FACILITY-fn": 47.0,
      "eval_FACILITY-fp": 16.0,
      "eval_FACILITY-precision": 0.6981132075471698,
      "eval_FACILITY-recall": 0.44047619047619047,
      "eval_FACILITY-tp": 37.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.7123287671232876,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 11.0,
      "eval_IDEOLOGY-precision": 0.7027027027027027,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.6022727272727273,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 40.0,
      "eval_LAW-precision": 0.5698924731182796,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.6902654867256637,
      "eval_LOCATION-fn": 25.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.7959183673469388,
      "eval_LOCATION-recall": 0.609375,
      "eval_LOCATION-tp": 39.0,
      "eval_MONEY-f1": 0.8064516129032258,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 8.0,
      "eval_MONEY-precision": 0.7575757575757576,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7663551401869159,
      "eval_NATIONALITY-fn": 17.0,
      "eval_NATIONALITY-fp": 8.0,
      "eval_NATIONALITY-precision": 0.8367346938775511,
      "eval_NATIONALITY-recall": 0.7068965517241379,
      "eval_NATIONALITY-tp": 41.0,
      "eval_NUMBER-f1": 0.8602739726027397,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 24.0,
      "eval_NUMBER-precision": 0.8674033149171271,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8324873096446701,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8541666666666666,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8332108743570904,
      "eval_ORGANIZATION-fn": 49.0,
      "eval_ORGANIZATION-fp": 178.0,
      "eval_ORGANIZATION-precision": 0.7610738255033557,
      "eval_ORGANIZATION-recall": 0.9204545454545454,
      "eval_ORGANIZATION-tp": 567.0,
      "eval_PENALTY-f1": 0.6804123711340206,
      "eval_PENALTY-fn": 24.0,
      "eval_PENALTY-fp": 7.0,
      "eval_PENALTY-precision": 0.825,
      "eval_PENALTY-recall": 0.5789473684210527,
      "eval_PENALTY-tp": 33.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9590336134453782,
      "eval_PERSON-fn": 36.0,
      "eval_PERSON-fp": 42.0,
      "eval_PERSON-precision": 0.956020942408377,
      "eval_PERSON-recall": 0.9620653319283456,
      "eval_PERSON-tp": 913.0,
      "eval_PRODUCT-f1": 0.6075949367088608,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 25.0,
      "eval_PRODUCT-precision": 0.4897959183673469,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8602520045819015,
      "eval_PROFESSION-fn": 102.0,
      "eval_PROFESSION-fp": 142.0,
      "eval_PROFESSION-precision": 0.8409854423292273,
      "eval_PROFESSION-recall": 0.88042203985932,
      "eval_PROFESSION-tp": 751.0,
      "eval_RELIGION-f1": 0.7142857142857143,
      "eval_RELIGION-fn": 4.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.5555555555555556,
      "eval_RELIGION-tp": 5.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8543689320388349,
      "eval_STATE_OR_PROVINCE-fn": 11.0,
      "eval_STATE_OR_PROVINCE-fp": 19.0,
      "eval_STATE_OR_PROVINCE-precision": 0.822429906542056,
      "eval_STATE_OR_PROVINCE-recall": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-tp": 88.0,
      "eval_TIME-f1": 0.7719298245614035,
      "eval_TIME-fn": 7.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.7857142857142857,
      "eval_TIME-recall": 0.7586206896551724,
      "eval_TIME-tp": 22.0,
      "eval_WORK_OF_ART-f1": 0.8122270742358079,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 32.0,
      "eval_WORK_OF_ART-precision": 0.744,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.6984108267971452,
      "eval_macro-f1": 0.6984108267971452,
      "eval_macro-precision": 0.7016309362376292,
      "eval_macro-recall": 0.7121893276075454,
      "eval_micro-f1": 0.8255824253698291,
      "eval_micro-precision": 0.8101529902642559,
      "eval_micro-recall": 0.841610980675456,
      "eval_precision": 0.7016309362376292,
      "eval_recall": 0.7121893276075454,
      "step": 600
    },
    {
      "epoch": 6.16,
      "learning_rate": 2.7125946969696972e-05,
      "loss": 0.265,
      "step": 610
    },
    {
      "epoch": 6.26,
      "learning_rate": 2.7078598484848486e-05,
      "loss": 0.2734,
      "step": 620
    },
    {
      "epoch": 6.36,
      "learning_rate": 2.703125e-05,
      "loss": 0.2592,
      "step": 630
    },
    {
      "epoch": 6.46,
      "learning_rate": 2.6983901515151517e-05,
      "loss": 0.2598,
      "step": 640
    },
    {
      "epoch": 6.57,
      "learning_rate": 2.693655303030303e-05,
      "loss": 0.2585,
      "step": 650
    },
    {
      "epoch": 6.67,
      "learning_rate": 2.6889204545454548e-05,
      "loss": 0.2583,
      "step": 660
    },
    {
      "epoch": 6.77,
      "learning_rate": 2.6841856060606062e-05,
      "loss": 0.2651,
      "step": 670
    },
    {
      "epoch": 6.87,
      "learning_rate": 2.6794507575757576e-05,
      "loss": 0.2785,
      "step": 680
    },
    {
      "epoch": 6.97,
      "learning_rate": 2.6747159090909093e-05,
      "loss": 0.2636,
      "step": 690
    },
    {
      "epoch": 7.07,
      "learning_rate": 2.6699810606060607e-05,
      "loss": 0.2291,
      "step": 700
    },
    {
      "epoch": 7.07,
      "eval_AGE-f1": 0.9157509157509157,
      "eval_AGE-fn": 12.0,
      "eval_AGE-fp": 11.0,
      "eval_AGE-precision": 0.9191176470588235,
      "eval_AGE-recall": 0.9124087591240876,
      "eval_AGE-tp": 125.0,
      "eval_AWARD-f1": 0.6842105263157895,
      "eval_AWARD-fn": 15.0,
      "eval_AWARD-fp": 9.0,
      "eval_AWARD-precision": 0.7428571428571429,
      "eval_AWARD-recall": 0.6341463414634146,
      "eval_AWARD-tp": 26.0,
      "eval_CITY-f1": 0.897025171624714,
      "eval_CITY-fn": 12.0,
      "eval_CITY-fp": 33.0,
      "eval_CITY-precision": 0.8558951965065502,
      "eval_CITY-recall": 0.9423076923076923,
      "eval_CITY-tp": 196.0,
      "eval_COUNTRY-f1": 0.9428172942817294,
      "eval_COUNTRY-fn": 17.0,
      "eval_COUNTRY-fp": 24.0,
      "eval_COUNTRY-precision": 0.9337016574585635,
      "eval_COUNTRY-recall": 0.952112676056338,
      "eval_COUNTRY-tp": 338.0,
      "eval_CRIME-f1": 0.4752475247524752,
      "eval_CRIME-fn": 31.0,
      "eval_CRIME-fp": 22.0,
      "eval_CRIME-precision": 0.5217391304347826,
      "eval_CRIME-recall": 0.43636363636363634,
      "eval_CRIME-tp": 24.0,
      "eval_DATE-f1": 0.8866995073891626,
      "eval_DATE-fn": 74.0,
      "eval_DATE-fp": 41.0,
      "eval_DATE-precision": 0.9164969450101833,
      "eval_DATE-recall": 0.8587786259541985,
      "eval_DATE-tp": 450.0,
      "eval_DISEASE-f1": 0.4044943820224719,
      "eval_DISEASE-fn": 76.0,
      "eval_DISEASE-fp": 30.0,
      "eval_DISEASE-precision": 0.5454545454545454,
      "eval_DISEASE-recall": 0.32142857142857145,
      "eval_DISEASE-tp": 36.0,
      "eval_DISTRICT-f1": 0.5714285714285714,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 8.0,
      "eval_DISTRICT-precision": 0.5555555555555556,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6624102154828412,
      "eval_EVENT-fn": 266.0,
      "eval_EVENT-fp": 157.0,
      "eval_EVENT-precision": 0.7255244755244755,
      "eval_EVENT-recall": 0.6093979441997063,
      "eval_EVENT-tp": 415.0,
      "eval_FACILITY-f1": 0.562962962962963,
      "eval_FACILITY-fn": 46.0,
      "eval_FACILITY-fp": 13.0,
      "eval_FACILITY-precision": 0.7450980392156863,
      "eval_FACILITY-recall": 0.4523809523809524,
      "eval_FACILITY-tp": 38.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.704225352112676,
      "eval_IDEOLOGY-fn": 11.0,
      "eval_IDEOLOGY-fp": 10.0,
      "eval_IDEOLOGY-precision": 0.7142857142857143,
      "eval_IDEOLOGY-recall": 0.6944444444444444,
      "eval_IDEOLOGY-tp": 25.0,
      "eval_LANGUAGE-f1": 0.0,
      "eval_LANGUAGE-fn": 7.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 0.0,
      "eval_LANGUAGE-recall": 0.0,
      "eval_LANGUAGE-tp": 0.0,
      "eval_LAW-f1": 0.5378151260504201,
      "eval_LAW-fn": 51.0,
      "eval_LAW-fp": 4.0,
      "eval_LAW-precision": 0.8888888888888888,
      "eval_LAW-recall": 0.3855421686746988,
      "eval_LAW-tp": 32.0,
      "eval_LOCATION-f1": 0.6542056074766355,
      "eval_LOCATION-fn": 29.0,
      "eval_LOCATION-fp": 8.0,
      "eval_LOCATION-precision": 0.813953488372093,
      "eval_LOCATION-recall": 0.546875,
      "eval_LOCATION-tp": 35.0,
      "eval_MONEY-f1": 0.8135593220338984,
      "eval_MONEY-fn": 5.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8,
      "eval_MONEY-recall": 0.8275862068965517,
      "eval_MONEY-tp": 24.0,
      "eval_NATIONALITY-f1": 0.7563025210084033,
      "eval_NATIONALITY-fn": 13.0,
      "eval_NATIONALITY-fp": 16.0,
      "eval_NATIONALITY-precision": 0.7377049180327869,
      "eval_NATIONALITY-recall": 0.7758620689655172,
      "eval_NATIONALITY-tp": 45.0,
      "eval_NUMBER-f1": 0.8774928774928775,
      "eval_NUMBER-fn": 30.0,
      "eval_NUMBER-fp": 13.0,
      "eval_NUMBER-precision": 0.9221556886227545,
      "eval_NUMBER-recall": 0.8369565217391305,
      "eval_NUMBER-tp": 154.0,
      "eval_ORDINAL-f1": 0.8,
      "eval_ORDINAL-fn": 27.0,
      "eval_ORDINAL-fp": 10.0,
      "eval_ORDINAL-precision": 0.8809523809523809,
      "eval_ORDINAL-recall": 0.7326732673267327,
      "eval_ORDINAL-tp": 74.0,
      "eval_ORGANIZATION-f1": 0.8476118271417741,
      "eval_ORGANIZATION-fn": 57.0,
      "eval_ORGANIZATION-fp": 144.0,
      "eval_ORGANIZATION-precision": 0.7951635846372689,
      "eval_ORGANIZATION-recall": 0.9074675324675324,
      "eval_ORGANIZATION-tp": 559.0,
      "eval_PENALTY-f1": 0.6938775510204082,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 7.0,
      "eval_PENALTY-precision": 0.8292682926829268,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 1.0,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 0.0,
      "eval_PERCENT-precision": 1.0,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9652220438737292,
      "eval_PERSON-fn": 47.0,
      "eval_PERSON-fp": 18.0,
      "eval_PERSON-precision": 0.9804347826086957,
      "eval_PERSON-recall": 0.9504741833508957,
      "eval_PERSON-tp": 902.0,
      "eval_PRODUCT-f1": 0.6301369863013698,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 20.0,
      "eval_PRODUCT-precision": 0.5348837209302325,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8569807037457434,
      "eval_PROFESSION-fn": 98.0,
      "eval_PROFESSION-fp": 154.0,
      "eval_PROFESSION-precision": 0.8305830583058306,
      "eval_PROFESSION-recall": 0.8851113716295428,
      "eval_PROFESSION-tp": 755.0,
      "eval_RELIGION-f1": 0.7142857142857143,
      "eval_RELIGION-fn": 4.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.5555555555555556,
      "eval_RELIGION-tp": 5.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8497409326424871,
      "eval_STATE_OR_PROVINCE-fn": 17.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8723404255319149,
      "eval_STATE_OR_PROVINCE-recall": 0.8282828282828283,
      "eval_STATE_OR_PROVINCE-tp": 82.0,
      "eval_TIME-f1": 0.7636363636363637,
      "eval_TIME-fn": 8.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8076923076923077,
      "eval_TIME-recall": 0.7241379310344828,
      "eval_TIME-tp": 21.0,
      "eval_WORK_OF_ART-f1": 0.8365384615384616,
      "eval_WORK_OF_ART-fn": 17.0,
      "eval_WORK_OF_ART-fp": 17.0,
      "eval_WORK_OF_ART-precision": 0.8365384615384616,
      "eval_WORK_OF_ART-recall": 0.8365384615384616,
      "eval_WORK_OF_ART-tp": 87.0,
      "eval_f1": 0.7001613262887102,
      "eval_macro-f1": 0.7001613262887102,
      "eval_macro-precision": 0.7484926223502955,
      "eval_macro-recall": 0.6744215837944644,
      "eval_micro-f1": 0.8336865382843454,
      "eval_micro-precision": 0.8510158013544018,
      "eval_micro-recall": 0.8170489434711938,
      "eval_precision": 0.7484926223502955,
      "eval_recall": 0.6744215837944644,
      "step": 700
    },
    {
      "epoch": 7.17,
      "learning_rate": 2.6652462121212124e-05,
      "loss": 0.2219,
      "step": 710
    },
    {
      "epoch": 7.27,
      "learning_rate": 2.660511363636364e-05,
      "loss": 0.2244,
      "step": 720
    },
    {
      "epoch": 7.37,
      "learning_rate": 2.6557765151515152e-05,
      "loss": 0.2231,
      "step": 730
    },
    {
      "epoch": 7.47,
      "learning_rate": 2.651041666666667e-05,
      "loss": 0.2351,
      "step": 740
    },
    {
      "epoch": 7.58,
      "learning_rate": 2.6463068181818183e-05,
      "loss": 0.2125,
      "step": 750
    },
    {
      "epoch": 7.68,
      "learning_rate": 2.6415719696969697e-05,
      "loss": 0.2184,
      "step": 760
    },
    {
      "epoch": 7.78,
      "learning_rate": 2.636837121212121e-05,
      "loss": 0.209,
      "step": 770
    },
    {
      "epoch": 7.88,
      "learning_rate": 2.6321022727272725e-05,
      "loss": 0.228,
      "step": 780
    },
    {
      "epoch": 7.98,
      "learning_rate": 2.6273674242424242e-05,
      "loss": 0.2424,
      "step": 790
    },
    {
      "epoch": 8.08,
      "learning_rate": 2.6226325757575756e-05,
      "loss": 0.1965,
      "step": 800
    },
    {
      "epoch": 8.08,
      "eval_AGE-f1": 0.9338235294117647,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 8.0,
      "eval_AGE-precision": 0.9407407407407408,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6265060240963856,
      "eval_AWARD-fn": 15.0,
      "eval_AWARD-fp": 16.0,
      "eval_AWARD-precision": 0.6190476190476191,
      "eval_AWARD-recall": 0.6341463414634146,
      "eval_AWARD-tp": 26.0,
      "eval_CITY-f1": 0.9133489461358314,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8904109589041096,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9423347398030942,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 21.0,
      "eval_COUNTRY-precision": 0.9410112359550562,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.47368421052631576,
      "eval_CRIME-fn": 28.0,
      "eval_CRIME-fp": 32.0,
      "eval_CRIME-precision": 0.4576271186440678,
      "eval_CRIME-recall": 0.4909090909090909,
      "eval_CRIME-tp": 27.0,
      "eval_DATE-f1": 0.8952929875120077,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 51.0,
      "eval_DATE-precision": 0.9013539651837524,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.4371584699453552,
      "eval_DISEASE-fn": 72.0,
      "eval_DISEASE-fp": 31.0,
      "eval_DISEASE-precision": 0.5633802816901409,
      "eval_DISEASE-recall": 0.35714285714285715,
      "eval_DISEASE-tp": 40.0,
      "eval_DISTRICT-f1": 0.5384615384615384,
      "eval_DISTRICT-fn": 10.0,
      "eval_DISTRICT-fp": 2.0,
      "eval_DISTRICT-precision": 0.7777777777777778,
      "eval_DISTRICT-recall": 0.4117647058823529,
      "eval_DISTRICT-tp": 7.0,
      "eval_EVENT-f1": 0.6623897353648757,
      "eval_EVENT-fn": 268.0,
      "eval_EVENT-fp": 153.0,
      "eval_EVENT-precision": 0.7296819787985865,
      "eval_EVENT-recall": 0.6064610866372981,
      "eval_EVENT-tp": 413.0,
      "eval_FACILITY-f1": 0.6,
      "eval_FACILITY-fn": 36.0,
      "eval_FACILITY-fp": 28.0,
      "eval_FACILITY-precision": 0.631578947368421,
      "eval_FACILITY-recall": 0.5714285714285714,
      "eval_FACILITY-tp": 48.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.71875,
      "eval_IDEOLOGY-fn": 13.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.8214285714285714,
      "eval_IDEOLOGY-recall": 0.6388888888888888,
      "eval_IDEOLOGY-tp": 23.0,
      "eval_LANGUAGE-f1": 0.25,
      "eval_LANGUAGE-fn": 6.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 1.0,
      "eval_LANGUAGE-recall": 0.14285714285714285,
      "eval_LANGUAGE-tp": 1.0,
      "eval_LAW-f1": 0.6527777777777778,
      "eval_LAW-fn": 36.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.7704918032786885,
      "eval_LAW-recall": 0.5662650602409639,
      "eval_LAW-tp": 47.0,
      "eval_LOCATION-f1": 0.7368421052631579,
      "eval_LOCATION-fn": 22.0,
      "eval_LOCATION-fp": 8.0,
      "eval_LOCATION-precision": 0.84,
      "eval_LOCATION-recall": 0.65625,
      "eval_LOCATION-tp": 42.0,
      "eval_MONEY-f1": 0.8135593220338984,
      "eval_MONEY-fn": 5.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8,
      "eval_MONEY-recall": 0.8275862068965517,
      "eval_MONEY-tp": 24.0,
      "eval_NATIONALITY-f1": 0.7758620689655172,
      "eval_NATIONALITY-fn": 13.0,
      "eval_NATIONALITY-fp": 13.0,
      "eval_NATIONALITY-precision": 0.7758620689655172,
      "eval_NATIONALITY-recall": 0.7758620689655172,
      "eval_NATIONALITY-tp": 45.0,
      "eval_NUMBER-f1": 0.884393063583815,
      "eval_NUMBER-fn": 31.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9444444444444444,
      "eval_NUMBER-recall": 0.8315217391304348,
      "eval_NUMBER-tp": 153.0,
      "eval_ORDINAL-f1": 0.8272251308900523,
      "eval_ORDINAL-fn": 22.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8777777777777778,
      "eval_ORDINAL-recall": 0.7821782178217822,
      "eval_ORDINAL-tp": 79.0,
      "eval_ORGANIZATION-f1": 0.8510959939531368,
      "eval_ORGANIZATION-fn": 53.0,
      "eval_ORGANIZATION-fp": 144.0,
      "eval_ORGANIZATION-precision": 0.7963224893917963,
      "eval_ORGANIZATION-recall": 0.913961038961039,
      "eval_ORGANIZATION-tp": 563.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 24.0,
      "eval_PENALTY-fp": 9.0,
      "eval_PENALTY-precision": 0.7857142857142857,
      "eval_PENALTY-recall": 0.5789473684210527,
      "eval_PENALTY-tp": 33.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9619047619047619,
      "eval_PERSON-fn": 40.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9659936238044633,
      "eval_PERSON-recall": 0.9578503688092729,
      "eval_PERSON-tp": 909.0,
      "eval_PRODUCT-f1": 0.5384615384615384,
      "eval_PRODUCT-fn": 9.0,
      "eval_PRODUCT-fp": 27.0,
      "eval_PRODUCT-precision": 0.4375,
      "eval_PRODUCT-recall": 0.7,
      "eval_PRODUCT-tp": 21.0,
      "eval_PROFESSION-f1": 0.855039637599094,
      "eval_PROFESSION-fn": 98.0,
      "eval_PROFESSION-fp": 158.0,
      "eval_PROFESSION-precision": 0.8269441401971522,
      "eval_PROFESSION-recall": 0.8851113716295428,
      "eval_PROFESSION-tp": 755.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8704663212435233,
      "eval_STATE_OR_PROVINCE-fn": 15.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8936170212765957,
      "eval_STATE_OR_PROVINCE-recall": 0.8484848484848485,
      "eval_STATE_OR_PROVINCE-tp": 84.0,
      "eval_TIME-f1": 0.7857142857142857,
      "eval_TIME-fn": 7.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8148148148148148,
      "eval_TIME-recall": 0.7586206896551724,
      "eval_TIME-tp": 22.0,
      "eval_WORK_OF_ART-f1": 0.8502415458937198,
      "eval_WORK_OF_ART-fn": 16.0,
      "eval_WORK_OF_ART-fp": 15.0,
      "eval_WORK_OF_ART-precision": 0.8543689320388349,
      "eval_WORK_OF_ART-recall": 0.8461538461538461,
      "eval_WORK_OF_ART-tp": 88.0,
      "eval_f1": 0.7175644421469222,
      "eval_macro-f1": 0.7175644421469222,
      "eval_macro-precision": 0.7778582964566625,
      "eval_macro-recall": 0.6947082905257449,
      "eval_micro-f1": 0.8373790837744114,
      "eval_micro-precision": 0.8463383139642132,
      "eval_micro-recall": 0.8286075492143761,
      "eval_precision": 0.7778582964566625,
      "eval_recall": 0.6947082905257449,
      "step": 800
    },
    {
      "epoch": 8.18,
      "learning_rate": 2.6178977272727274e-05,
      "loss": 0.202,
      "step": 810
    },
    {
      "epoch": 8.28,
      "learning_rate": 2.6131628787878788e-05,
      "loss": 0.1885,
      "step": 820
    },
    {
      "epoch": 8.38,
      "learning_rate": 2.60842803030303e-05,
      "loss": 0.1879,
      "step": 830
    },
    {
      "epoch": 8.48,
      "learning_rate": 2.603693181818182e-05,
      "loss": 0.1972,
      "step": 840
    },
    {
      "epoch": 8.59,
      "learning_rate": 2.5989583333333333e-05,
      "loss": 0.1832,
      "step": 850
    },
    {
      "epoch": 8.69,
      "learning_rate": 2.594223484848485e-05,
      "loss": 0.1954,
      "step": 860
    },
    {
      "epoch": 8.79,
      "learning_rate": 2.5894886363636364e-05,
      "loss": 0.1741,
      "step": 870
    },
    {
      "epoch": 8.89,
      "learning_rate": 2.5847537878787878e-05,
      "loss": 0.1958,
      "step": 880
    },
    {
      "epoch": 8.99,
      "learning_rate": 2.5800189393939395e-05,
      "loss": 0.1796,
      "step": 890
    },
    {
      "epoch": 9.09,
      "learning_rate": 2.575284090909091e-05,
      "loss": 0.1621,
      "step": 900
    },
    {
      "epoch": 9.09,
      "eval_AGE-f1": 0.9264705882352942,
      "eval_AGE-fn": 11.0,
      "eval_AGE-fp": 9.0,
      "eval_AGE-precision": 0.9333333333333333,
      "eval_AGE-recall": 0.9197080291970803,
      "eval_AGE-tp": 126.0,
      "eval_AWARD-f1": 0.6944444444444444,
      "eval_AWARD-fn": 16.0,
      "eval_AWARD-fp": 6.0,
      "eval_AWARD-precision": 0.8064516129032258,
      "eval_AWARD-recall": 0.6097560975609756,
      "eval_AWARD-tp": 25.0,
      "eval_CITY-f1": 0.9178743961352657,
      "eval_CITY-fn": 18.0,
      "eval_CITY-fp": 16.0,
      "eval_CITY-precision": 0.9223300970873787,
      "eval_CITY-recall": 0.9134615384615384,
      "eval_CITY-tp": 190.0,
      "eval_COUNTRY-f1": 0.9421720733427362,
      "eval_COUNTRY-fn": 21.0,
      "eval_COUNTRY-fp": 20.0,
      "eval_COUNTRY-precision": 0.943502824858757,
      "eval_COUNTRY-recall": 0.9408450704225352,
      "eval_COUNTRY-tp": 334.0,
      "eval_CRIME-f1": 0.45454545454545453,
      "eval_CRIME-fn": 30.0,
      "eval_CRIME-fp": 30.0,
      "eval_CRIME-precision": 0.45454545454545453,
      "eval_CRIME-recall": 0.45454545454545453,
      "eval_CRIME-tp": 25.0,
      "eval_DATE-f1": 0.8880233690360273,
      "eval_DATE-fn": 68.0,
      "eval_DATE-fp": 47.0,
      "eval_DATE-precision": 0.9065606361829026,
      "eval_DATE-recall": 0.8702290076335878,
      "eval_DATE-tp": 456.0,
      "eval_DISEASE-f1": 0.4046242774566474,
      "eval_DISEASE-fn": 77.0,
      "eval_DISEASE-fp": 26.0,
      "eval_DISEASE-precision": 0.5737704918032787,
      "eval_DISEASE-recall": 0.3125,
      "eval_DISEASE-tp": 35.0,
      "eval_DISTRICT-f1": 0.5,
      "eval_DISTRICT-fn": 9.0,
      "eval_DISTRICT-fp": 7.0,
      "eval_DISTRICT-precision": 0.5333333333333333,
      "eval_DISTRICT-recall": 0.47058823529411764,
      "eval_DISTRICT-tp": 8.0,
      "eval_EVENT-f1": 0.6274848746758859,
      "eval_EVENT-fn": 318.0,
      "eval_EVENT-fp": 113.0,
      "eval_EVENT-precision": 0.7626050420168067,
      "eval_EVENT-recall": 0.5330396475770925,
      "eval_EVENT-tp": 363.0,
      "eval_FACILITY-f1": 0.6181818181818182,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 30.0,
      "eval_FACILITY-precision": 0.6296296296296297,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.75,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 9.0,
      "eval_IDEOLOGY-precision": 0.75,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.25,
      "eval_LANGUAGE-fn": 6.0,
      "eval_LANGUAGE-fp": 0.0,
      "eval_LANGUAGE-precision": 1.0,
      "eval_LANGUAGE-recall": 0.14285714285714285,
      "eval_LANGUAGE-tp": 1.0,
      "eval_LAW-f1": 0.6573426573426573,
      "eval_LAW-fn": 36.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.7833333333333333,
      "eval_LAW-recall": 0.5662650602409639,
      "eval_LAW-tp": 47.0,
      "eval_LOCATION-f1": 0.6902654867256637,
      "eval_LOCATION-fn": 25.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.7959183673469388,
      "eval_LOCATION-recall": 0.609375,
      "eval_LOCATION-tp": 39.0,
      "eval_MONEY-f1": 0.8070175438596491,
      "eval_MONEY-fn": 6.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8214285714285714,
      "eval_MONEY-recall": 0.7931034482758621,
      "eval_MONEY-tp": 23.0,
      "eval_NATIONALITY-f1": 0.7377049180327869,
      "eval_NATIONALITY-fn": 13.0,
      "eval_NATIONALITY-fp": 19.0,
      "eval_NATIONALITY-precision": 0.703125,
      "eval_NATIONALITY-recall": 0.7758620689655172,
      "eval_NATIONALITY-tp": 45.0,
      "eval_NUMBER-f1": 0.892128279883382,
      "eval_NUMBER-fn": 31.0,
      "eval_NUMBER-fp": 6.0,
      "eval_NUMBER-precision": 0.9622641509433962,
      "eval_NUMBER-recall": 0.8315217391304348,
      "eval_NUMBER-tp": 153.0,
      "eval_ORDINAL-f1": 0.84375,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 10.0,
      "eval_ORDINAL-precision": 0.8901098901098901,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8669322709163346,
      "eval_ORGANIZATION-fn": 72.0,
      "eval_ORGANIZATION-fp": 95.0,
      "eval_ORGANIZATION-precision": 0.8513302034428795,
      "eval_ORGANIZATION-recall": 0.8831168831168831,
      "eval_ORGANIZATION-tp": 544.0,
      "eval_PENALTY-f1": 0.6597938144329897,
      "eval_PENALTY-fn": 25.0,
      "eval_PENALTY-fp": 8.0,
      "eval_PENALTY-precision": 0.8,
      "eval_PENALTY-recall": 0.5614035087719298,
      "eval_PENALTY-tp": 32.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9654806160382369,
      "eval_PERSON-fn": 40.0,
      "eval_PERSON-fp": 25.0,
      "eval_PERSON-precision": 0.9732334047109208,
      "eval_PERSON-recall": 0.9578503688092729,
      "eval_PERSON-tp": 909.0,
      "eval_PRODUCT-f1": 0.5609756097560976,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 29.0,
      "eval_PRODUCT-precision": 0.4423076923076923,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8541423570595099,
      "eval_PROFESSION-fn": 121.0,
      "eval_PROFESSION-fp": 129.0,
      "eval_PROFESSION-precision": 0.8501742160278746,
      "eval_PROFESSION-recall": 0.8581477139507621,
      "eval_PROFESSION-tp": 732.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8645833333333334,
      "eval_STATE_OR_PROVINCE-fn": 16.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8924731182795699,
      "eval_STATE_OR_PROVINCE-recall": 0.8383838383838383,
      "eval_STATE_OR_PROVINCE-tp": 83.0,
      "eval_TIME-f1": 0.7636363636363637,
      "eval_TIME-fn": 8.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8076923076923077,
      "eval_TIME-recall": 0.7241379310344828,
      "eval_TIME-tp": 21.0,
      "eval_WORK_OF_ART-f1": 0.8502415458937198,
      "eval_WORK_OF_ART-fn": 16.0,
      "eval_WORK_OF_ART-fp": 15.0,
      "eval_WORK_OF_ART-precision": 0.8543689320388349,
      "eval_WORK_OF_ART-recall": 0.8461538461538461,
      "eval_WORK_OF_ART-tp": 88.0,
      "eval_f1": 0.715006362552308,
      "eval_macro-f1": 0.715006362552308,
      "eval_macro-precision": 0.7773731601157349,
      "eval_macro-recall": 0.6898382075475624,
      "eval_micro-f1": 0.8361666355314776,
      "eval_micro-precision": 0.8659315147997678,
      "eval_micro-recall": 0.8083799891638072,
      "eval_precision": 0.7773731601157349,
      "eval_recall": 0.6898382075475624,
      "step": 900
    },
    {
      "epoch": 9.19,
      "learning_rate": 2.5705492424242426e-05,
      "loss": 0.1627,
      "step": 910
    },
    {
      "epoch": 9.29,
      "learning_rate": 2.565814393939394e-05,
      "loss": 0.1775,
      "step": 920
    },
    {
      "epoch": 9.39,
      "learning_rate": 2.5610795454545454e-05,
      "loss": 0.1637,
      "step": 930
    },
    {
      "epoch": 9.49,
      "learning_rate": 2.556344696969697e-05,
      "loss": 0.1605,
      "step": 940
    },
    {
      "epoch": 9.6,
      "learning_rate": 2.5516098484848485e-05,
      "loss": 0.1621,
      "step": 950
    },
    {
      "epoch": 9.7,
      "learning_rate": 2.5468750000000002e-05,
      "loss": 0.1712,
      "step": 960
    },
    {
      "epoch": 9.8,
      "learning_rate": 2.5421401515151516e-05,
      "loss": 0.1526,
      "step": 970
    },
    {
      "epoch": 9.9,
      "learning_rate": 2.537405303030303e-05,
      "loss": 0.1583,
      "step": 980
    },
    {
      "epoch": 10.0,
      "learning_rate": 2.5326704545454548e-05,
      "loss": 0.1668,
      "step": 990
    },
    {
      "epoch": 10.1,
      "learning_rate": 2.527935606060606e-05,
      "loss": 0.1369,
      "step": 1000
    },
    {
      "epoch": 10.1,
      "eval_AGE-f1": 0.9407407407407408,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 6.0,
      "eval_AGE-precision": 0.9548872180451128,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6666666666666666,
      "eval_AWARD-fn": 12.0,
      "eval_AWARD-fp": 17.0,
      "eval_AWARD-precision": 0.6304347826086957,
      "eval_AWARD-recall": 0.7073170731707317,
      "eval_AWARD-tp": 29.0,
      "eval_CITY-f1": 0.9170506912442397,
      "eval_CITY-fn": 9.0,
      "eval_CITY-fp": 27.0,
      "eval_CITY-precision": 0.8805309734513275,
      "eval_CITY-recall": 0.9567307692307693,
      "eval_CITY-tp": 199.0,
      "eval_COUNTRY-f1": 0.9449929478138223,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 19.0,
      "eval_COUNTRY-precision": 0.9463276836158192,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.4745762711864407,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 35.0,
      "eval_CRIME-precision": 0.4444444444444444,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8978805394990366,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 48.0,
      "eval_DATE-precision": 0.9066147859922179,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5023696682464455,
      "eval_DISEASE-fn": 59.0,
      "eval_DISEASE-fp": 46.0,
      "eval_DISEASE-precision": 0.5353535353535354,
      "eval_DISEASE-recall": 0.4732142857142857,
      "eval_DISEASE-tp": 53.0,
      "eval_DISTRICT-f1": 0.5789473684210527,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5238095238095238,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6770428015564203,
      "eval_EVENT-fn": 246.0,
      "eval_EVENT-fp": 169.0,
      "eval_EVENT-precision": 0.7201986754966887,
      "eval_EVENT-recall": 0.6387665198237885,
      "eval_EVENT-tp": 435.0,
      "eval_FACILITY-f1": 0.5911949685534591,
      "eval_FACILITY-fn": 37.0,
      "eval_FACILITY-fp": 28.0,
      "eval_FACILITY-precision": 0.6266666666666667,
      "eval_FACILITY-recall": 0.5595238095238095,
      "eval_FACILITY-tp": 47.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.7605633802816901,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7714285714285715,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6808510638297872,
      "eval_LAW-fn": 35.0,
      "eval_LAW-fp": 10.0,
      "eval_LAW-precision": 0.8275862068965517,
      "eval_LAW-recall": 0.5783132530120482,
      "eval_LAW-tp": 48.0,
      "eval_LOCATION-f1": 0.7580645161290323,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 13.0,
      "eval_LOCATION-precision": 0.7833333333333333,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.8620689655172413,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8620689655172413,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7966101694915254,
      "eval_NATIONALITY-fn": 11.0,
      "eval_NATIONALITY-fp": 13.0,
      "eval_NATIONALITY-precision": 0.7833333333333333,
      "eval_NATIONALITY-recall": 0.8103448275862069,
      "eval_NATIONALITY-tp": 47.0,
      "eval_NUMBER-f1": 0.8863636363636364,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 12.0,
      "eval_NUMBER-precision": 0.9285714285714286,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8571428571428571,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 7.0,
      "eval_ORDINAL-precision": 0.9204545454545454,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8560371517027864,
      "eval_ORGANIZATION-fn": 63.0,
      "eval_ORGANIZATION-fp": 123.0,
      "eval_ORGANIZATION-precision": 0.8180473372781065,
      "eval_ORGANIZATION-recall": 0.8977272727272727,
      "eval_ORGANIZATION-tp": 553.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7555555555555555,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9664218258132214,
      "eval_PERSON-fn": 28.0,
      "eval_PERSON-fp": 36.0,
      "eval_PERSON-precision": 0.9623824451410659,
      "eval_PERSON-recall": 0.9704952581664911,
      "eval_PERSON-tp": 921.0,
      "eval_PRODUCT-f1": 0.5454545454545454,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 34.0,
      "eval_PRODUCT-precision": 0.41379310344827586,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8493303571428571,
      "eval_PROFESSION-fn": 92.0,
      "eval_PROFESSION-fp": 178.0,
      "eval_PROFESSION-precision": 0.8104366347177849,
      "eval_PROFESSION-recall": 0.8921453692848769,
      "eval_PROFESSION-tp": 761.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883495145631068,
      "eval_STATE_OR_PROVINCE-fn": 8.0,
      "eval_STATE_OR_PROVINCE-fp": 16.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8504672897196262,
      "eval_STATE_OR_PROVINCE-recall": 0.9191919191919192,
      "eval_STATE_OR_PROVINCE-tp": 91.0,
      "eval_TIME-f1": 0.8214285714285714,
      "eval_TIME-fn": 6.0,
      "eval_TIME-fp": 4.0,
      "eval_TIME-precision": 0.8518518518518519,
      "eval_TIME-recall": 0.7931034482758621,
      "eval_TIME-tp": 23.0,
      "eval_WORK_OF_ART-f1": 0.8792270531400966,
      "eval_WORK_OF_ART-fn": 13.0,
      "eval_WORK_OF_ART-fp": 12.0,
      "eval_WORK_OF_ART-precision": 0.883495145631068,
      "eval_WORK_OF_ART-recall": 0.875,
      "eval_WORK_OF_ART-tp": 91.0,
      "eval_f1": 0.7382261031281563,
      "eval_macro-f1": 0.7382261031281563,
      "eval_macro-precision": 0.757197955311346,
      "eval_macro-recall": 0.7356251109473577,
      "eval_micro-f1": 0.8424466264300513,
      "eval_micro-precision": 0.8404025880661394,
      "eval_micro-recall": 0.8445006321112516,
      "eval_precision": 0.757197955311346,
      "eval_recall": 0.7356251109473577,
      "step": 1000
    },
    {
      "epoch": 10.2,
      "learning_rate": 2.523200757575758e-05,
      "loss": 0.141,
      "step": 1010
    },
    {
      "epoch": 10.3,
      "learning_rate": 2.5184659090909093e-05,
      "loss": 0.1479,
      "step": 1020
    },
    {
      "epoch": 10.4,
      "learning_rate": 2.5137310606060606e-05,
      "loss": 0.1391,
      "step": 1030
    },
    {
      "epoch": 10.51,
      "learning_rate": 2.5089962121212124e-05,
      "loss": 0.139,
      "step": 1040
    },
    {
      "epoch": 10.61,
      "learning_rate": 2.5042613636363638e-05,
      "loss": 0.1456,
      "step": 1050
    },
    {
      "epoch": 10.71,
      "learning_rate": 2.499526515151515e-05,
      "loss": 0.1361,
      "step": 1060
    },
    {
      "epoch": 10.81,
      "learning_rate": 2.4947916666666665e-05,
      "loss": 0.1509,
      "step": 1070
    },
    {
      "epoch": 10.91,
      "learning_rate": 2.4900568181818183e-05,
      "loss": 0.1373,
      "step": 1080
    },
    {
      "epoch": 11.01,
      "learning_rate": 2.4853219696969697e-05,
      "loss": 0.1446,
      "step": 1090
    },
    {
      "epoch": 11.11,
      "learning_rate": 2.480587121212121e-05,
      "loss": 0.1244,
      "step": 1100
    },
    {
      "epoch": 11.11,
      "eval_AGE-f1": 0.9280575539568345,
      "eval_AGE-fn": 8.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9148936170212766,
      "eval_AGE-recall": 0.9416058394160584,
      "eval_AGE-tp": 129.0,
      "eval_AWARD-f1": 0.7111111111111111,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 17.0,
      "eval_AWARD-precision": 0.6530612244897959,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9112709832134293,
      "eval_CITY-fn": 18.0,
      "eval_CITY-fp": 19.0,
      "eval_CITY-precision": 0.9090909090909091,
      "eval_CITY-recall": 0.9134615384615384,
      "eval_CITY-tp": 190.0,
      "eval_COUNTRY-f1": 0.9370629370629371,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 25.0,
      "eval_COUNTRY-precision": 0.9305555555555556,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.49557522123893805,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 30.0,
      "eval_CRIME-precision": 0.4827586206896552,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8906098741529526,
      "eval_DATE-fn": 64.0,
      "eval_DATE-fp": 49.0,
      "eval_DATE-precision": 0.9037328094302554,
      "eval_DATE-recall": 0.8778625954198473,
      "eval_DATE-tp": 460.0,
      "eval_DISEASE-f1": 0.5412844036697247,
      "eval_DISEASE-fn": 53.0,
      "eval_DISEASE-fp": 47.0,
      "eval_DISEASE-precision": 0.5566037735849056,
      "eval_DISEASE-recall": 0.5267857142857143,
      "eval_DISEASE-tp": 59.0,
      "eval_DISTRICT-f1": 0.4489795918367347,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 21.0,
      "eval_DISTRICT-precision": 0.34375,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6565349544072948,
      "eval_EVENT-fn": 249.0,
      "eval_EVENT-fp": 203.0,
      "eval_EVENT-precision": 0.6803149606299213,
      "eval_EVENT-recall": 0.6343612334801763,
      "eval_EVENT-tp": 432.0,
      "eval_FACILITY-f1": 0.6242774566473989,
      "eval_FACILITY-fn": 30.0,
      "eval_FACILITY-fp": 35.0,
      "eval_FACILITY-precision": 0.6067415730337079,
      "eval_FACILITY-recall": 0.6428571428571429,
      "eval_FACILITY-tp": 54.0,
      "eval_FAMILY-f1": 0.0,
      "eval_FAMILY-fn": 6.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 0.0,
      "eval_FAMILY-recall": 0.0,
      "eval_FAMILY-tp": 0.0,
      "eval_IDEOLOGY-f1": 0.8115942028985508,
      "eval_IDEOLOGY-fn": 8.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.8484848484848485,
      "eval_IDEOLOGY-recall": 0.7777777777777778,
      "eval_IDEOLOGY-tp": 28.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.7019867549668874,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 15.0,
      "eval_LAW-precision": 0.7794117647058824,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7777777777777778,
      "eval_LOCATION-fn": 15.0,
      "eval_LOCATION-fp": 13.0,
      "eval_LOCATION-precision": 0.7903225806451613,
      "eval_LOCATION-recall": 0.765625,
      "eval_LOCATION-tp": 49.0,
      "eval_MONEY-f1": 0.8135593220338984,
      "eval_MONEY-fn": 5.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8,
      "eval_MONEY-recall": 0.8275862068965517,
      "eval_MONEY-tp": 24.0,
      "eval_NATIONALITY-f1": 0.7559055118110236,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 21.0,
      "eval_NATIONALITY-precision": 0.6956521739130435,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8757062146892656,
      "eval_NUMBER-fn": 29.0,
      "eval_NUMBER-fp": 15.0,
      "eval_NUMBER-precision": 0.9117647058823529,
      "eval_NUMBER-recall": 0.842391304347826,
      "eval_NUMBER-tp": 155.0,
      "eval_ORDINAL-f1": 0.826530612244898,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8526315789473684,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8385140257771039,
      "eval_ORGANIZATION-fn": 63.0,
      "eval_ORGANIZATION-fp": 150.0,
      "eval_ORGANIZATION-precision": 0.786628733997155,
      "eval_ORGANIZATION-recall": 0.8977272727272727,
      "eval_ORGANIZATION-tp": 553.0,
      "eval_PENALTY-f1": 0.6597938144329897,
      "eval_PENALTY-fn": 25.0,
      "eval_PENALTY-fp": 8.0,
      "eval_PENALTY-precision": 0.8,
      "eval_PENALTY-recall": 0.5614035087719298,
      "eval_PENALTY-tp": 32.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.965662968832541,
      "eval_PERSON-fn": 35.0,
      "eval_PERSON-fp": 30.0,
      "eval_PERSON-precision": 0.9682203389830508,
      "eval_PERSON-recall": 0.9631190727081138,
      "eval_PERSON-tp": 914.0,
      "eval_PRODUCT-f1": 0.5494505494505495,
      "eval_PRODUCT-fn": 5.0,
      "eval_PRODUCT-fp": 36.0,
      "eval_PRODUCT-precision": 0.4098360655737705,
      "eval_PRODUCT-recall": 0.8333333333333334,
      "eval_PRODUCT-tp": 25.0,
      "eval_PROFESSION-f1": 0.8660508083140878,
      "eval_PROFESSION-fn": 103.0,
      "eval_PROFESSION-fp": 129.0,
      "eval_PROFESSION-precision": 0.8532423208191127,
      "eval_PROFESSION-recall": 0.8792497069167644,
      "eval_PROFESSION-tp": 750.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8712871287128713,
      "eval_STATE_OR_PROVINCE-fn": 11.0,
      "eval_STATE_OR_PROVINCE-fp": 15.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8543689320388349,
      "eval_STATE_OR_PROVINCE-recall": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-tp": 88.0,
      "eval_TIME-f1": 0.819672131147541,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 7.0,
      "eval_TIME-precision": 0.78125,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8490566037735849,
      "eval_WORK_OF_ART-fn": 14.0,
      "eval_WORK_OF_ART-fp": 18.0,
      "eval_WORK_OF_ART-precision": 0.8333333333333334,
      "eval_WORK_OF_ART-recall": 0.8653846153846154,
      "eval_WORK_OF_ART-tp": 90.0,
      "eval_f1": 0.733609687421157,
      "eval_macro-f1": 0.733609687421157,
      "eval_macro-precision": 0.7418385202591918,
      "eval_macro-recall": 0.7449065793339629,
      "eval_micro-f1": 0.8369087155551567,
      "eval_micro-precision": 0.8319057815845824,
      "eval_micro-recall": 0.8419721871049305,
      "eval_precision": 0.7418385202591918,
      "eval_recall": 0.7449065793339629,
      "step": 1100
    },
    {
      "epoch": 11.21,
      "learning_rate": 2.4758522727272728e-05,
      "loss": 0.1294,
      "step": 1110
    },
    {
      "epoch": 11.31,
      "learning_rate": 2.4711174242424242e-05,
      "loss": 0.1315,
      "step": 1120
    },
    {
      "epoch": 11.41,
      "learning_rate": 2.466382575757576e-05,
      "loss": 0.1228,
      "step": 1130
    },
    {
      "epoch": 11.52,
      "learning_rate": 2.4616477272727273e-05,
      "loss": 0.1319,
      "step": 1140
    },
    {
      "epoch": 11.62,
      "learning_rate": 2.4569128787878787e-05,
      "loss": 0.1278,
      "step": 1150
    },
    {
      "epoch": 11.72,
      "learning_rate": 2.4521780303030304e-05,
      "loss": 0.1329,
      "step": 1160
    },
    {
      "epoch": 11.82,
      "learning_rate": 2.4474431818181818e-05,
      "loss": 0.1198,
      "step": 1170
    },
    {
      "epoch": 11.92,
      "learning_rate": 2.4427083333333335e-05,
      "loss": 0.1288,
      "step": 1180
    },
    {
      "epoch": 12.02,
      "learning_rate": 2.437973484848485e-05,
      "loss": 0.1338,
      "step": 1190
    },
    {
      "epoch": 12.12,
      "learning_rate": 2.4332386363636363e-05,
      "loss": 0.1193,
      "step": 1200
    },
    {
      "epoch": 12.12,
      "eval_AGE-f1": 0.927007299270073,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 10.0,
      "eval_AGE-precision": 0.927007299270073,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7058823529411765,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6818181818181818,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9125295508274232,
      "eval_CITY-fn": 15.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8976744186046511,
      "eval_CITY-recall": 0.9278846153846154,
      "eval_CITY-tp": 193.0,
      "eval_COUNTRY-f1": 0.938375350140056,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 24.0,
      "eval_COUNTRY-precision": 0.9331476323119777,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.5225225225225225,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 27.0,
      "eval_CRIME-precision": 0.5178571428571429,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.884871550903901,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 62.0,
      "eval_DATE-precision": 0.8823529411764706,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.5333333333333333,
      "eval_DISEASE-fn": 56.0,
      "eval_DISEASE-fp": 42.0,
      "eval_DISEASE-precision": 0.5714285714285714,
      "eval_DISEASE-recall": 0.5,
      "eval_DISEASE-tp": 56.0,
      "eval_DISTRICT-f1": 0.6111111111111112,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 8.0,
      "eval_DISTRICT-precision": 0.5789473684210527,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6596858638743456,
      "eval_EVENT-fn": 240.0,
      "eval_EVENT-fp": 215.0,
      "eval_EVENT-precision": 0.6722560975609756,
      "eval_EVENT-recall": 0.6475770925110133,
      "eval_EVENT-tp": 441.0,
      "eval_FACILITY-f1": 0.588957055214724,
      "eval_FACILITY-fn": 36.0,
      "eval_FACILITY-fp": 31.0,
      "eval_FACILITY-precision": 0.6075949367088608,
      "eval_FACILITY-recall": 0.5714285714285714,
      "eval_FACILITY-tp": 48.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7714285714285715,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7941176470588235,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.68,
      "eval_LAW-fn": 32.0,
      "eval_LAW-fp": 16.0,
      "eval_LAW-precision": 0.7611940298507462,
      "eval_LAW-recall": 0.6144578313253012,
      "eval_LAW-tp": 51.0,
      "eval_LOCATION-f1": 0.7586206896551724,
      "eval_LOCATION-fn": 20.0,
      "eval_LOCATION-fp": 8.0,
      "eval_LOCATION-precision": 0.8461538461538461,
      "eval_LOCATION-recall": 0.6875,
      "eval_LOCATION-tp": 44.0,
      "eval_MONEY-f1": 0.8,
      "eval_MONEY-fn": 5.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.7741935483870968,
      "eval_MONEY-recall": 0.8275862068965517,
      "eval_MONEY-tp": 24.0,
      "eval_NATIONALITY-f1": 0.7704918032786885,
      "eval_NATIONALITY-fn": 11.0,
      "eval_NATIONALITY-fp": 17.0,
      "eval_NATIONALITY-precision": 0.734375,
      "eval_NATIONALITY-recall": 0.8103448275862069,
      "eval_NATIONALITY-tp": 47.0,
      "eval_NUMBER-f1": 0.8786127167630058,
      "eval_NUMBER-fn": 32.0,
      "eval_NUMBER-fp": 10.0,
      "eval_NUMBER-precision": 0.9382716049382716,
      "eval_NUMBER-recall": 0.8260869565217391,
      "eval_NUMBER-tp": 152.0,
      "eval_ORDINAL-f1": 0.8367346938775511,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 13.0,
      "eval_ORDINAL-precision": 0.8631578947368421,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8540202966432474,
      "eval_ORGANIZATION-fn": 69.0,
      "eval_ORGANIZATION-fp": 118.0,
      "eval_ORGANIZATION-precision": 0.8225563909774436,
      "eval_ORGANIZATION-recall": 0.887987012987013,
      "eval_ORGANIZATION-tp": 547.0,
      "eval_PENALTY-f1": 0.6728971962616822,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 14.0,
      "eval_PENALTY-precision": 0.72,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9688325409403064,
      "eval_PERSON-fn": 32.0,
      "eval_PERSON-fp": 27.0,
      "eval_PERSON-precision": 0.9713983050847458,
      "eval_PERSON-recall": 0.9662802950474183,
      "eval_PERSON-tp": 917.0,
      "eval_PRODUCT-f1": 0.625,
      "eval_PRODUCT-fn": 5.0,
      "eval_PRODUCT-fp": 25.0,
      "eval_PRODUCT-precision": 0.5,
      "eval_PRODUCT-recall": 0.8333333333333334,
      "eval_PRODUCT-tp": 25.0,
      "eval_PROFESSION-f1": 0.8613804905875642,
      "eval_PROFESSION-fn": 98.0,
      "eval_PROFESSION-fp": 145.0,
      "eval_PROFESSION-precision": 0.8388888888888889,
      "eval_PROFESSION-recall": 0.8851113716295428,
      "eval_PROFESSION-tp": 755.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8725490196078431,
      "eval_STATE_OR_PROVINCE-fn": 10.0,
      "eval_STATE_OR_PROVINCE-fp": 16.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8476190476190476,
      "eval_STATE_OR_PROVINCE-recall": 0.898989898989899,
      "eval_STATE_OR_PROVINCE-tp": 89.0,
      "eval_TIME-f1": 0.8070175438596491,
      "eval_TIME-fn": 6.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8214285714285714,
      "eval_TIME-recall": 0.7931034482758621,
      "eval_TIME-tp": 23.0,
      "eval_WORK_OF_ART-f1": 0.8363636363636363,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 24.0,
      "eval_WORK_OF_ART-precision": 0.7931034482758621,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.756054952084766,
      "eval_macro-f1": 0.756054952084766,
      "eval_macro-precision": 0.7883865338008554,
      "eval_macro-recall": 0.7484680685125176,
      "eval_micro-f1": 0.8397083970839708,
      "eval_micro-precision": 0.8369214208826695,
      "eval_micro-recall": 0.8425139967491422,
      "eval_precision": 0.7883865338008554,
      "eval_recall": 0.7484680685125176,
      "step": 1200
    },
    {
      "epoch": 12.22,
      "learning_rate": 2.428503787878788e-05,
      "loss": 0.1206,
      "step": 1210
    },
    {
      "epoch": 12.32,
      "learning_rate": 2.4237689393939394e-05,
      "loss": 0.1057,
      "step": 1220
    },
    {
      "epoch": 12.42,
      "learning_rate": 2.419034090909091e-05,
      "loss": 0.1187,
      "step": 1230
    },
    {
      "epoch": 12.53,
      "learning_rate": 2.4142992424242425e-05,
      "loss": 0.1194,
      "step": 1240
    },
    {
      "epoch": 12.63,
      "learning_rate": 2.409564393939394e-05,
      "loss": 0.1184,
      "step": 1250
    },
    {
      "epoch": 12.73,
      "learning_rate": 2.4048295454545457e-05,
      "loss": 0.11,
      "step": 1260
    },
    {
      "epoch": 12.83,
      "learning_rate": 2.400094696969697e-05,
      "loss": 0.1118,
      "step": 1270
    },
    {
      "epoch": 12.93,
      "learning_rate": 2.3953598484848488e-05,
      "loss": 0.1168,
      "step": 1280
    },
    {
      "epoch": 13.03,
      "learning_rate": 2.3906250000000002e-05,
      "loss": 0.1167,
      "step": 1290
    },
    {
      "epoch": 13.13,
      "learning_rate": 2.3858901515151516e-05,
      "loss": 0.103,
      "step": 1300
    },
    {
      "epoch": 13.13,
      "eval_AGE-f1": 0.9247311827956989,
      "eval_AGE-fn": 8.0,
      "eval_AGE-fp": 13.0,
      "eval_AGE-precision": 0.9084507042253521,
      "eval_AGE-recall": 0.9416058394160584,
      "eval_AGE-tp": 129.0,
      "eval_AWARD-f1": 0.675,
      "eval_AWARD-fn": 14.0,
      "eval_AWARD-fp": 12.0,
      "eval_AWARD-precision": 0.6923076923076923,
      "eval_AWARD-recall": 0.6585365853658537,
      "eval_AWARD-tp": 27.0,
      "eval_CITY-f1": 0.9238095238095239,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 18.0,
      "eval_CITY-precision": 0.9150943396226415,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9370629370629371,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 25.0,
      "eval_COUNTRY-precision": 0.9305555555555556,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.5210084033613446,
      "eval_CRIME-fn": 24.0,
      "eval_CRIME-fp": 33.0,
      "eval_CRIME-precision": 0.484375,
      "eval_CRIME-recall": 0.5636363636363636,
      "eval_CRIME-tp": 31.0,
      "eval_DATE-f1": 0.8836329233680227,
      "eval_DATE-fn": 57.0,
      "eval_DATE-fp": 66.0,
      "eval_DATE-precision": 0.8761726078799249,
      "eval_DATE-recall": 0.8912213740458015,
      "eval_DATE-tp": 467.0,
      "eval_DISEASE-f1": 0.6178861788617886,
      "eval_DISEASE-fn": 36.0,
      "eval_DISEASE-fp": 58.0,
      "eval_DISEASE-precision": 0.5671641791044776,
      "eval_DISEASE-recall": 0.6785714285714286,
      "eval_DISEASE-tp": 76.0,
      "eval_DISTRICT-f1": 0.5714285714285714,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 8.0,
      "eval_DISTRICT-precision": 0.5555555555555556,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6471054718477399,
      "eval_EVENT-fn": 273.0,
      "eval_EVENT-fp": 172.0,
      "eval_EVENT-precision": 0.7034482758620689,
      "eval_EVENT-recall": 0.5991189427312775,
      "eval_EVENT-tp": 408.0,
      "eval_FACILITY-f1": 0.620253164556962,
      "eval_FACILITY-fn": 35.0,
      "eval_FACILITY-fp": 25.0,
      "eval_FACILITY-precision": 0.6621621621621622,
      "eval_FACILITY-recall": 0.5833333333333334,
      "eval_FACILITY-tp": 49.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6577181208053692,
      "eval_LAW-fn": 34.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.7424242424242424,
      "eval_LAW-recall": 0.5903614457831325,
      "eval_LAW-tp": 49.0,
      "eval_LOCATION-f1": 0.7627118644067796,
      "eval_LOCATION-fn": 19.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8333333333333334,
      "eval_LOCATION-recall": 0.703125,
      "eval_LOCATION-tp": 45.0,
      "eval_MONEY-f1": 0.7796610169491526,
      "eval_MONEY-fn": 6.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.7666666666666667,
      "eval_MONEY-recall": 0.7931034482758621,
      "eval_MONEY-tp": 23.0,
      "eval_NATIONALITY-f1": 0.7933884297520661,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 15.0,
      "eval_NATIONALITY-precision": 0.7619047619047619,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8760806916426513,
      "eval_NUMBER-fn": 32.0,
      "eval_NUMBER-fp": 11.0,
      "eval_NUMBER-precision": 0.9325153374233128,
      "eval_NUMBER-recall": 0.8260869565217391,
      "eval_NUMBER-tp": 152.0,
      "eval_ORDINAL-f1": 0.8359788359788359,
      "eval_ORDINAL-fn": 22.0,
      "eval_ORDINAL-fp": 9.0,
      "eval_ORDINAL-precision": 0.8977272727272727,
      "eval_ORDINAL-recall": 0.7821782178217822,
      "eval_ORDINAL-tp": 79.0,
      "eval_ORGANIZATION-f1": 0.8406676783004552,
      "eval_ORGANIZATION-fn": 62.0,
      "eval_ORGANIZATION-fp": 148.0,
      "eval_ORGANIZATION-precision": 0.7891737891737892,
      "eval_ORGANIZATION-recall": 0.8993506493506493,
      "eval_ORGANIZATION-tp": 554.0,
      "eval_PENALTY-f1": 0.6538461538461539,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 13.0,
      "eval_PENALTY-precision": 0.723404255319149,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9678439641539273,
      "eval_PERSON-fn": 31.0,
      "eval_PERSON-fp": 30.0,
      "eval_PERSON-precision": 0.9683544303797469,
      "eval_PERSON-recall": 0.9673340358271865,
      "eval_PERSON-tp": 918.0,
      "eval_PRODUCT-f1": 0.6333333333333333,
      "eval_PRODUCT-fn": 11.0,
      "eval_PRODUCT-fp": 11.0,
      "eval_PRODUCT-precision": 0.6333333333333333,
      "eval_PRODUCT-recall": 0.6333333333333333,
      "eval_PRODUCT-tp": 19.0,
      "eval_PROFESSION-f1": 0.8626086956521739,
      "eval_PROFESSION-fn": 109.0,
      "eval_PROFESSION-fp": 128.0,
      "eval_PROFESSION-precision": 0.8532110091743119,
      "eval_PROFESSION-recall": 0.8722157092614302,
      "eval_PROFESSION-tp": 744.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8844221105527639,
      "eval_STATE_OR_PROVINCE-fn": 11.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.88,
      "eval_STATE_OR_PROVINCE-recall": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-tp": 88.0,
      "eval_TIME-f1": 0.8070175438596491,
      "eval_TIME-fn": 6.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8214285714285714,
      "eval_TIME-recall": 0.7931034482758621,
      "eval_TIME-tp": 23.0,
      "eval_WORK_OF_ART-f1": 0.8780487804878049,
      "eval_WORK_OF_ART-fn": 14.0,
      "eval_WORK_OF_ART-fp": 11.0,
      "eval_WORK_OF_ART-precision": 0.8910891089108911,
      "eval_WORK_OF_ART-recall": 0.8653846153846154,
      "eval_WORK_OF_ART-tp": 90.0,
      "eval_f1": 0.7567403841628785,
      "eval_macro-f1": 0.7567403841628785,
      "eval_macro-precision": 0.7972836114998078,
      "eval_macro-recall": 0.7388652804265095,
      "eval_micro-f1": 0.840036231884058,
      "eval_micro-precision": 0.8426312920225332,
      "eval_micro-recall": 0.8374571067364999,
      "eval_precision": 0.7972836114998078,
      "eval_recall": 0.7388652804265095,
      "step": 1300
    },
    {
      "epoch": 13.23,
      "learning_rate": 2.3811553030303033e-05,
      "loss": 0.1051,
      "step": 1310
    },
    {
      "epoch": 13.33,
      "learning_rate": 2.3764204545454547e-05,
      "loss": 0.1035,
      "step": 1320
    },
    {
      "epoch": 13.43,
      "learning_rate": 2.3716856060606064e-05,
      "loss": 0.1154,
      "step": 1330
    },
    {
      "epoch": 13.54,
      "learning_rate": 2.3669507575757578e-05,
      "loss": 0.1048,
      "step": 1340
    },
    {
      "epoch": 13.64,
      "learning_rate": 2.362215909090909e-05,
      "loss": 0.102,
      "step": 1350
    },
    {
      "epoch": 13.74,
      "learning_rate": 2.3574810606060606e-05,
      "loss": 0.1072,
      "step": 1360
    },
    {
      "epoch": 13.84,
      "learning_rate": 2.352746212121212e-05,
      "loss": 0.1006,
      "step": 1370
    },
    {
      "epoch": 13.94,
      "learning_rate": 2.3480113636363637e-05,
      "loss": 0.1074,
      "step": 1380
    },
    {
      "epoch": 14.04,
      "learning_rate": 2.343276515151515e-05,
      "loss": 0.0982,
      "step": 1390
    },
    {
      "epoch": 14.14,
      "learning_rate": 2.3385416666666665e-05,
      "loss": 0.0913,
      "step": 1400
    },
    {
      "epoch": 14.14,
      "eval_AGE-f1": 0.9124087591240876,
      "eval_AGE-fn": 12.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9124087591240876,
      "eval_AGE-recall": 0.9124087591240876,
      "eval_AGE-tp": 125.0,
      "eval_AWARD-f1": 0.7654320987654321,
      "eval_AWARD-fn": 10.0,
      "eval_AWARD-fp": 9.0,
      "eval_AWARD-precision": 0.775,
      "eval_AWARD-recall": 0.7560975609756098,
      "eval_AWARD-tp": 31.0,
      "eval_CITY-f1": 0.9146919431279621,
      "eval_CITY-fn": 15.0,
      "eval_CITY-fp": 21.0,
      "eval_CITY-precision": 0.9018691588785047,
      "eval_CITY-recall": 0.9278846153846154,
      "eval_CITY-tp": 193.0,
      "eval_COUNTRY-f1": 0.9375,
      "eval_COUNTRY-fn": 25.0,
      "eval_COUNTRY-fp": 19.0,
      "eval_COUNTRY-precision": 0.9455587392550143,
      "eval_COUNTRY-recall": 0.9295774647887324,
      "eval_COUNTRY-tp": 330.0,
      "eval_CRIME-f1": 0.4807692307692308,
      "eval_CRIME-fn": 30.0,
      "eval_CRIME-fp": 24.0,
      "eval_CRIME-precision": 0.5102040816326531,
      "eval_CRIME-recall": 0.45454545454545453,
      "eval_CRIME-tp": 25.0,
      "eval_DATE-f1": 0.887378640776699,
      "eval_DATE-fn": 67.0,
      "eval_DATE-fp": 49.0,
      "eval_DATE-precision": 0.9031620553359684,
      "eval_DATE-recall": 0.8721374045801527,
      "eval_DATE-tp": 457.0,
      "eval_DISEASE-f1": 0.4444444444444444,
      "eval_DISEASE-fn": 70.0,
      "eval_DISEASE-fp": 35.0,
      "eval_DISEASE-precision": 0.5454545454545454,
      "eval_DISEASE-recall": 0.375,
      "eval_DISEASE-tp": 42.0,
      "eval_DISTRICT-f1": 0.5945945945945946,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 9.0,
      "eval_DISTRICT-precision": 0.55,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6438467807660961,
      "eval_EVENT-fn": 286.0,
      "eval_EVENT-fp": 151.0,
      "eval_EVENT-precision": 0.7234432234432234,
      "eval_EVENT-recall": 0.580029368575624,
      "eval_EVENT-tp": 395.0,
      "eval_FACILITY-f1": 0.5925925925925926,
      "eval_FACILITY-fn": 36.0,
      "eval_FACILITY-fp": 30.0,
      "eval_FACILITY-precision": 0.6153846153846154,
      "eval_FACILITY-recall": 0.5714285714285714,
      "eval_FACILITY-tp": 48.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6887417218543046,
      "eval_LAW-fn": 31.0,
      "eval_LAW-fp": 16.0,
      "eval_LAW-precision": 0.7647058823529411,
      "eval_LAW-recall": 0.6265060240963856,
      "eval_LAW-tp": 52.0,
      "eval_LOCATION-f1": 0.7768595041322314,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8245614035087719,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.8333333333333334,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8064516129032258,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7727272727272727,
      "eval_NATIONALITY-fn": 7.0,
      "eval_NATIONALITY-fp": 23.0,
      "eval_NATIONALITY-precision": 0.6891891891891891,
      "eval_NATIONALITY-recall": 0.8793103448275862,
      "eval_NATIONALITY-tp": 51.0,
      "eval_NUMBER-f1": 0.8876080691642652,
      "eval_NUMBER-fn": 30.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9447852760736196,
      "eval_NUMBER-recall": 0.8369565217391305,
      "eval_NUMBER-tp": 154.0,
      "eval_ORDINAL-f1": 0.837696335078534,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 10.0,
      "eval_ORDINAL-precision": 0.8888888888888888,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8462709284627092,
      "eval_ORGANIZATION-fn": 60.0,
      "eval_ORGANIZATION-fp": 142.0,
      "eval_ORGANIZATION-precision": 0.7965616045845272,
      "eval_ORGANIZATION-recall": 0.9025974025974026,
      "eval_ORGANIZATION-tp": 556.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 24.0,
      "eval_PENALTY-fp": 9.0,
      "eval_PENALTY-precision": 0.7857142857142857,
      "eval_PENALTY-recall": 0.5789473684210527,
      "eval_PENALTY-tp": 33.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9698890649762282,
      "eval_PERSON-fn": 31.0,
      "eval_PERSON-fp": 26.0,
      "eval_PERSON-precision": 0.972457627118644,
      "eval_PERSON-recall": 0.9673340358271865,
      "eval_PERSON-tp": 918.0,
      "eval_PRODUCT-f1": 0.5783132530120482,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 29.0,
      "eval_PRODUCT-precision": 0.4528301886792453,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8607888631090487,
      "eval_PROFESSION-fn": 111.0,
      "eval_PROFESSION-fp": 129.0,
      "eval_PROFESSION-precision": 0.851894374282434,
      "eval_PROFESSION-recall": 0.8698710433763188,
      "eval_PROFESSION-tp": 742.0,
      "eval_RELIGION-f1": 0.75,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 1.0,
      "eval_RELIGION-precision": 0.8571428571428571,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 13.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8532110091743119,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 21.0,
      "eval_WORK_OF_ART-precision": 0.8157894736842105,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.7513107197442092,
      "eval_macro-f1": 0.7513107197442092,
      "eval_macro-precision": 0.7875851335600398,
      "eval_macro-recall": 0.7416943809871291,
      "eval_micro-f1": 0.8384502923976608,
      "eval_micro-precision": 0.8485296837432957,
      "eval_micro-recall": 0.8286075492143761,
      "eval_precision": 0.7875851335600398,
      "eval_recall": 0.7416943809871291,
      "step": 1400
    },
    {
      "epoch": 14.24,
      "learning_rate": 2.3338068181818182e-05,
      "loss": 0.0927,
      "step": 1410
    },
    {
      "epoch": 14.34,
      "learning_rate": 2.3290719696969696e-05,
      "loss": 0.0977,
      "step": 1420
    },
    {
      "epoch": 14.44,
      "learning_rate": 2.3243371212121213e-05,
      "loss": 0.097,
      "step": 1430
    },
    {
      "epoch": 14.55,
      "learning_rate": 2.3196022727272727e-05,
      "loss": 0.0909,
      "step": 1440
    },
    {
      "epoch": 14.65,
      "learning_rate": 2.314867424242424e-05,
      "loss": 0.0897,
      "step": 1450
    },
    {
      "epoch": 14.75,
      "learning_rate": 2.310132575757576e-05,
      "loss": 0.1085,
      "step": 1460
    },
    {
      "epoch": 14.85,
      "learning_rate": 2.3053977272727272e-05,
      "loss": 0.0925,
      "step": 1470
    },
    {
      "epoch": 14.95,
      "learning_rate": 2.300662878787879e-05,
      "loss": 0.1005,
      "step": 1480
    },
    {
      "epoch": 15.05,
      "learning_rate": 2.2959280303030303e-05,
      "loss": 0.0828,
      "step": 1490
    },
    {
      "epoch": 15.15,
      "learning_rate": 2.2911931818181817e-05,
      "loss": 0.0883,
      "step": 1500
    },
    {
      "epoch": 15.15,
      "eval_AGE-f1": 0.9124087591240876,
      "eval_AGE-fn": 12.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9124087591240876,
      "eval_AGE-recall": 0.9124087591240876,
      "eval_AGE-tp": 125.0,
      "eval_AWARD-f1": 0.735632183908046,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6956521739130435,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9162790697674419,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 25.0,
      "eval_CITY-precision": 0.8873873873873874,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.9320388349514563,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 30.0,
      "eval_COUNTRY-precision": 0.9180327868852459,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.48333333333333334,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 36.0,
      "eval_CRIME-precision": 0.4461538461538462,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8903846153846153,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 53.0,
      "eval_DATE-precision": 0.8972868217054264,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.5,
      "eval_DISEASE-fn": 59.0,
      "eval_DISEASE-fp": 47.0,
      "eval_DISEASE-precision": 0.53,
      "eval_DISEASE-recall": 0.4732142857142857,
      "eval_DISEASE-tp": 53.0,
      "eval_DISTRICT-f1": 0.5641025641025641,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6580742987111448,
      "eval_EVENT-fn": 247.0,
      "eval_EVENT-fp": 204.0,
      "eval_EVENT-precision": 0.6802507836990596,
      "eval_EVENT-recall": 0.6372980910425844,
      "eval_EVENT-tp": 434.0,
      "eval_FACILITY-f1": 0.6145251396648045,
      "eval_FACILITY-fn": 29.0,
      "eval_FACILITY-fp": 40.0,
      "eval_FACILITY-precision": 0.5789473684210527,
      "eval_FACILITY-recall": 0.6547619047619048,
      "eval_FACILITY-tp": 55.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7605633802816901,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7714285714285715,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.36363636363636365,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.5,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6666666666666666,
      "eval_LAW-fn": 33.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.746268656716418,
      "eval_LAW-recall": 0.6024096385542169,
      "eval_LAW-tp": 50.0,
      "eval_LOCATION-f1": 0.7768595041322314,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8245614035087719,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.847457627118644,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8333333333333334,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7857142857142857,
      "eval_NATIONALITY-fn": 14.0,
      "eval_NATIONALITY-fp": 10.0,
      "eval_NATIONALITY-precision": 0.8148148148148148,
      "eval_NATIONALITY-recall": 0.7586206896551724,
      "eval_NATIONALITY-tp": 44.0,
      "eval_NUMBER-f1": 0.8895184135977338,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 12.0,
      "eval_NUMBER-precision": 0.9289940828402367,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8383838383838383,
      "eval_ORDINAL-fn": 18.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8556701030927835,
      "eval_ORDINAL-recall": 0.8217821782178217,
      "eval_ORDINAL-tp": 83.0,
      "eval_ORGANIZATION-f1": 0.8423457730388424,
      "eval_ORGANIZATION-fn": 63.0,
      "eval_ORGANIZATION-fp": 144.0,
      "eval_ORGANIZATION-precision": 0.793400286944046,
      "eval_ORGANIZATION-recall": 0.8977272727272727,
      "eval_ORGANIZATION-tp": 553.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 22.0,
      "eval_PENALTY-fp": 13.0,
      "eval_PENALTY-precision": 0.7291666666666666,
      "eval_PENALTY-recall": 0.6140350877192983,
      "eval_PENALTY-tp": 35.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9683544303797469,
      "eval_PERSON-fn": 31.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9693769799366421,
      "eval_PERSON-recall": 0.9673340358271865,
      "eval_PERSON-tp": 918.0,
      "eval_PRODUCT-f1": 0.6666666666666666,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 18.0,
      "eval_PRODUCT-precision": 0.5714285714285714,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8605990783410138,
      "eval_PROFESSION-fn": 106.0,
      "eval_PROFESSION-fp": 136.0,
      "eval_PROFESSION-precision": 0.8459796149490374,
      "eval_PROFESSION-recall": 0.8757327080890973,
      "eval_PROFESSION-tp": 747.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8844221105527639,
      "eval_STATE_OR_PROVINCE-fn": 11.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.88,
      "eval_STATE_OR_PROVINCE-recall": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-tp": 88.0,
      "eval_TIME-f1": 0.8135593220338984,
      "eval_TIME-fn": 5.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8,
      "eval_TIME-recall": 0.8275862068965517,
      "eval_TIME-tp": 24.0,
      "eval_WORK_OF_ART-f1": 0.8571428571428571,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 20.0,
      "eval_WORK_OF_ART-precision": 0.8230088495575221,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.7566449725639321,
      "eval_macro-f1": 0.7566449725639321,
      "eval_macro-precision": 0.7804673056036746,
      "eval_macro-recall": 0.7532224495531183,
      "eval_micro-f1": 0.8386169735069601,
      "eval_micro-precision": 0.8340478742408003,
      "eval_micro-recall": 0.843236409608091,
      "eval_precision": 0.7804673056036746,
      "eval_recall": 0.7532224495531183,
      "step": 1500
    },
    {
      "epoch": 15.25,
      "learning_rate": 2.2864583333333335e-05,
      "loss": 0.089,
      "step": 1510
    },
    {
      "epoch": 15.35,
      "learning_rate": 2.281723484848485e-05,
      "loss": 0.0851,
      "step": 1520
    },
    {
      "epoch": 15.45,
      "learning_rate": 2.2769886363636366e-05,
      "loss": 0.0838,
      "step": 1530
    },
    {
      "epoch": 15.56,
      "learning_rate": 2.272253787878788e-05,
      "loss": 0.091,
      "step": 1540
    },
    {
      "epoch": 15.66,
      "learning_rate": 2.2675189393939397e-05,
      "loss": 0.0926,
      "step": 1550
    },
    {
      "epoch": 15.76,
      "learning_rate": 2.262784090909091e-05,
      "loss": 0.0806,
      "step": 1560
    },
    {
      "epoch": 15.86,
      "learning_rate": 2.2580492424242425e-05,
      "loss": 0.0848,
      "step": 1570
    },
    {
      "epoch": 15.96,
      "learning_rate": 2.2533143939393942e-05,
      "loss": 0.0801,
      "step": 1580
    },
    {
      "epoch": 16.06,
      "learning_rate": 2.2485795454545456e-05,
      "loss": 0.0808,
      "step": 1590
    },
    {
      "epoch": 16.16,
      "learning_rate": 2.2438446969696973e-05,
      "loss": 0.0852,
      "step": 1600
    },
    {
      "epoch": 16.16,
      "eval_AGE-f1": 0.9097472924187726,
      "eval_AGE-fn": 11.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.9,
      "eval_AGE-recall": 0.9197080291970803,
      "eval_AGE-tp": 126.0,
      "eval_AWARD-f1": 0.7228915662650602,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 12.0,
      "eval_AWARD-precision": 0.7142857142857143,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9198113207547169,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 21.0,
      "eval_CITY-precision": 0.9027777777777778,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9424964936886395,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 22.0,
      "eval_COUNTRY-precision": 0.9385474860335196,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.5178571428571429,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 28.0,
      "eval_CRIME-precision": 0.5087719298245614,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8944820909970959,
      "eval_DATE-fn": 62.0,
      "eval_DATE-fp": 47.0,
      "eval_DATE-precision": 0.9076620825147348,
      "eval_DATE-recall": 0.8816793893129771,
      "eval_DATE-tp": 462.0,
      "eval_DISEASE-f1": 0.41304347826086957,
      "eval_DISEASE-fn": 74.0,
      "eval_DISEASE-fp": 34.0,
      "eval_DISEASE-precision": 0.5277777777777778,
      "eval_DISEASE-recall": 0.3392857142857143,
      "eval_DISEASE-tp": 38.0,
      "eval_DISTRICT-f1": 0.6285714285714286,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 7.0,
      "eval_DISTRICT-precision": 0.6111111111111112,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6583657587548638,
      "eval_EVENT-fn": 258.0,
      "eval_EVENT-fp": 181.0,
      "eval_EVENT-precision": 0.7003311258278145,
      "eval_EVENT-recall": 0.6211453744493393,
      "eval_EVENT-tp": 423.0,
      "eval_FACILITY-f1": 0.6075949367088608,
      "eval_FACILITY-fn": 36.0,
      "eval_FACILITY-fp": 26.0,
      "eval_FACILITY-precision": 0.6486486486486487,
      "eval_FACILITY-recall": 0.5714285714285714,
      "eval_FACILITY-tp": 48.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6620689655172414,
      "eval_LAW-fn": 35.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.7741935483870968,
      "eval_LAW-recall": 0.5783132530120482,
      "eval_LAW-tp": 48.0,
      "eval_LOCATION-f1": 0.7966101694915254,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 7.0,
      "eval_LOCATION-precision": 0.8703703703703703,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.7868852459016393,
      "eval_MONEY-fn": 5.0,
      "eval_MONEY-fp": 8.0,
      "eval_MONEY-precision": 0.75,
      "eval_MONEY-recall": 0.8275862068965517,
      "eval_MONEY-tp": 24.0,
      "eval_NATIONALITY-f1": 0.7931034482758621,
      "eval_NATIONALITY-fn": 12.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.7931034482758621,
      "eval_NATIONALITY-recall": 0.7931034482758621,
      "eval_NATIONALITY-tp": 46.0,
      "eval_NUMBER-f1": 0.884393063583815,
      "eval_NUMBER-fn": 31.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9444444444444444,
      "eval_NUMBER-recall": 0.8315217391304348,
      "eval_NUMBER-tp": 153.0,
      "eval_ORDINAL-f1": 0.8404255319148937,
      "eval_ORDINAL-fn": 22.0,
      "eval_ORDINAL-fp": 8.0,
      "eval_ORDINAL-precision": 0.9080459770114943,
      "eval_ORDINAL-recall": 0.7821782178217822,
      "eval_ORDINAL-tp": 79.0,
      "eval_ORGANIZATION-f1": 0.8494623655913979,
      "eval_ORGANIZATION-fn": 63.0,
      "eval_ORGANIZATION-fp": 133.0,
      "eval_ORGANIZATION-precision": 0.8061224489795918,
      "eval_ORGANIZATION-recall": 0.8977272727272727,
      "eval_ORGANIZATION-tp": 553.0,
      "eval_PENALTY-f1": 0.6857142857142857,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.75,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9678100263852243,
      "eval_PERSON-fn": 32.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9693446088794926,
      "eval_PERSON-recall": 0.9662802950474183,
      "eval_PERSON-tp": 917.0,
      "eval_PRODUCT-f1": 0.5797101449275363,
      "eval_PRODUCT-fn": 10.0,
      "eval_PRODUCT-fp": 19.0,
      "eval_PRODUCT-precision": 0.5128205128205128,
      "eval_PRODUCT-recall": 0.6666666666666666,
      "eval_PRODUCT-tp": 20.0,
      "eval_PROFESSION-f1": 0.8606130711393869,
      "eval_PROFESSION-fn": 109.0,
      "eval_PROFESSION-fp": 132.0,
      "eval_PROFESSION-precision": 0.8493150684931506,
      "eval_PROFESSION-recall": 0.8722157092614302,
      "eval_PROFESSION-tp": 744.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8775510204081632,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8865979381443299,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.8070175438596491,
      "eval_TIME-fn": 6.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8214285714285714,
      "eval_TIME-recall": 0.7931034482758621,
      "eval_TIME-tp": 23.0,
      "eval_WORK_OF_ART-f1": 0.8490566037735849,
      "eval_WORK_OF_ART-fn": 14.0,
      "eval_WORK_OF_ART-fp": 18.0,
      "eval_WORK_OF_ART-precision": 0.8333333333333334,
      "eval_WORK_OF_ART-recall": 0.8653846153846154,
      "eval_WORK_OF_ART-tp": 90.0,
      "eval_f1": 0.7532933986093596,
      "eval_macro-f1": 0.7532933986093596,
      "eval_macro-precision": 0.7986347059789489,
      "eval_macro-recall": 0.7324111384924198,
      "eval_micro-f1": 0.8406748746010032,
      "eval_micro-precision": 0.8491156963890936,
      "eval_micro-recall": 0.8324002167238577,
      "eval_precision": 0.7986347059789489,
      "eval_recall": 0.7324111384924198,
      "step": 1600
    },
    {
      "epoch": 16.26,
      "learning_rate": 2.2391098484848487e-05,
      "loss": 0.0841,
      "step": 1610
    },
    {
      "epoch": 16.36,
      "learning_rate": 2.234375e-05,
      "loss": 0.0747,
      "step": 1620
    },
    {
      "epoch": 16.46,
      "learning_rate": 2.2296401515151515e-05,
      "loss": 0.084,
      "step": 1630
    },
    {
      "epoch": 16.57,
      "learning_rate": 2.224905303030303e-05,
      "loss": 0.073,
      "step": 1640
    },
    {
      "epoch": 16.67,
      "learning_rate": 2.2201704545454546e-05,
      "loss": 0.0812,
      "step": 1650
    },
    {
      "epoch": 16.77,
      "learning_rate": 2.215435606060606e-05,
      "loss": 0.0799,
      "step": 1660
    },
    {
      "epoch": 16.87,
      "learning_rate": 2.2107007575757574e-05,
      "loss": 0.0827,
      "step": 1670
    },
    {
      "epoch": 16.97,
      "learning_rate": 2.205965909090909e-05,
      "loss": 0.0781,
      "step": 1680
    },
    {
      "epoch": 17.07,
      "learning_rate": 2.2012310606060605e-05,
      "loss": 0.0819,
      "step": 1690
    },
    {
      "epoch": 17.17,
      "learning_rate": 2.1964962121212122e-05,
      "loss": 0.0753,
      "step": 1700
    },
    {
      "epoch": 17.17,
      "eval_AGE-f1": 0.924187725631769,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9142857142857143,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.717948717948718,
      "eval_AWARD-fn": 13.0,
      "eval_AWARD-fp": 9.0,
      "eval_AWARD-precision": 0.7567567567567568,
      "eval_AWARD-recall": 0.6829268292682927,
      "eval_AWARD-tp": 28.0,
      "eval_CITY-f1": 0.919431279620853,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 20.0,
      "eval_CITY-precision": 0.9065420560747663,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.943342776203966,
      "eval_COUNTRY-fn": 22.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9487179487179487,
      "eval_COUNTRY-recall": 0.9380281690140845,
      "eval_COUNTRY-tp": 333.0,
      "eval_CRIME-f1": 0.45901639344262296,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 39.0,
      "eval_CRIME-precision": 0.417910447761194,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8966183574879227,
      "eval_DATE-fn": 60.0,
      "eval_DATE-fp": 47.0,
      "eval_DATE-precision": 0.9080234833659491,
      "eval_DATE-recall": 0.8854961832061069,
      "eval_DATE-tp": 464.0,
      "eval_DISEASE-f1": 0.5,
      "eval_DISEASE-fn": 62.0,
      "eval_DISEASE-fp": 38.0,
      "eval_DISEASE-precision": 0.5681818181818182,
      "eval_DISEASE-recall": 0.44642857142857145,
      "eval_DISEASE-tp": 50.0,
      "eval_DISTRICT-f1": 0.5405405405405406,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6477541371158393,
      "eval_EVENT-fn": 270.0,
      "eval_EVENT-fp": 177.0,
      "eval_EVENT-precision": 0.6989795918367347,
      "eval_EVENT-recall": 0.6035242290748899,
      "eval_EVENT-tp": 411.0,
      "eval_FACILITY-f1": 0.5853658536585366,
      "eval_FACILITY-fn": 36.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6,
      "eval_FACILITY-recall": 0.5714285714285714,
      "eval_FACILITY-tp": 48.0,
      "eval_FAMILY-f1": 0.6666666666666666,
      "eval_FAMILY-fn": 2.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6666666666666666,
      "eval_FAMILY-recall": 0.6666666666666666,
      "eval_FAMILY-tp": 4.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6666666666666666,
      "eval_LAW-fn": 33.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.746268656716418,
      "eval_LAW-recall": 0.6024096385542169,
      "eval_LAW-tp": 50.0,
      "eval_LOCATION-f1": 0.8067226890756303,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 7.0,
      "eval_LOCATION-precision": 0.8727272727272727,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8333333333333334,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8064516129032258,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 14.0,
      "eval_NATIONALITY-precision": 0.7741935483870968,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8908045977011494,
      "eval_NUMBER-fn": 29.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9451219512195121,
      "eval_NUMBER-recall": 0.842391304347826,
      "eval_NUMBER-tp": 155.0,
      "eval_ORDINAL-f1": 0.8333333333333334,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8791208791208791,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8605388272583201,
      "eval_ORGANIZATION-fn": 73.0,
      "eval_ORGANIZATION-fp": 103.0,
      "eval_ORGANIZATION-precision": 0.8405572755417957,
      "eval_ORGANIZATION-recall": 0.8814935064935064,
      "eval_ORGANIZATION-tp": 543.0,
      "eval_PENALTY-f1": 0.6851851851851852,
      "eval_PENALTY-fn": 20.0,
      "eval_PENALTY-fp": 14.0,
      "eval_PENALTY-precision": 0.7254901960784313,
      "eval_PENALTY-recall": 0.6491228070175439,
      "eval_PENALTY-tp": 37.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9698253043938592,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 24.0,
      "eval_PERSON-precision": 0.9744680851063829,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.6067415730337079,
      "eval_PRODUCT-fn": 3.0,
      "eval_PRODUCT-fp": 32.0,
      "eval_PRODUCT-precision": 0.4576271186440678,
      "eval_PRODUCT-recall": 0.9,
      "eval_PRODUCT-tp": 27.0,
      "eval_PROFESSION-f1": 0.8680351906158358,
      "eval_PROFESSION-fn": 113.0,
      "eval_PROFESSION-fp": 112.0,
      "eval_PROFESSION-precision": 0.8685446009389671,
      "eval_PROFESSION-recall": 0.8675263774912075,
      "eval_PROFESSION-tp": 740.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.882051282051282,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8958333333333334,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8202764976958525,
      "eval_WORK_OF_ART-fn": 15.0,
      "eval_WORK_OF_ART-fp": 24.0,
      "eval_WORK_OF_ART-precision": 0.7876106194690266,
      "eval_WORK_OF_ART-recall": 0.8557692307692307,
      "eval_WORK_OF_ART-tp": 89.0,
      "eval_f1": 0.7611322815599538,
      "eval_macro-f1": 0.7611322815599538,
      "eval_macro-precision": 0.7809640835073361,
      "eval_macro-recall": 0.7572364520142816,
      "eval_micro-f1": 0.8421629521373767,
      "eval_micro-precision": 0.8519682128996489,
      "eval_micro-recall": 0.8325808199385949,
      "eval_precision": 0.7809640835073361,
      "eval_recall": 0.7572364520142816,
      "step": 1700
    },
    {
      "epoch": 17.27,
      "learning_rate": 2.1917613636363636e-05,
      "loss": 0.0818,
      "step": 1710
    },
    {
      "epoch": 17.37,
      "learning_rate": 2.187026515151515e-05,
      "loss": 0.072,
      "step": 1720
    },
    {
      "epoch": 17.47,
      "learning_rate": 2.1822916666666667e-05,
      "loss": 0.0799,
      "step": 1730
    },
    {
      "epoch": 17.58,
      "learning_rate": 2.177556818181818e-05,
      "loss": 0.0744,
      "step": 1740
    },
    {
      "epoch": 17.68,
      "learning_rate": 2.17282196969697e-05,
      "loss": 0.0722,
      "step": 1750
    },
    {
      "epoch": 17.78,
      "learning_rate": 2.1680871212121213e-05,
      "loss": 0.0735,
      "step": 1760
    },
    {
      "epoch": 17.88,
      "learning_rate": 2.1633522727272726e-05,
      "loss": 0.0744,
      "step": 1770
    },
    {
      "epoch": 17.98,
      "learning_rate": 2.1586174242424244e-05,
      "loss": 0.0704,
      "step": 1780
    },
    {
      "epoch": 18.08,
      "learning_rate": 2.1538825757575758e-05,
      "loss": 0.075,
      "step": 1790
    },
    {
      "epoch": 18.18,
      "learning_rate": 2.1491477272727275e-05,
      "loss": 0.069,
      "step": 1800
    },
    {
      "epoch": 18.18,
      "eval_AGE-f1": 0.9309090909090909,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 10.0,
      "eval_AGE-precision": 0.927536231884058,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7012987012987013,
      "eval_AWARD-fn": 14.0,
      "eval_AWARD-fp": 9.0,
      "eval_AWARD-precision": 0.75,
      "eval_AWARD-recall": 0.6585365853658537,
      "eval_AWARD-tp": 27.0,
      "eval_CITY-f1": 0.9238095238095239,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 18.0,
      "eval_CITY-precision": 0.9150943396226415,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9398280802292264,
      "eval_COUNTRY-fn": 27.0,
      "eval_COUNTRY-fp": 15.0,
      "eval_COUNTRY-precision": 0.956268221574344,
      "eval_COUNTRY-recall": 0.923943661971831,
      "eval_COUNTRY-tp": 328.0,
      "eval_CRIME-f1": 0.47368421052631576,
      "eval_CRIME-fn": 28.0,
      "eval_CRIME-fp": 32.0,
      "eval_CRIME-precision": 0.4576271186440678,
      "eval_CRIME-recall": 0.4909090909090909,
      "eval_CRIME-tp": 27.0,
      "eval_DATE-f1": 0.8951456310679612,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9110671936758893,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.43386243386243384,
      "eval_DISEASE-fn": 71.0,
      "eval_DISEASE-fp": 36.0,
      "eval_DISEASE-precision": 0.5324675324675324,
      "eval_DISEASE-recall": 0.36607142857142855,
      "eval_DISEASE-tp": 41.0,
      "eval_DISTRICT-f1": 0.625,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 5.0,
      "eval_DISTRICT-precision": 0.6666666666666666,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6462264150943396,
      "eval_EVENT-fn": 270.0,
      "eval_EVENT-fp": 180.0,
      "eval_EVENT-precision": 0.6954314720812182,
      "eval_EVENT-recall": 0.6035242290748899,
      "eval_EVENT-tp": 411.0,
      "eval_FACILITY-f1": 0.5369127516778524,
      "eval_FACILITY-fn": 44.0,
      "eval_FACILITY-fp": 25.0,
      "eval_FACILITY-precision": 0.6153846153846154,
      "eval_FACILITY-recall": 0.47619047619047616,
      "eval_FACILITY-tp": 40.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6758620689655173,
      "eval_LAW-fn": 34.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.7903225806451613,
      "eval_LAW-recall": 0.5903614457831325,
      "eval_LAW-tp": 49.0,
      "eval_LOCATION-f1": 0.7863247863247863,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 7.0,
      "eval_LOCATION-precision": 0.8679245283018868,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.8135593220338984,
      "eval_MONEY-fn": 5.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8,
      "eval_MONEY-recall": 0.8275862068965517,
      "eval_MONEY-tp": 24.0,
      "eval_NATIONALITY-f1": 0.8034188034188035,
      "eval_NATIONALITY-fn": 11.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.7966101694915254,
      "eval_NATIONALITY-recall": 0.8103448275862069,
      "eval_NATIONALITY-tp": 47.0,
      "eval_NUMBER-f1": 0.884393063583815,
      "eval_NUMBER-fn": 31.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9444444444444444,
      "eval_NUMBER-recall": 0.8315217391304348,
      "eval_NUMBER-tp": 153.0,
      "eval_ORDINAL-f1": 0.84375,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 10.0,
      "eval_ORDINAL-precision": 0.8901098901098901,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8589951377633711,
      "eval_ORGANIZATION-fn": 86.0,
      "eval_ORGANIZATION-fp": 88.0,
      "eval_ORGANIZATION-precision": 0.8576051779935275,
      "eval_ORGANIZATION-recall": 0.8603896103896104,
      "eval_ORGANIZATION-tp": 530.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7555555555555555,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9682203389830508,
      "eval_PERSON-fn": 35.0,
      "eval_PERSON-fp": 25.0,
      "eval_PERSON-precision": 0.9733759318423855,
      "eval_PERSON-recall": 0.9631190727081138,
      "eval_PERSON-tp": 914.0,
      "eval_PRODUCT-f1": 0.5882352941176471,
      "eval_PRODUCT-fn": 10.0,
      "eval_PRODUCT-fp": 18.0,
      "eval_PRODUCT-precision": 0.5263157894736842,
      "eval_PRODUCT-recall": 0.6666666666666666,
      "eval_PRODUCT-tp": 20.0,
      "eval_PROFESSION-f1": 0.858682634730539,
      "eval_PROFESSION-fn": 136.0,
      "eval_PROFESSION-fp": 100.0,
      "eval_PROFESSION-precision": 0.8776009791921665,
      "eval_PROFESSION-recall": 0.8405627198124267,
      "eval_PROFESSION-tp": 717.0,
      "eval_RELIGION-f1": 0.75,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 1.0,
      "eval_RELIGION-precision": 0.8571428571428571,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8865979381443299,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 9.0,
      "eval_STATE_OR_PROVINCE-precision": 0.9052631578947369,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.8070175438596491,
      "eval_TIME-fn": 6.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8214285714285714,
      "eval_TIME-recall": 0.7931034482758621,
      "eval_TIME-tp": 23.0,
      "eval_WORK_OF_ART-f1": 0.8855721393034826,
      "eval_WORK_OF_ART-fn": 15.0,
      "eval_WORK_OF_ART-fp": 8.0,
      "eval_WORK_OF_ART-precision": 0.9175257731958762,
      "eval_WORK_OF_ART-recall": 0.8557692307692307,
      "eval_WORK_OF_ART-tp": 89.0,
      "eval_f1": 0.7508344186303715,
      "eval_macro-f1": 0.7508344186303715,
      "eval_macro-precision": 0.8048324602666521,
      "eval_macro-recall": 0.7202569105632619,
      "eval_micro-f1": 0.8403751508960906,
      "eval_micro-precision": 0.8648700305810397,
      "eval_micro-recall": 0.8172295466859311,
      "eval_precision": 0.8048324602666521,
      "eval_recall": 0.7202569105632619,
      "step": 1800
    },
    {
      "epoch": 18.28,
      "learning_rate": 2.144412878787879e-05,
      "loss": 0.0679,
      "step": 1810
    },
    {
      "epoch": 18.38,
      "learning_rate": 2.1396780303030303e-05,
      "loss": 0.0782,
      "step": 1820
    },
    {
      "epoch": 18.48,
      "learning_rate": 2.134943181818182e-05,
      "loss": 0.0739,
      "step": 1830
    },
    {
      "epoch": 18.59,
      "learning_rate": 2.1302083333333334e-05,
      "loss": 0.0706,
      "step": 1840
    },
    {
      "epoch": 18.69,
      "learning_rate": 2.125473484848485e-05,
      "loss": 0.0695,
      "step": 1850
    },
    {
      "epoch": 18.79,
      "learning_rate": 2.1207386363636365e-05,
      "loss": 0.0718,
      "step": 1860
    },
    {
      "epoch": 18.89,
      "learning_rate": 2.116003787878788e-05,
      "loss": 0.0714,
      "step": 1870
    },
    {
      "epoch": 18.99,
      "learning_rate": 2.1112689393939396e-05,
      "loss": 0.0696,
      "step": 1880
    },
    {
      "epoch": 19.09,
      "learning_rate": 2.106534090909091e-05,
      "loss": 0.068,
      "step": 1890
    },
    {
      "epoch": 19.19,
      "learning_rate": 2.1017992424242427e-05,
      "loss": 0.062,
      "step": 1900
    },
    {
      "epoch": 19.19,
      "eval_AGE-f1": 0.9236363636363636,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 11.0,
      "eval_AGE-precision": 0.9202898550724637,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7073170731707317,
      "eval_AWARD-fn": 12.0,
      "eval_AWARD-fp": 12.0,
      "eval_AWARD-precision": 0.7073170731707317,
      "eval_AWARD-recall": 0.7073170731707317,
      "eval_AWARD-tp": 29.0,
      "eval_CITY-f1": 0.9223529411764706,
      "eval_CITY-fn": 12.0,
      "eval_CITY-fp": 21.0,
      "eval_CITY-precision": 0.9032258064516129,
      "eval_CITY-recall": 0.9423076923076923,
      "eval_CITY-tp": 196.0,
      "eval_COUNTRY-f1": 0.9403409090909091,
      "eval_COUNTRY-fn": 24.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9484240687679083,
      "eval_COUNTRY-recall": 0.9323943661971831,
      "eval_COUNTRY-tp": 331.0,
      "eval_CRIME-f1": 0.5042016806722689,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 34.0,
      "eval_CRIME-precision": 0.46875,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8955512572533849,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 47.0,
      "eval_DATE-precision": 0.907843137254902,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.5098039215686274,
      "eval_DISEASE-fn": 60.0,
      "eval_DISEASE-fp": 40.0,
      "eval_DISEASE-precision": 0.5652173913043478,
      "eval_DISEASE-recall": 0.4642857142857143,
      "eval_DISEASE-tp": 52.0,
      "eval_DISTRICT-f1": 0.4878048780487805,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 14.0,
      "eval_DISTRICT-precision": 0.4166666666666667,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6463815789473685,
      "eval_EVENT-fn": 288.0,
      "eval_EVENT-fp": 142.0,
      "eval_EVENT-precision": 0.7345794392523365,
      "eval_EVENT-recall": 0.5770925110132159,
      "eval_EVENT-tp": 393.0,
      "eval_FACILITY-f1": 0.5786163522012578,
      "eval_FACILITY-fn": 38.0,
      "eval_FACILITY-fp": 29.0,
      "eval_FACILITY-precision": 0.6133333333333333,
      "eval_FACILITY-recall": 0.5476190476190477,
      "eval_FACILITY-tp": 46.0,
      "eval_FAMILY-f1": 0.5,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 0.0,
      "eval_FAMILY-precision": 1.0,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7647058823529411,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 6.0,
      "eval_IDEOLOGY-precision": 0.8125,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6883116883116883,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 18.0,
      "eval_LAW-precision": 0.7464788732394366,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7627118644067796,
      "eval_LOCATION-fn": 19.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8333333333333334,
      "eval_LOCATION-recall": 0.703125,
      "eval_LOCATION-tp": 45.0,
      "eval_MONEY-f1": 0.819672131147541,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.78125,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7903225806451613,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 17.0,
      "eval_NATIONALITY-precision": 0.7424242424242424,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.8820224719101124,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 15.0,
      "eval_NUMBER-precision": 0.9127906976744186,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.841025641025641,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 12.0,
      "eval_ORDINAL-precision": 0.8723404255319149,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8589540412044374,
      "eval_ORGANIZATION-fn": 74.0,
      "eval_ORGANIZATION-fp": 104.0,
      "eval_ORGANIZATION-precision": 0.8390092879256966,
      "eval_ORGANIZATION-recall": 0.8798701298701299,
      "eval_ORGANIZATION-tp": 542.0,
      "eval_PENALTY-f1": 0.7169811320754716,
      "eval_PENALTY-fn": 19.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7755102040816326,
      "eval_PENALTY-recall": 0.6666666666666666,
      "eval_PENALTY-tp": 38.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.966824644549763,
      "eval_PERSON-fn": 31.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9663157894736842,
      "eval_PERSON-recall": 0.9673340358271865,
      "eval_PERSON-tp": 918.0,
      "eval_PRODUCT-f1": 0.5393258426966292,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 35.0,
      "eval_PRODUCT-precision": 0.4067796610169492,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.864927536231884,
      "eval_PROFESSION-fn": 107.0,
      "eval_PROFESSION-fp": 126.0,
      "eval_PROFESSION-precision": 0.8555045871559633,
      "eval_PROFESSION-recall": 0.8745603751465416,
      "eval_PROFESSION-tp": 746.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8865979381443299,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 9.0,
      "eval_STATE_OR_PROVINCE-precision": 0.9052631578947369,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.8,
      "eval_TIME-fn": 5.0,
      "eval_TIME-fp": 7.0,
      "eval_TIME-precision": 0.7741935483870968,
      "eval_TIME-recall": 0.8275862068965517,
      "eval_TIME-tp": 24.0,
      "eval_WORK_OF_ART-f1": 0.8857142857142857,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 13.0,
      "eval_WORK_OF_ART-precision": 0.8773584905660378,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.7528094157667399,
      "eval_macro-f1": 0.7528094157667399,
      "eval_macro-precision": 0.7880470943671073,
      "eval_macro-recall": 0.7453755419390431,
      "eval_micro-f1": 0.8422978412001464,
      "eval_micro-precision": 0.8533827618164967,
      "eval_micro-recall": 0.8314972006501715,
      "eval_precision": 0.7880470943671073,
      "eval_recall": 0.7453755419390431,
      "step": 1900
    },
    {
      "epoch": 19.29,
      "learning_rate": 2.097064393939394e-05,
      "loss": 0.0676,
      "step": 1910
    },
    {
      "epoch": 19.39,
      "learning_rate": 2.0923295454545455e-05,
      "loss": 0.0677,
      "step": 1920
    },
    {
      "epoch": 19.49,
      "learning_rate": 2.087594696969697e-05,
      "loss": 0.0687,
      "step": 1930
    },
    {
      "epoch": 19.6,
      "learning_rate": 2.0828598484848483e-05,
      "loss": 0.068,
      "step": 1940
    },
    {
      "epoch": 19.7,
      "learning_rate": 2.078125e-05,
      "loss": 0.062,
      "step": 1950
    },
    {
      "epoch": 19.8,
      "learning_rate": 2.0733901515151514e-05,
      "loss": 0.0688,
      "step": 1960
    },
    {
      "epoch": 19.9,
      "learning_rate": 2.0686553030303028e-05,
      "loss": 0.0729,
      "step": 1970
    },
    {
      "epoch": 20.0,
      "learning_rate": 2.0639204545454545e-05,
      "loss": 0.0613,
      "step": 1980
    },
    {
      "epoch": 20.1,
      "learning_rate": 2.059185606060606e-05,
      "loss": 0.0637,
      "step": 1990
    },
    {
      "epoch": 20.2,
      "learning_rate": 2.0544507575757577e-05,
      "loss": 0.0617,
      "step": 2000
    },
    {
      "epoch": 20.2,
      "eval_AGE-f1": 0.924187725631769,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9142857142857143,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7341772151898734,
      "eval_AWARD-fn": 12.0,
      "eval_AWARD-fp": 9.0,
      "eval_AWARD-precision": 0.7631578947368421,
      "eval_AWARD-recall": 0.7073170731707317,
      "eval_AWARD-tp": 29.0,
      "eval_CITY-f1": 0.9255813953488372,
      "eval_CITY-fn": 9.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8963963963963963,
      "eval_CITY-recall": 0.9567307692307693,
      "eval_CITY-tp": 199.0,
      "eval_COUNTRY-f1": 0.9396914446002805,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 23.0,
      "eval_COUNTRY-precision": 0.9357541899441341,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.49557522123893805,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 30.0,
      "eval_CRIME-precision": 0.4827586206896552,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8931665062560153,
      "eval_DATE-fn": 60.0,
      "eval_DATE-fp": 51.0,
      "eval_DATE-precision": 0.9009708737864077,
      "eval_DATE-recall": 0.8854961832061069,
      "eval_DATE-tp": 464.0,
      "eval_DISEASE-f1": 0.45454545454545453,
      "eval_DISEASE-fn": 67.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.5232558139534884,
      "eval_DISEASE-recall": 0.4017857142857143,
      "eval_DISEASE-tp": 45.0,
      "eval_DISTRICT-f1": 0.6285714285714286,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 7.0,
      "eval_DISTRICT-precision": 0.6111111111111112,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6476190476190476,
      "eval_EVENT-fn": 273.0,
      "eval_EVENT-fp": 171.0,
      "eval_EVENT-precision": 0.7046632124352331,
      "eval_EVENT-recall": 0.5991189427312775,
      "eval_EVENT-tp": 408.0,
      "eval_FACILITY-f1": 0.5641025641025641,
      "eval_FACILITY-fn": 40.0,
      "eval_FACILITY-fp": 28.0,
      "eval_FACILITY-precision": 0.6111111111111112,
      "eval_FACILITY-recall": 0.5238095238095238,
      "eval_FACILITY-tp": 44.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6853146853146853,
      "eval_LAW-fn": 34.0,
      "eval_LAW-fp": 11.0,
      "eval_LAW-precision": 0.8166666666666667,
      "eval_LAW-recall": 0.5903614457831325,
      "eval_LAW-tp": 49.0,
      "eval_LOCATION-f1": 0.7833333333333333,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8392857142857143,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.8333333333333334,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8064516129032258,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 14.0,
      "eval_NATIONALITY-precision": 0.7741935483870968,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8857142857142857,
      "eval_NUMBER-fn": 29.0,
      "eval_NUMBER-fp": 11.0,
      "eval_NUMBER-precision": 0.9337349397590361,
      "eval_NUMBER-recall": 0.842391304347826,
      "eval_NUMBER-tp": 155.0,
      "eval_ORDINAL-f1": 0.8316831683168316,
      "eval_ORDINAL-fn": 17.0,
      "eval_ORDINAL-fp": 17.0,
      "eval_ORDINAL-precision": 0.8316831683168316,
      "eval_ORDINAL-recall": 0.8316831683168316,
      "eval_ORDINAL-tp": 84.0,
      "eval_ORGANIZATION-f1": 0.8609794628751974,
      "eval_ORGANIZATION-fn": 71.0,
      "eval_ORGANIZATION-fp": 105.0,
      "eval_ORGANIZATION-precision": 0.8384615384615385,
      "eval_ORGANIZATION-recall": 0.8847402597402597,
      "eval_ORGANIZATION-tp": 545.0,
      "eval_PENALTY-f1": 0.6796116504854369,
      "eval_PENALTY-fn": 22.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7608695652173914,
      "eval_PENALTY-recall": 0.6140350877192983,
      "eval_PENALTY-tp": 35.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9676735559088501,
      "eval_PERSON-fn": 36.0,
      "eval_PERSON-fp": 25.0,
      "eval_PERSON-precision": 0.9733475479744137,
      "eval_PERSON-recall": 0.9620653319283456,
      "eval_PERSON-tp": 913.0,
      "eval_PRODUCT-f1": 0.6,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 26.0,
      "eval_PRODUCT-precision": 0.48,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.862331575864089,
      "eval_PROFESSION-fn": 117.0,
      "eval_PROFESSION-fp": 118.0,
      "eval_PROFESSION-precision": 0.8618266978922716,
      "eval_PROFESSION-recall": 0.8628370457209847,
      "eval_PROFESSION-tp": 736.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8923076923076924,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 9.0,
      "eval_STATE_OR_PROVINCE-precision": 0.90625,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8620689655172413,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 4.0,
      "eval_TIME-precision": 0.8620689655172413,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8792270531400966,
      "eval_WORK_OF_ART-fn": 13.0,
      "eval_WORK_OF_ART-fp": 12.0,
      "eval_WORK_OF_ART-precision": 0.883495145631068,
      "eval_WORK_OF_ART-recall": 0.875,
      "eval_WORK_OF_ART-tp": 91.0,
      "eval_f1": 0.7593455975560365,
      "eval_macro-f1": 0.7593455975560365,
      "eval_macro-precision": 0.781948480407432,
      "eval_macro-recall": 0.747833475561991,
      "eval_micro-f1": 0.8423654339069938,
      "eval_micro-precision": 0.854093187302766,
      "eval_micro-recall": 0.8309553910059599,
      "eval_precision": 0.781948480407432,
      "eval_recall": 0.747833475561991,
      "step": 2000
    },
    {
      "epoch": 20.3,
      "learning_rate": 2.049715909090909e-05,
      "loss": 0.0622,
      "step": 2010
    },
    {
      "epoch": 20.4,
      "learning_rate": 2.0449810606060604e-05,
      "loss": 0.0619,
      "step": 2020
    },
    {
      "epoch": 20.51,
      "learning_rate": 2.040246212121212e-05,
      "loss": 0.0611,
      "step": 2030
    },
    {
      "epoch": 20.61,
      "learning_rate": 2.0355113636363636e-05,
      "loss": 0.0643,
      "step": 2040
    },
    {
      "epoch": 20.71,
      "learning_rate": 2.0307765151515153e-05,
      "loss": 0.0645,
      "step": 2050
    },
    {
      "epoch": 20.81,
      "learning_rate": 2.0260416666666667e-05,
      "loss": 0.0606,
      "step": 2060
    },
    {
      "epoch": 20.91,
      "learning_rate": 2.0213068181818184e-05,
      "loss": 0.0656,
      "step": 2070
    },
    {
      "epoch": 21.01,
      "learning_rate": 2.0165719696969698e-05,
      "loss": 0.0594,
      "step": 2080
    },
    {
      "epoch": 21.11,
      "learning_rate": 2.0118371212121212e-05,
      "loss": 0.0638,
      "step": 2090
    },
    {
      "epoch": 21.21,
      "learning_rate": 2.007102272727273e-05,
      "loss": 0.0648,
      "step": 2100
    },
    {
      "epoch": 21.21,
      "eval_AGE-f1": 0.9214285714285714,
      "eval_AGE-fn": 8.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.9020979020979021,
      "eval_AGE-recall": 0.9416058394160584,
      "eval_AGE-tp": 129.0,
      "eval_AWARD-f1": 0.7228915662650602,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 12.0,
      "eval_AWARD-precision": 0.7142857142857143,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9184149184149184,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8914027149321267,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.935933147632312,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 27.0,
      "eval_COUNTRY-precision": 0.9256198347107438,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.4409448818897638,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 44.0,
      "eval_CRIME-precision": 0.3888888888888889,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8977604673807206,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 42.0,
      "eval_DATE-precision": 0.9165009940357853,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.48514851485148514,
      "eval_DISEASE-fn": 63.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.5444444444444444,
      "eval_DISEASE-recall": 0.4375,
      "eval_DISEASE-tp": 49.0,
      "eval_DISTRICT-f1": 0.5789473684210527,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5238095238095238,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6412092283214001,
      "eval_EVENT-fn": 278.0,
      "eval_EVENT-fp": 173.0,
      "eval_EVENT-precision": 0.6996527777777778,
      "eval_EVENT-recall": 0.591776798825257,
      "eval_EVENT-tp": 403.0,
      "eval_FACILITY-f1": 0.6024096385542169,
      "eval_FACILITY-fn": 34.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6097560975609756,
      "eval_FACILITY-recall": 0.5952380952380952,
      "eval_FACILITY-tp": 50.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6835443037974683,
      "eval_LAW-fn": 29.0,
      "eval_LAW-fp": 21.0,
      "eval_LAW-precision": 0.72,
      "eval_LAW-recall": 0.6506024096385542,
      "eval_LAW-tp": 54.0,
      "eval_LOCATION-f1": 0.7868852459016393,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8275862068965517,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8620689655172413,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8620689655172413,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.768,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 19.0,
      "eval_NATIONALITY-precision": 0.7164179104477612,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8908045977011494,
      "eval_NUMBER-fn": 29.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9451219512195121,
      "eval_NUMBER-recall": 0.842391304347826,
      "eval_NUMBER-tp": 155.0,
      "eval_ORDINAL-f1": 0.8383838383838383,
      "eval_ORDINAL-fn": 18.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8556701030927835,
      "eval_ORDINAL-recall": 0.8217821782178217,
      "eval_ORDINAL-tp": 83.0,
      "eval_ORGANIZATION-f1": 0.8489425981873112,
      "eval_ORGANIZATION-fn": 54.0,
      "eval_ORGANIZATION-fp": 146.0,
      "eval_ORGANIZATION-precision": 0.7937853107344632,
      "eval_ORGANIZATION-recall": 0.9123376623376623,
      "eval_ORGANIZATION-tp": 562.0,
      "eval_PENALTY-f1": 0.6792452830188679,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 13.0,
      "eval_PENALTY-precision": 0.7346938775510204,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9674711437565582,
      "eval_PERSON-fn": 27.0,
      "eval_PERSON-fp": 35.0,
      "eval_PERSON-precision": 0.9634273772204807,
      "eval_PERSON-recall": 0.9715489989462592,
      "eval_PERSON-tp": 922.0,
      "eval_PRODUCT-f1": 0.48,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 46.0,
      "eval_PRODUCT-precision": 0.34285714285714286,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8604382929642446,
      "eval_PROFESSION-fn": 107.0,
      "eval_PROFESSION-fp": 135.0,
      "eval_PROFESSION-precision": 0.8467650397275823,
      "eval_PROFESSION-recall": 0.8745603751465416,
      "eval_PROFESSION-tp": 746.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-fn": 11.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-recall": 0.8888888888888888,
      "eval_STATE_OR_PROVINCE-tp": 88.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8867924528301887,
      "eval_WORK_OF_ART-fn": 10.0,
      "eval_WORK_OF_ART-fp": 14.0,
      "eval_WORK_OF_ART-precision": 0.8703703703703703,
      "eval_WORK_OF_ART-recall": 0.9038461538461539,
      "eval_WORK_OF_ART-tp": 94.0,
      "eval_f1": 0.7524440985137467,
      "eval_macro-f1": 0.7524440985137467,
      "eval_macro-precision": 0.7613256013051619,
      "eval_macro-recall": 0.7578413014088603,
      "eval_micro-f1": 0.8377623637510134,
      "eval_micro-precision": 0.8357296908698778,
      "eval_micro-recall": 0.8398049485280838,
      "eval_precision": 0.7613256013051619,
      "eval_recall": 0.7578413014088603,
      "step": 2100
    },
    {
      "epoch": 21.31,
      "learning_rate": 2.0023674242424243e-05,
      "loss": 0.0615,
      "step": 2110
    },
    {
      "epoch": 21.41,
      "learning_rate": 1.997632575757576e-05,
      "loss": 0.0608,
      "step": 2120
    },
    {
      "epoch": 21.52,
      "learning_rate": 1.9928977272727274e-05,
      "loss": 0.0605,
      "step": 2130
    },
    {
      "epoch": 21.62,
      "learning_rate": 1.9881628787878788e-05,
      "loss": 0.0589,
      "step": 2140
    },
    {
      "epoch": 21.72,
      "learning_rate": 1.9834280303030305e-05,
      "loss": 0.0564,
      "step": 2150
    },
    {
      "epoch": 21.82,
      "learning_rate": 1.978693181818182e-05,
      "loss": 0.0567,
      "step": 2160
    },
    {
      "epoch": 21.92,
      "learning_rate": 1.9739583333333337e-05,
      "loss": 0.061,
      "step": 2170
    },
    {
      "epoch": 22.02,
      "learning_rate": 1.969223484848485e-05,
      "loss": 0.0581,
      "step": 2180
    },
    {
      "epoch": 22.12,
      "learning_rate": 1.9644886363636364e-05,
      "loss": 0.0703,
      "step": 2190
    },
    {
      "epoch": 22.22,
      "learning_rate": 1.959753787878788e-05,
      "loss": 0.0534,
      "step": 2200
    },
    {
      "epoch": 22.22,
      "eval_AGE-f1": 0.9214285714285714,
      "eval_AGE-fn": 8.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.9020979020979021,
      "eval_AGE-recall": 0.9416058394160584,
      "eval_AGE-tp": 129.0,
      "eval_AWARD-f1": 0.7317073170731707,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 11.0,
      "eval_AWARD-precision": 0.7317073170731707,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.91725768321513,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 21.0,
      "eval_CITY-precision": 0.9023255813953488,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.943342776203966,
      "eval_COUNTRY-fn": 22.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9487179487179487,
      "eval_COUNTRY-recall": 0.9380281690140845,
      "eval_COUNTRY-tp": 333.0,
      "eval_CRIME-f1": 0.47863247863247865,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 34.0,
      "eval_CRIME-precision": 0.45161290322580644,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8934108527131783,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 47.0,
      "eval_DATE-precision": 0.90748031496063,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.4824120603015075,
      "eval_DISEASE-fn": 64.0,
      "eval_DISEASE-fp": 39.0,
      "eval_DISEASE-precision": 0.5517241379310345,
      "eval_DISEASE-recall": 0.42857142857142855,
      "eval_DISEASE-tp": 48.0,
      "eval_DISTRICT-f1": 0.55,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 12.0,
      "eval_DISTRICT-precision": 0.4782608695652174,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6571428571428571,
      "eval_EVENT-fn": 267.0,
      "eval_EVENT-fp": 165.0,
      "eval_EVENT-precision": 0.7150259067357513,
      "eval_EVENT-recall": 0.6079295154185022,
      "eval_EVENT-tp": 414.0,
      "eval_FACILITY-f1": 0.6153846153846154,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 33.0,
      "eval_FACILITY-precision": 0.611764705882353,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.4444444444444444,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 1.0,
      "eval_FAMILY-precision": 0.6666666666666666,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7605633802816901,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7714285714285715,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.7,
      "eval_LAW-fn": 27.0,
      "eval_LAW-fp": 21.0,
      "eval_LAW-precision": 0.7272727272727273,
      "eval_LAW-recall": 0.6746987951807228,
      "eval_LAW-tp": 56.0,
      "eval_LOCATION-f1": 0.773109243697479,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8363636363636363,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.8333333333333334,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8064516129032258,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7933884297520661,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 15.0,
      "eval_NATIONALITY-precision": 0.7619047619047619,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8908045977011494,
      "eval_NUMBER-fn": 29.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9451219512195121,
      "eval_NUMBER-recall": 0.842391304347826,
      "eval_NUMBER-tp": 155.0,
      "eval_ORDINAL-f1": 0.8210526315789474,
      "eval_ORDINAL-fn": 23.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8764044943820225,
      "eval_ORDINAL-recall": 0.7722772277227723,
      "eval_ORDINAL-tp": 78.0,
      "eval_ORGANIZATION-f1": 0.8582494190549961,
      "eval_ORGANIZATION-fn": 62.0,
      "eval_ORGANIZATION-fp": 121.0,
      "eval_ORGANIZATION-precision": 0.8207407407407408,
      "eval_ORGANIZATION-recall": 0.8993506493506493,
      "eval_ORGANIZATION-tp": 554.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7555555555555555,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 2.0,
      "eval_PERCENT-precision": 0.8181818181818182,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9683210137275607,
      "eval_PERSON-fn": 32.0,
      "eval_PERSON-fp": 28.0,
      "eval_PERSON-precision": 0.9703703703703703,
      "eval_PERSON-recall": 0.9662802950474183,
      "eval_PERSON-tp": 917.0,
      "eval_PRODUCT-f1": 0.5185185185185185,
      "eval_PRODUCT-fn": 9.0,
      "eval_PRODUCT-fp": 30.0,
      "eval_PRODUCT-precision": 0.4117647058823529,
      "eval_PRODUCT-recall": 0.7,
      "eval_PRODUCT-tp": 21.0,
      "eval_PROFESSION-f1": 0.856140350877193,
      "eval_PROFESSION-fn": 121.0,
      "eval_PROFESSION-fp": 125.0,
      "eval_PROFESSION-precision": 0.8541423570595099,
      "eval_PROFESSION-recall": 0.8581477139507621,
      "eval_PROFESSION-tp": 732.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.89,
      "eval_STATE_OR_PROVINCE-fn": 10.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8811881188118812,
      "eval_STATE_OR_PROVINCE-recall": 0.898989898989899,
      "eval_STATE_OR_PROVINCE-tp": 89.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8846153846153846,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 12.0,
      "eval_WORK_OF_ART-precision": 0.8846153846153846,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7511468951613184,
      "eval_macro-f1": 0.7511468951613184,
      "eval_macro-precision": 0.7745520462246136,
      "eval_macro-recall": 0.7460322014531322,
      "eval_micro-f1": 0.8413956454404664,
      "eval_micro-precision": 0.8488970588235294,
      "eval_micro-recall": 0.8340256456564927,
      "eval_precision": 0.7745520462246136,
      "eval_recall": 0.7460322014531322,
      "step": 2200
    },
    {
      "epoch": 22.32,
      "learning_rate": 1.9550189393939396e-05,
      "loss": 0.0537,
      "step": 2210
    },
    {
      "epoch": 22.42,
      "learning_rate": 1.950284090909091e-05,
      "loss": 0.0546,
      "step": 2220
    },
    {
      "epoch": 22.53,
      "learning_rate": 1.9455492424242423e-05,
      "loss": 0.0535,
      "step": 2230
    },
    {
      "epoch": 22.63,
      "learning_rate": 1.9408143939393937e-05,
      "loss": 0.0578,
      "step": 2240
    },
    {
      "epoch": 22.73,
      "learning_rate": 1.9360795454545455e-05,
      "loss": 0.0612,
      "step": 2250
    },
    {
      "epoch": 22.83,
      "learning_rate": 1.931344696969697e-05,
      "loss": 0.0538,
      "step": 2260
    },
    {
      "epoch": 22.93,
      "learning_rate": 1.9266098484848486e-05,
      "loss": 0.0563,
      "step": 2270
    },
    {
      "epoch": 23.03,
      "learning_rate": 1.921875e-05,
      "loss": 0.0526,
      "step": 2280
    },
    {
      "epoch": 23.13,
      "learning_rate": 1.9171401515151513e-05,
      "loss": 0.0566,
      "step": 2290
    },
    {
      "epoch": 23.23,
      "learning_rate": 1.912405303030303e-05,
      "loss": 0.0537,
      "step": 2300
    },
    {
      "epoch": 23.23,
      "eval_AGE-f1": 0.9309090909090909,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 10.0,
      "eval_AGE-precision": 0.927536231884058,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.6823529411764706,
      "eval_AWARD-fn": 12.0,
      "eval_AWARD-fp": 15.0,
      "eval_AWARD-precision": 0.6590909090909091,
      "eval_AWARD-recall": 0.7073170731707317,
      "eval_AWARD-tp": 29.0,
      "eval_CITY-f1": 0.9133489461358314,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8904109589041096,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9421720733427362,
      "eval_COUNTRY-fn": 21.0,
      "eval_COUNTRY-fp": 20.0,
      "eval_COUNTRY-precision": 0.943502824858757,
      "eval_COUNTRY-recall": 0.9408450704225352,
      "eval_COUNTRY-tp": 334.0,
      "eval_CRIME-f1": 0.45161290322580644,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 41.0,
      "eval_CRIME-precision": 0.4057971014492754,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.8964181994191674,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 46.0,
      "eval_DATE-precision": 0.9096267190569745,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.5882352941176471,
      "eval_DISEASE-fn": 42.0,
      "eval_DISEASE-fp": 56.0,
      "eval_DISEASE-precision": 0.5555555555555556,
      "eval_DISEASE-recall": 0.625,
      "eval_DISEASE-tp": 70.0,
      "eval_DISTRICT-f1": 0.6666666666666666,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 5.0,
      "eval_DISTRICT-precision": 0.6875,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6481334392374901,
      "eval_EVENT-fn": 273.0,
      "eval_EVENT-fp": 170.0,
      "eval_EVENT-precision": 0.7058823529411765,
      "eval_EVENT-recall": 0.5991189427312775,
      "eval_EVENT-tp": 408.0,
      "eval_FACILITY-f1": 0.5977011494252874,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 38.0,
      "eval_FACILITY-precision": 0.5777777777777777,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7878787878787878,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 4.0,
      "eval_IDEOLOGY-precision": 0.8666666666666667,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.4,
      "eval_LANGUAGE-fn": 5.0,
      "eval_LANGUAGE-fp": 1.0,
      "eval_LANGUAGE-precision": 0.6666666666666666,
      "eval_LANGUAGE-recall": 0.2857142857142857,
      "eval_LANGUAGE-tp": 2.0,
      "eval_LAW-f1": 0.6666666666666666,
      "eval_LAW-fn": 33.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.746268656716418,
      "eval_LAW-recall": 0.6024096385542169,
      "eval_LAW-tp": 50.0,
      "eval_LOCATION-f1": 0.8,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 8.0,
      "eval_LOCATION-precision": 0.8571428571428571,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8064516129032258,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 8.0,
      "eval_MONEY-precision": 0.7575757575757576,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8099173553719008,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 14.0,
      "eval_NATIONALITY-precision": 0.7777777777777778,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.884393063583815,
      "eval_NUMBER-fn": 31.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9444444444444444,
      "eval_NUMBER-recall": 0.8315217391304348,
      "eval_NUMBER-tp": 153.0,
      "eval_ORDINAL-f1": 0.8307692307692308,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 13.0,
      "eval_ORDINAL-precision": 0.8617021276595744,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8571428571428571,
      "eval_ORGANIZATION-fn": 70.0,
      "eval_ORGANIZATION-fp": 112.0,
      "eval_ORGANIZATION-precision": 0.8297872340425532,
      "eval_ORGANIZATION-recall": 0.8863636363636364,
      "eval_ORGANIZATION-tp": 546.0,
      "eval_PENALTY-f1": 0.66,
      "eval_PENALTY-fn": 24.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.7674418604651163,
      "eval_PENALTY-recall": 0.5789473684210527,
      "eval_PENALTY-tp": 33.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9669984284965951,
      "eval_PERSON-fn": 26.0,
      "eval_PERSON-fp": 37.0,
      "eval_PERSON-precision": 0.9614583333333333,
      "eval_PERSON-recall": 0.9726027397260274,
      "eval_PERSON-tp": 923.0,
      "eval_PRODUCT-f1": 0.6419753086419753,
      "eval_PRODUCT-fn": 4.0,
      "eval_PRODUCT-fp": 25.0,
      "eval_PRODUCT-precision": 0.5098039215686274,
      "eval_PRODUCT-recall": 0.8666666666666667,
      "eval_PRODUCT-tp": 26.0,
      "eval_PROFESSION-f1": 0.8639258830341633,
      "eval_PROFESSION-fn": 107.0,
      "eval_PROFESSION-fp": 128.0,
      "eval_PROFESSION-precision": 0.8535469107551488,
      "eval_PROFESSION-recall": 0.8745603751465416,
      "eval_PROFESSION-tp": 746.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8923076923076924,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 9.0,
      "eval_STATE_OR_PROVINCE-precision": 0.90625,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.7857142857142857,
      "eval_TIME-fn": 7.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8148148148148148,
      "eval_TIME-recall": 0.7586206896551724,
      "eval_TIME-tp": 22.0,
      "eval_WORK_OF_ART-f1": 0.8363636363636363,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 24.0,
      "eval_WORK_OF_ART-precision": 0.7931034482758621,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7570835839166778,
      "eval_macro-f1": 0.7570835839166778,
      "eval_macro-precision": 0.7785217899801452,
      "eval_macro-recall": 0.7518890402876743,
      "eval_micro-f1": 0.8418381219976434,
      "eval_micro-precision": 0.8449781659388647,
      "eval_micro-recall": 0.8387213292396605,
      "eval_precision": 0.7785217899801452,
      "eval_recall": 0.7518890402876743,
      "step": 2300
    },
    {
      "epoch": 23.33,
      "learning_rate": 1.9076704545454545e-05,
      "loss": 0.0557,
      "step": 2310
    },
    {
      "epoch": 23.43,
      "learning_rate": 1.9029356060606062e-05,
      "loss": 0.0555,
      "step": 2320
    },
    {
      "epoch": 23.54,
      "learning_rate": 1.8982007575757576e-05,
      "loss": 0.0524,
      "step": 2330
    },
    {
      "epoch": 23.64,
      "learning_rate": 1.893465909090909e-05,
      "loss": 0.0508,
      "step": 2340
    },
    {
      "epoch": 23.74,
      "learning_rate": 1.8887310606060607e-05,
      "loss": 0.0535,
      "step": 2350
    },
    {
      "epoch": 23.84,
      "learning_rate": 1.883996212121212e-05,
      "loss": 0.0518,
      "step": 2360
    },
    {
      "epoch": 23.94,
      "learning_rate": 1.8792613636363638e-05,
      "loss": 0.0531,
      "step": 2370
    },
    {
      "epoch": 24.04,
      "learning_rate": 1.8745265151515152e-05,
      "loss": 0.0488,
      "step": 2380
    },
    {
      "epoch": 24.14,
      "learning_rate": 1.8697916666666666e-05,
      "loss": 0.0469,
      "step": 2390
    },
    {
      "epoch": 24.24,
      "learning_rate": 1.8650568181818183e-05,
      "loss": 0.0553,
      "step": 2400
    },
    {
      "epoch": 24.24,
      "eval_AGE-f1": 0.9202898550724637,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9136690647482014,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6741573033707865,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 18.0,
      "eval_AWARD-precision": 0.625,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9133489461358314,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8904109589041096,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9403409090909091,
      "eval_COUNTRY-fn": 24.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9484240687679083,
      "eval_COUNTRY-recall": 0.9323943661971831,
      "eval_COUNTRY-tp": 331.0,
      "eval_CRIME-f1": 0.4881889763779528,
      "eval_CRIME-fn": 24.0,
      "eval_CRIME-fp": 41.0,
      "eval_CRIME-precision": 0.4305555555555556,
      "eval_CRIME-recall": 0.5636363636363636,
      "eval_CRIME-tp": 31.0,
      "eval_DATE-f1": 0.8899521531100478,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 56.0,
      "eval_DATE-precision": 0.8925143953934741,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.5023696682464455,
      "eval_DISEASE-fn": 59.0,
      "eval_DISEASE-fp": 46.0,
      "eval_DISEASE-precision": 0.5353535353535354,
      "eval_DISEASE-recall": 0.4732142857142857,
      "eval_DISEASE-tp": 53.0,
      "eval_DISTRICT-f1": 0.6285714285714286,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 7.0,
      "eval_DISTRICT-precision": 0.6111111111111112,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6561324303987961,
      "eval_EVENT-fn": 245.0,
      "eval_EVENT-fp": 212.0,
      "eval_EVENT-precision": 0.6728395061728395,
      "eval_EVENT-recall": 0.6402349486049926,
      "eval_EVENT-tp": 436.0,
      "eval_FACILITY-f1": 0.6011560693641619,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 37.0,
      "eval_FACILITY-precision": 0.5842696629213483,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.4444444444444444,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 1.0,
      "eval_FAMILY-precision": 0.6666666666666666,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.8059701492537313,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 4.0,
      "eval_IDEOLOGY-precision": 0.8709677419354839,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6883116883116883,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 18.0,
      "eval_LAW-precision": 0.7464788732394366,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7741935483870968,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 12.0,
      "eval_LOCATION-precision": 0.8,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.819672131147541,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.78125,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8099173553719008,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 14.0,
      "eval_NATIONALITY-precision": 0.7777777777777778,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.88,
      "eval_NUMBER-fn": 30.0,
      "eval_NUMBER-fp": 12.0,
      "eval_NUMBER-precision": 0.927710843373494,
      "eval_NUMBER-recall": 0.8369565217391305,
      "eval_NUMBER-tp": 154.0,
      "eval_ORDINAL-f1": 0.8367346938775511,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 13.0,
      "eval_ORDINAL-precision": 0.8631578947368421,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8598574821852731,
      "eval_ORGANIZATION-fn": 73.0,
      "eval_ORGANIZATION-fp": 104.0,
      "eval_ORGANIZATION-precision": 0.839258114374034,
      "eval_ORGANIZATION-recall": 0.8814935064935064,
      "eval_ORGANIZATION-tp": 543.0,
      "eval_PENALTY-f1": 0.6601941747572816,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.7391304347826086,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9683210137275607,
      "eval_PERSON-fn": 32.0,
      "eval_PERSON-fp": 28.0,
      "eval_PERSON-precision": 0.9703703703703703,
      "eval_PERSON-recall": 0.9662802950474183,
      "eval_PERSON-tp": 917.0,
      "eval_PRODUCT-f1": 0.6419753086419753,
      "eval_PRODUCT-fn": 4.0,
      "eval_PRODUCT-fp": 25.0,
      "eval_PRODUCT-precision": 0.5098039215686274,
      "eval_PRODUCT-recall": 0.8666666666666667,
      "eval_PRODUCT-tp": 26.0,
      "eval_PROFESSION-f1": 0.860934795152914,
      "eval_PROFESSION-fn": 107.0,
      "eval_PROFESSION-fp": 134.0,
      "eval_PROFESSION-precision": 0.8477272727272728,
      "eval_PROFESSION-recall": 0.8745603751465416,
      "eval_PROFESSION-tp": 746.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8865979381443299,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 9.0,
      "eval_STATE_OR_PROVINCE-precision": 0.9052631578947369,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8558139534883721,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 19.0,
      "eval_WORK_OF_ART-precision": 0.8288288288288288,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7616602817591879,
      "eval_macro-f1": 0.7616602817591879,
      "eval_macro-precision": 0.7753445300037064,
      "eval_macro-recall": 0.7614803034651915,
      "eval_micro-f1": 0.8402633715161901,
      "eval_micro-precision": 0.8392792792792793,
      "eval_micro-recall": 0.8412497742459816,
      "eval_precision": 0.7753445300037064,
      "eval_recall": 0.7614803034651915,
      "step": 2400
    },
    {
      "epoch": 24.34,
      "learning_rate": 1.8603219696969697e-05,
      "loss": 0.0564,
      "step": 2410
    },
    {
      "epoch": 24.44,
      "learning_rate": 1.8555871212121214e-05,
      "loss": 0.0519,
      "step": 2420
    },
    {
      "epoch": 24.55,
      "learning_rate": 1.850852272727273e-05,
      "loss": 0.0549,
      "step": 2430
    },
    {
      "epoch": 24.65,
      "learning_rate": 1.8461174242424242e-05,
      "loss": 0.0537,
      "step": 2440
    },
    {
      "epoch": 24.75,
      "learning_rate": 1.841382575757576e-05,
      "loss": 0.0506,
      "step": 2450
    },
    {
      "epoch": 24.85,
      "learning_rate": 1.8366477272727273e-05,
      "loss": 0.0537,
      "step": 2460
    },
    {
      "epoch": 24.95,
      "learning_rate": 1.831912878787879e-05,
      "loss": 0.0493,
      "step": 2470
    },
    {
      "epoch": 25.05,
      "learning_rate": 1.8271780303030305e-05,
      "loss": 0.0506,
      "step": 2480
    },
    {
      "epoch": 25.15,
      "learning_rate": 1.822443181818182e-05,
      "loss": 0.0501,
      "step": 2490
    },
    {
      "epoch": 25.25,
      "learning_rate": 1.8177083333333336e-05,
      "loss": 0.0462,
      "step": 2500
    },
    {
      "epoch": 25.25,
      "eval_AGE-f1": 0.9169675090252708,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 13.0,
      "eval_AGE-precision": 0.9071428571428571,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6896551724137931,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 16.0,
      "eval_AWARD-precision": 0.6521739130434783,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9134615384615384,
      "eval_CITY-fn": 18.0,
      "eval_CITY-fp": 18.0,
      "eval_CITY-precision": 0.9134615384615384,
      "eval_CITY-recall": 0.9134615384615384,
      "eval_CITY-tp": 190.0,
      "eval_COUNTRY-f1": 0.9463276836158192,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9490084985835694,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.4793388429752066,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 37.0,
      "eval_CRIME-precision": 0.4393939393939394,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8916827852998066,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 49.0,
      "eval_DATE-precision": 0.903921568627451,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.5213270142180095,
      "eval_DISEASE-fn": 57.0,
      "eval_DISEASE-fp": 44.0,
      "eval_DISEASE-precision": 0.5555555555555556,
      "eval_DISEASE-recall": 0.49107142857142855,
      "eval_DISEASE-tp": 55.0,
      "eval_DISTRICT-f1": 0.5945945945945946,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 9.0,
      "eval_DISTRICT-precision": 0.55,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6537267080745341,
      "eval_EVENT-fn": 260.0,
      "eval_EVENT-fp": 186.0,
      "eval_EVENT-precision": 0.6935749588138386,
      "eval_EVENT-recall": 0.618208516886931,
      "eval_EVENT-tp": 421.0,
      "eval_FACILITY-f1": 0.575,
      "eval_FACILITY-fn": 38.0,
      "eval_FACILITY-fp": 30.0,
      "eval_FACILITY-precision": 0.6052631578947368,
      "eval_FACILITY-recall": 0.5476190476190477,
      "eval_FACILITY-tp": 46.0,
      "eval_FAMILY-f1": 0.6,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 1.0,
      "eval_FAMILY-precision": 0.75,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7941176470588235,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.84375,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.68,
      "eval_LAW-fn": 32.0,
      "eval_LAW-fp": 16.0,
      "eval_LAW-precision": 0.7611940298507462,
      "eval_LAW-recall": 0.6144578313253012,
      "eval_LAW-tp": 51.0,
      "eval_LOCATION-f1": 0.7899159663865546,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 8.0,
      "eval_LOCATION-precision": 0.8545454545454545,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.847457627118644,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8333333333333334,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7903225806451613,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 17.0,
      "eval_NATIONALITY-precision": 0.7424242424242424,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.899135446685879,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9570552147239264,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8247422680412371,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 13.0,
      "eval_ORDINAL-precision": 0.8602150537634409,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8564668769716088,
      "eval_ORGANIZATION-fn": 73.0,
      "eval_ORGANIZATION-fp": 109.0,
      "eval_ORGANIZATION-precision": 0.8328220858895705,
      "eval_ORGANIZATION-recall": 0.8814935064935064,
      "eval_ORGANIZATION-tp": 543.0,
      "eval_PENALTY-f1": 0.6732673267326733,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.7727272727272727,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9694415173867229,
      "eval_PERSON-fn": 29.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9694415173867229,
      "eval_PERSON-recall": 0.9694415173867229,
      "eval_PERSON-tp": 920.0,
      "eval_PRODUCT-f1": 0.6486486486486487,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 20.0,
      "eval_PRODUCT-precision": 0.5454545454545454,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8618721461187214,
      "eval_PROFESSION-fn": 98.0,
      "eval_PROFESSION-fp": 144.0,
      "eval_PROFESSION-precision": 0.8398220244716351,
      "eval_PROFESSION-recall": 0.8851113716295428,
      "eval_PROFESSION-tp": 755.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.863849765258216,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 17.0,
      "eval_WORK_OF_ART-precision": 0.8440366972477065,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7669244585829416,
      "eval_macro-f1": 0.7669244585829416,
      "eval_macro-precision": 0.7848812741733333,
      "eval_macro-recall": 0.7595076651223114,
      "eval_micro-f1": 0.8422867513611615,
      "eval_micro-precision": 0.8464344337041766,
      "eval_micro-recall": 0.8381795195954488,
      "eval_precision": 0.7848812741733333,
      "eval_recall": 0.7595076651223114,
      "step": 2500
    },
    {
      "epoch": 25.35,
      "learning_rate": 1.8129734848484846e-05,
      "loss": 0.051,
      "step": 2510
    },
    {
      "epoch": 25.45,
      "learning_rate": 1.8082386363636364e-05,
      "loss": 0.0552,
      "step": 2520
    },
    {
      "epoch": 25.56,
      "learning_rate": 1.8035037878787878e-05,
      "loss": 0.0494,
      "step": 2530
    },
    {
      "epoch": 25.66,
      "learning_rate": 1.7987689393939395e-05,
      "loss": 0.0479,
      "step": 2540
    },
    {
      "epoch": 25.76,
      "learning_rate": 1.794034090909091e-05,
      "loss": 0.0534,
      "step": 2550
    },
    {
      "epoch": 25.86,
      "learning_rate": 1.7892992424242423e-05,
      "loss": 0.0464,
      "step": 2560
    },
    {
      "epoch": 25.96,
      "learning_rate": 1.784564393939394e-05,
      "loss": 0.0535,
      "step": 2570
    },
    {
      "epoch": 26.06,
      "learning_rate": 1.7798295454545454e-05,
      "loss": 0.049,
      "step": 2580
    },
    {
      "epoch": 26.16,
      "learning_rate": 1.775094696969697e-05,
      "loss": 0.047,
      "step": 2590
    },
    {
      "epoch": 26.26,
      "learning_rate": 1.7703598484848485e-05,
      "loss": 0.0503,
      "step": 2600
    },
    {
      "epoch": 26.26,
      "eval_AGE-f1": 0.9142857142857143,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 15.0,
      "eval_AGE-precision": 0.8951048951048951,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.6881720430107527,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 20.0,
      "eval_AWARD-precision": 0.6153846153846154,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9227166276346604,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8995433789954338,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.9439775910364145,
      "eval_COUNTRY-fn": 18.0,
      "eval_COUNTRY-fp": 22.0,
      "eval_COUNTRY-precision": 0.9387186629526463,
      "eval_COUNTRY-recall": 0.9492957746478873,
      "eval_COUNTRY-tp": 337.0,
      "eval_CRIME-f1": 0.496,
      "eval_CRIME-fn": 24.0,
      "eval_CRIME-fp": 39.0,
      "eval_CRIME-precision": 0.44285714285714284,
      "eval_CRIME-recall": 0.5636363636363636,
      "eval_CRIME-tp": 31.0,
      "eval_DATE-f1": 0.8935762224352828,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 53.0,
      "eval_DATE-precision": 0.8978805394990366,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5897435897435898,
      "eval_DISEASE-fn": 43.0,
      "eval_DISEASE-fp": 53.0,
      "eval_DISEASE-precision": 0.5655737704918032,
      "eval_DISEASE-recall": 0.6160714285714286,
      "eval_DISEASE-tp": 69.0,
      "eval_DISTRICT-f1": 0.5641025641025641,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.653250773993808,
      "eval_EVENT-fn": 259.0,
      "eval_EVENT-fp": 189.0,
      "eval_EVENT-precision": 0.690671031096563,
      "eval_EVENT-recall": 0.6196769456681351,
      "eval_EVENT-tp": 422.0,
      "eval_FACILITY-f1": 0.5868263473053892,
      "eval_FACILITY-fn": 35.0,
      "eval_FACILITY-fp": 34.0,
      "eval_FACILITY-precision": 0.5903614457831325,
      "eval_FACILITY-recall": 0.5833333333333334,
      "eval_FACILITY-tp": 49.0,
      "eval_FAMILY-f1": 0.6153846153846154,
      "eval_FAMILY-fn": 2.0,
      "eval_FAMILY-fp": 3.0,
      "eval_FAMILY-precision": 0.5714285714285714,
      "eval_FAMILY-recall": 0.6666666666666666,
      "eval_FAMILY-tp": 4.0,
      "eval_IDEOLOGY-f1": 0.7605633802816901,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7714285714285715,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6845637583892618,
      "eval_LAW-fn": 32.0,
      "eval_LAW-fp": 15.0,
      "eval_LAW-precision": 0.7727272727272727,
      "eval_LAW-recall": 0.6144578313253012,
      "eval_LAW-tp": 51.0,
      "eval_LOCATION-f1": 0.7777777777777778,
      "eval_LOCATION-fn": 15.0,
      "eval_LOCATION-fp": 13.0,
      "eval_LOCATION-precision": 0.7903225806451613,
      "eval_LOCATION-recall": 0.765625,
      "eval_LOCATION-tp": 49.0,
      "eval_MONEY-f1": 0.847457627118644,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8333333333333334,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8245614035087719,
      "eval_NATIONALITY-fn": 11.0,
      "eval_NATIONALITY-fp": 9.0,
      "eval_NATIONALITY-precision": 0.8392857142857143,
      "eval_NATIONALITY-recall": 0.8103448275862069,
      "eval_NATIONALITY-tp": 47.0,
      "eval_NUMBER-f1": 0.8977272727272727,
      "eval_NUMBER-fn": 26.0,
      "eval_NUMBER-fp": 10.0,
      "eval_NUMBER-precision": 0.9404761904761905,
      "eval_NUMBER-recall": 0.8586956521739131,
      "eval_NUMBER-tp": 158.0,
      "eval_ORDINAL-f1": 0.85,
      "eval_ORDINAL-fn": 16.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8585858585858586,
      "eval_ORDINAL-recall": 0.8415841584158416,
      "eval_ORDINAL-tp": 85.0,
      "eval_ORGANIZATION-f1": 0.8629600626468285,
      "eval_ORGANIZATION-fn": 65.0,
      "eval_ORGANIZATION-fp": 110.0,
      "eval_ORGANIZATION-precision": 0.8335854765506808,
      "eval_ORGANIZATION-recall": 0.8944805194805194,
      "eval_ORGANIZATION-tp": 551.0,
      "eval_PENALTY-f1": 0.6923076923076923,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7659574468085106,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 2.0,
      "eval_PERCENT-precision": 0.8181818181818182,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9688325409403064,
      "eval_PERSON-fn": 32.0,
      "eval_PERSON-fp": 27.0,
      "eval_PERSON-precision": 0.9713983050847458,
      "eval_PERSON-recall": 0.9662802950474183,
      "eval_PERSON-tp": 917.0,
      "eval_PRODUCT-f1": 0.6582278481012658,
      "eval_PRODUCT-fn": 4.0,
      "eval_PRODUCT-fp": 23.0,
      "eval_PRODUCT-precision": 0.5306122448979592,
      "eval_PRODUCT-recall": 0.8666666666666667,
      "eval_PRODUCT-tp": 26.0,
      "eval_PROFESSION-f1": 0.8619883040935673,
      "eval_PROFESSION-fn": 116.0,
      "eval_PROFESSION-fp": 120.0,
      "eval_PROFESSION-precision": 0.8599766627771295,
      "eval_PROFESSION-recall": 0.8640093786635404,
      "eval_PROFESSION-tp": 737.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8416289592760181,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 24.0,
      "eval_WORK_OF_ART-precision": 0.7948717948717948,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.769754421448566,
      "eval_macro-f1": 0.769754421448566,
      "eval_macro-precision": 0.7689789150472343,
      "eval_macro-recall": 0.7811406904485524,
      "eval_micro-f1": 0.8439473209453364,
      "eval_micro-precision": 0.8430347810416291,
      "eval_micro-recall": 0.844861838540726,
      "eval_precision": 0.7689789150472343,
      "eval_recall": 0.7811406904485524,
      "step": 2600
    },
    {
      "epoch": 26.36,
      "learning_rate": 1.765625e-05,
      "loss": 0.049,
      "step": 2610
    },
    {
      "epoch": 26.46,
      "learning_rate": 1.7608901515151516e-05,
      "loss": 0.0533,
      "step": 2620
    },
    {
      "epoch": 26.57,
      "learning_rate": 1.756155303030303e-05,
      "loss": 0.044,
      "step": 2630
    },
    {
      "epoch": 26.67,
      "learning_rate": 1.7514204545454547e-05,
      "loss": 0.0483,
      "step": 2640
    },
    {
      "epoch": 26.77,
      "learning_rate": 1.746685606060606e-05,
      "loss": 0.0506,
      "step": 2650
    },
    {
      "epoch": 26.87,
      "learning_rate": 1.7419507575757575e-05,
      "loss": 0.0458,
      "step": 2660
    },
    {
      "epoch": 26.97,
      "learning_rate": 1.7372159090909092e-05,
      "loss": 0.047,
      "step": 2670
    },
    {
      "epoch": 27.07,
      "learning_rate": 1.7324810606060606e-05,
      "loss": 0.0492,
      "step": 2680
    },
    {
      "epoch": 27.17,
      "learning_rate": 1.7277462121212124e-05,
      "loss": 0.0457,
      "step": 2690
    },
    {
      "epoch": 27.27,
      "learning_rate": 1.7230113636363638e-05,
      "loss": 0.0462,
      "step": 2700
    },
    {
      "epoch": 27.27,
      "eval_AGE-f1": 0.9071428571428571,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 16.0,
      "eval_AGE-precision": 0.8881118881118881,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6976744186046512,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 15.0,
      "eval_AWARD-precision": 0.6666666666666666,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9125295508274232,
      "eval_CITY-fn": 15.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8976744186046511,
      "eval_CITY-recall": 0.9278846153846154,
      "eval_CITY-tp": 193.0,
      "eval_COUNTRY-f1": 0.9478138222849083,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9491525423728814,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.45,
      "eval_CRIME-fn": 28.0,
      "eval_CRIME-fp": 38.0,
      "eval_CRIME-precision": 0.4153846153846154,
      "eval_CRIME-recall": 0.4909090909090909,
      "eval_CRIME-tp": 27.0,
      "eval_DATE-f1": 0.892925430210325,
      "eval_DATE-fn": 57.0,
      "eval_DATE-fp": 55.0,
      "eval_DATE-precision": 0.8946360153256705,
      "eval_DATE-recall": 0.8912213740458015,
      "eval_DATE-tp": 467.0,
      "eval_DISEASE-f1": 0.5345622119815668,
      "eval_DISEASE-fn": 54.0,
      "eval_DISEASE-fp": 47.0,
      "eval_DISEASE-precision": 0.5523809523809524,
      "eval_DISEASE-recall": 0.5178571428571429,
      "eval_DISEASE-tp": 58.0,
      "eval_DISTRICT-f1": 0.5641025641025641,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6556862745098039,
      "eval_EVENT-fn": 263.0,
      "eval_EVENT-fp": 176.0,
      "eval_EVENT-precision": 0.7037037037037037,
      "eval_EVENT-recall": 0.6138032305433186,
      "eval_EVENT-tp": 418.0,
      "eval_FACILITY-f1": 0.6136363636363636,
      "eval_FACILITY-fn": 30.0,
      "eval_FACILITY-fp": 38.0,
      "eval_FACILITY-precision": 0.5869565217391305,
      "eval_FACILITY-recall": 0.6428571428571429,
      "eval_FACILITY-tp": 54.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6986301369863014,
      "eval_LAW-fn": 32.0,
      "eval_LAW-fp": 12.0,
      "eval_LAW-precision": 0.8095238095238095,
      "eval_LAW-recall": 0.6144578313253012,
      "eval_LAW-tp": 51.0,
      "eval_LOCATION-f1": 0.7586206896551724,
      "eval_LOCATION-fn": 20.0,
      "eval_LOCATION-fp": 8.0,
      "eval_LOCATION-precision": 0.8461538461538461,
      "eval_LOCATION-recall": 0.6875,
      "eval_LOCATION-tp": 44.0,
      "eval_MONEY-f1": 0.819672131147541,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.78125,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7741935483870968,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 18.0,
      "eval_NATIONALITY-precision": 0.7272727272727273,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8997134670487106,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 8.0,
      "eval_NUMBER-precision": 0.9515151515151515,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8324873096446701,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8541666666666666,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8589440504334122,
      "eval_ORGANIZATION-fn": 71.0,
      "eval_ORGANIZATION-fp": 108.0,
      "eval_ORGANIZATION-precision": 0.8346094946401225,
      "eval_ORGANIZATION-recall": 0.8847402597402597,
      "eval_ORGANIZATION-tp": 545.0,
      "eval_PENALTY-f1": 0.7047619047619048,
      "eval_PENALTY-fn": 20.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7708333333333334,
      "eval_PENALTY-recall": 0.6491228070175439,
      "eval_PENALTY-tp": 37.0,
      "eval_PERCENT-f1": 0.9,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 2.0,
      "eval_PERCENT-precision": 0.8181818181818182,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9666842940243258,
      "eval_PERSON-fn": 35.0,
      "eval_PERSON-fp": 28.0,
      "eval_PERSON-precision": 0.970276008492569,
      "eval_PERSON-recall": 0.9631190727081138,
      "eval_PERSON-tp": 914.0,
      "eval_PRODUCT-f1": 0.5853658536585366,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 28.0,
      "eval_PRODUCT-precision": 0.46153846153846156,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8601398601398601,
      "eval_PROFESSION-fn": 115.0,
      "eval_PROFESSION-fp": 125.0,
      "eval_PROFESSION-precision": 0.8551564310544612,
      "eval_PROFESSION-recall": 0.8651817116060961,
      "eval_PROFESSION-tp": 738.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8969072164948454,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8598130841121495,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 18.0,
      "eval_WORK_OF_ART-precision": 0.8363636363636363,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7591471031908495,
      "eval_macro-f1": 0.7591471031908495,
      "eval_macro-precision": 0.7676809078035732,
      "eval_macro-recall": 0.7620219437443159,
      "eval_micro-f1": 0.841255442670537,
      "eval_micro-precision": 0.8450883907417532,
      "eval_micro-recall": 0.8374571067364999,
      "eval_precision": 0.7676809078035732,
      "eval_recall": 0.7620219437443159,
      "step": 2700
    },
    {
      "epoch": 27.37,
      "learning_rate": 1.718276515151515e-05,
      "loss": 0.0508,
      "step": 2710
    },
    {
      "epoch": 27.47,
      "learning_rate": 1.713541666666667e-05,
      "loss": 0.0475,
      "step": 2720
    },
    {
      "epoch": 27.58,
      "learning_rate": 1.7088068181818183e-05,
      "loss": 0.0447,
      "step": 2730
    },
    {
      "epoch": 27.68,
      "learning_rate": 1.70407196969697e-05,
      "loss": 0.0436,
      "step": 2740
    },
    {
      "epoch": 27.78,
      "learning_rate": 1.6993371212121214e-05,
      "loss": 0.05,
      "step": 2750
    },
    {
      "epoch": 27.88,
      "learning_rate": 1.6946022727272728e-05,
      "loss": 0.0461,
      "step": 2760
    },
    {
      "epoch": 27.98,
      "learning_rate": 1.6898674242424245e-05,
      "loss": 0.0451,
      "step": 2770
    },
    {
      "epoch": 28.08,
      "learning_rate": 1.685132575757576e-05,
      "loss": 0.0424,
      "step": 2780
    },
    {
      "epoch": 28.18,
      "learning_rate": 1.6803977272727276e-05,
      "loss": 0.0453,
      "step": 2790
    },
    {
      "epoch": 28.28,
      "learning_rate": 1.6756628787878787e-05,
      "loss": 0.0423,
      "step": 2800
    },
    {
      "epoch": 28.28,
      "eval_AGE-f1": 0.9309090909090909,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 10.0,
      "eval_AGE-precision": 0.927536231884058,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7126436781609196,
      "eval_AWARD-fn": 10.0,
      "eval_AWARD-fp": 15.0,
      "eval_AWARD-precision": 0.6739130434782609,
      "eval_AWARD-recall": 0.7560975609756098,
      "eval_AWARD-tp": 31.0,
      "eval_CITY-f1": 0.9176470588235294,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8986175115207373,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9445234708392604,
      "eval_COUNTRY-fn": 23.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.9540229885057471,
      "eval_COUNTRY-recall": 0.9352112676056338,
      "eval_COUNTRY-tp": 332.0,
      "eval_CRIME-f1": 0.48333333333333334,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 36.0,
      "eval_CRIME-precision": 0.4461538461538462,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8948891031822566,
      "eval_DATE-fn": 60.0,
      "eval_DATE-fp": 49.0,
      "eval_DATE-precision": 0.9044834307992202,
      "eval_DATE-recall": 0.8854961832061069,
      "eval_DATE-tp": 464.0,
      "eval_DISEASE-f1": 0.5345622119815668,
      "eval_DISEASE-fn": 54.0,
      "eval_DISEASE-fp": 47.0,
      "eval_DISEASE-precision": 0.5523809523809524,
      "eval_DISEASE-recall": 0.5178571428571429,
      "eval_DISEASE-tp": 58.0,
      "eval_DISTRICT-f1": 0.5714285714285714,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 8.0,
      "eval_DISTRICT-precision": 0.5555555555555556,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6656346749226006,
      "eval_EVENT-fn": 251.0,
      "eval_EVENT-fp": 181.0,
      "eval_EVENT-precision": 0.7037643207855974,
      "eval_EVENT-recall": 0.631424375917768,
      "eval_EVENT-tp": 430.0,
      "eval_FACILITY-f1": 0.5732484076433121,
      "eval_FACILITY-fn": 39.0,
      "eval_FACILITY-fp": 28.0,
      "eval_FACILITY-precision": 0.6164383561643836,
      "eval_FACILITY-recall": 0.5357142857142857,
      "eval_FACILITY-tp": 45.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7761194029850746,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.8387096774193549,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7066666666666667,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.7910447761194029,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7863247863247863,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 7.0,
      "eval_LOCATION-precision": 0.8679245283018868,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.819672131147541,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.78125,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.7868852459016393,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 16.0,
      "eval_NATIONALITY-precision": 0.75,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8971428571428571,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 9.0,
      "eval_NUMBER-precision": 0.9457831325301205,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8383838383838383,
      "eval_ORDINAL-fn": 18.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8556701030927835,
      "eval_ORDINAL-recall": 0.8217821782178217,
      "eval_ORDINAL-tp": 83.0,
      "eval_ORGANIZATION-f1": 0.8498054474708171,
      "eval_ORGANIZATION-fn": 70.0,
      "eval_ORGANIZATION-fp": 123.0,
      "eval_ORGANIZATION-precision": 0.8161434977578476,
      "eval_ORGANIZATION-recall": 0.8863636363636364,
      "eval_ORGANIZATION-tp": 546.0,
      "eval_PENALTY-f1": 0.6990291262135923,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.782608695652174,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9662090813093981,
      "eval_PERSON-fn": 34.0,
      "eval_PERSON-fp": 30.0,
      "eval_PERSON-precision": 0.9682539682539683,
      "eval_PERSON-recall": 0.964172813487882,
      "eval_PERSON-tp": 915.0,
      "eval_PRODUCT-f1": 0.5783132530120482,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 29.0,
      "eval_PRODUCT-precision": 0.4528301886792453,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8647092688543466,
      "eval_PROFESSION-fn": 102.0,
      "eval_PROFESSION-fp": 133.0,
      "eval_PROFESSION-precision": 0.8495475113122172,
      "eval_PROFESSION-recall": 0.88042203985932,
      "eval_PROFESSION-tp": 751.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.882051282051282,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8958333333333334,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8636363636363636,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 21.0,
      "eval_WORK_OF_ART-precision": 0.8189655172413793,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7649672050327764,
      "eval_macro-f1": 0.7649672050327764,
      "eval_macro-precision": 0.7786470517329451,
      "eval_macro-recall": 0.7619080334923971,
      "eval_micro-f1": 0.8435632808256383,
      "eval_micro-precision": 0.8457070248683972,
      "eval_micro-recall": 0.8414303774607188,
      "eval_precision": 0.7786470517329451,
      "eval_recall": 0.7619080334923971,
      "step": 2800
    },
    {
      "epoch": 28.38,
      "learning_rate": 1.67092803030303e-05,
      "loss": 0.0446,
      "step": 2810
    },
    {
      "epoch": 28.48,
      "learning_rate": 1.6661931818181818e-05,
      "loss": 0.0421,
      "step": 2820
    },
    {
      "epoch": 28.59,
      "learning_rate": 1.6614583333333332e-05,
      "loss": 0.0457,
      "step": 2830
    },
    {
      "epoch": 28.69,
      "learning_rate": 1.656723484848485e-05,
      "loss": 0.0463,
      "step": 2840
    },
    {
      "epoch": 28.79,
      "learning_rate": 1.6519886363636363e-05,
      "loss": 0.0493,
      "step": 2850
    },
    {
      "epoch": 28.89,
      "learning_rate": 1.6472537878787877e-05,
      "loss": 0.044,
      "step": 2860
    },
    {
      "epoch": 28.99,
      "learning_rate": 1.6425189393939394e-05,
      "loss": 0.0452,
      "step": 2870
    },
    {
      "epoch": 29.09,
      "learning_rate": 1.6377840909090908e-05,
      "loss": 0.0439,
      "step": 2880
    },
    {
      "epoch": 29.19,
      "learning_rate": 1.6330492424242425e-05,
      "loss": 0.0439,
      "step": 2890
    },
    {
      "epoch": 29.29,
      "learning_rate": 1.628314393939394e-05,
      "loss": 0.0455,
      "step": 2900
    },
    {
      "epoch": 29.29,
      "eval_AGE-f1": 0.927536231884058,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 11.0,
      "eval_AGE-precision": 0.920863309352518,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7111111111111111,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 17.0,
      "eval_AWARD-precision": 0.6530612244897959,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9150943396226415,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8981481481481481,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9415121255349501,
      "eval_COUNTRY-fn": 25.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.953757225433526,
      "eval_COUNTRY-recall": 0.9295774647887324,
      "eval_COUNTRY-tp": 330.0,
      "eval_CRIME-f1": 0.4580152671755725,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 46.0,
      "eval_CRIME-precision": 0.39473684210526316,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8978805394990366,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 48.0,
      "eval_DATE-precision": 0.9066147859922179,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5535714285714286,
      "eval_DISEASE-fn": 50.0,
      "eval_DISEASE-fp": 50.0,
      "eval_DISEASE-precision": 0.5535714285714286,
      "eval_DISEASE-recall": 0.5535714285714286,
      "eval_DISEASE-tp": 62.0,
      "eval_DISTRICT-f1": 0.5641025641025641,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6538461538461539,
      "eval_EVENT-fn": 256.0,
      "eval_EVENT-fp": 194.0,
      "eval_EVENT-precision": 0.6865912762520194,
      "eval_EVENT-recall": 0.6240822320117474,
      "eval_EVENT-tp": 425.0,
      "eval_FACILITY-f1": 0.6,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 35.0,
      "eval_FACILITY-precision": 0.5930232558139535,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7605633802816901,
      "eval_IDEOLOGY-fn": 9.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7714285714285715,
      "eval_IDEOLOGY-recall": 0.75,
      "eval_IDEOLOGY-tp": 27.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.697986577181208,
      "eval_LAW-fn": 31.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.7878787878787878,
      "eval_LAW-recall": 0.6265060240963856,
      "eval_LAW-tp": 52.0,
      "eval_LOCATION-f1": 0.7868852459016393,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8275862068965517,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8524590163934426,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8125,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.7903225806451613,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 17.0,
      "eval_NATIONALITY-precision": 0.7424242424242424,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.880466472303207,
      "eval_NUMBER-fn": 33.0,
      "eval_NUMBER-fp": 8.0,
      "eval_NUMBER-precision": 0.949685534591195,
      "eval_NUMBER-recall": 0.8206521739130435,
      "eval_NUMBER-tp": 151.0,
      "eval_ORDINAL-f1": 0.8324873096446701,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.8541666666666666,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8537920250195465,
      "eval_ORGANIZATION-fn": 70.0,
      "eval_ORGANIZATION-fp": 117.0,
      "eval_ORGANIZATION-precision": 0.8235294117647058,
      "eval_ORGANIZATION-recall": 0.8863636363636364,
      "eval_ORGANIZATION-tp": 546.0,
      "eval_PENALTY-f1": 0.6730769230769231,
      "eval_PENALTY-fn": 22.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.7446808510638298,
      "eval_PENALTY-recall": 0.6140350877192983,
      "eval_PENALTY-tp": 35.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9673684210526315,
      "eval_PERSON-fn": 30.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9663512092534174,
      "eval_PERSON-recall": 0.9683877766069547,
      "eval_PERSON-tp": 919.0,
      "eval_PRODUCT-f1": 0.64,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 21.0,
      "eval_PRODUCT-precision": 0.5333333333333333,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8594563331405437,
      "eval_PROFESSION-fn": 110.0,
      "eval_PROFESSION-fp": 133.0,
      "eval_PROFESSION-precision": 0.8481735159817352,
      "eval_PROFESSION-recall": 0.8710433763188745,
      "eval_PROFESSION-tp": 743.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8969072164948454,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8571428571428571,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 20.0,
      "eval_WORK_OF_ART-precision": 0.8230088495575221,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.7651237346555988,
      "eval_macro-f1": 0.7651237346555988,
      "eval_macro-precision": 0.7706370174619828,
      "eval_macro-recall": 0.7694572859574896,
      "eval_micro-f1": 0.840841383045951,
      "eval_micro-precision": 0.8406137184115523,
      "eval_micro-recall": 0.8410691710312443,
      "eval_precision": 0.7706370174619828,
      "eval_recall": 0.7694572859574896,
      "step": 2900
    },
    {
      "epoch": 29.39,
      "learning_rate": 1.6235795454545453e-05,
      "loss": 0.0419,
      "step": 2910
    },
    {
      "epoch": 29.49,
      "learning_rate": 1.618844696969697e-05,
      "loss": 0.0426,
      "step": 2920
    },
    {
      "epoch": 29.6,
      "learning_rate": 1.6141098484848484e-05,
      "loss": 0.0485,
      "step": 2930
    },
    {
      "epoch": 29.7,
      "learning_rate": 1.609375e-05,
      "loss": 0.0436,
      "step": 2940
    },
    {
      "epoch": 29.8,
      "learning_rate": 1.6046401515151515e-05,
      "loss": 0.043,
      "step": 2950
    },
    {
      "epoch": 29.9,
      "learning_rate": 1.599905303030303e-05,
      "loss": 0.0446,
      "step": 2960
    },
    {
      "epoch": 30.0,
      "learning_rate": 1.5951704545454547e-05,
      "loss": 0.0441,
      "step": 2970
    },
    {
      "epoch": 30.1,
      "learning_rate": 1.590435606060606e-05,
      "loss": 0.0418,
      "step": 2980
    },
    {
      "epoch": 30.2,
      "learning_rate": 1.5857007575757578e-05,
      "loss": 0.0435,
      "step": 2990
    },
    {
      "epoch": 30.3,
      "learning_rate": 1.5809659090909092e-05,
      "loss": 0.0425,
      "step": 3000
    },
    {
      "epoch": 30.3,
      "eval_AGE-f1": 0.9136690647482014,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.900709219858156,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6746987951807228,
      "eval_AWARD-fn": 13.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6666666666666666,
      "eval_AWARD-recall": 0.6829268292682927,
      "eval_AWARD-tp": 28.0,
      "eval_CITY-f1": 0.9176470588235294,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8986175115207373,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9431818181818182,
      "eval_COUNTRY-fn": 23.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9512893982808023,
      "eval_COUNTRY-recall": 0.9352112676056338,
      "eval_COUNTRY-tp": 332.0,
      "eval_CRIME-f1": 0.49122807017543857,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 31.0,
      "eval_CRIME-precision": 0.4745762711864407,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.9025341130604289,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 39.0,
      "eval_DATE-precision": 0.9223107569721115,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.5288461538461539,
      "eval_DISEASE-fn": 57.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.5729166666666666,
      "eval_DISEASE-recall": 0.49107142857142855,
      "eval_DISEASE-tp": 55.0,
      "eval_DISTRICT-f1": 0.5945945945945946,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 9.0,
      "eval_DISTRICT-precision": 0.55,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6520031421838177,
      "eval_EVENT-fn": 266.0,
      "eval_EVENT-fp": 177.0,
      "eval_EVENT-precision": 0.7010135135135135,
      "eval_EVENT-recall": 0.6093979441997063,
      "eval_EVENT-tp": 415.0,
      "eval_FACILITY-f1": 0.5822784810126582,
      "eval_FACILITY-fn": 38.0,
      "eval_FACILITY-fp": 28.0,
      "eval_FACILITY-precision": 0.6216216216216216,
      "eval_FACILITY-recall": 0.5476190476190477,
      "eval_FACILITY-tp": 46.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6573426573426573,
      "eval_LAW-fn": 36.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.7833333333333333,
      "eval_LAW-recall": 0.5662650602409639,
      "eval_LAW-tp": 47.0,
      "eval_LOCATION-f1": 0.8067226890756303,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 7.0,
      "eval_LOCATION-precision": 0.8727272727272727,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8253968253968254,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 8.0,
      "eval_MONEY-precision": 0.7647058823529411,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.7967479674796748,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 16.0,
      "eval_NATIONALITY-precision": 0.7538461538461538,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.8901734104046243,
      "eval_NUMBER-fn": 30.0,
      "eval_NUMBER-fp": 8.0,
      "eval_NUMBER-precision": 0.9506172839506173,
      "eval_NUMBER-recall": 0.8369565217391305,
      "eval_NUMBER-tp": 154.0,
      "eval_ORDINAL-f1": 0.8247422680412371,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 13.0,
      "eval_ORDINAL-precision": 0.8602150537634409,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8575899843505478,
      "eval_ORGANIZATION-fn": 68.0,
      "eval_ORGANIZATION-fp": 114.0,
      "eval_ORGANIZATION-precision": 0.8277945619335347,
      "eval_ORGANIZATION-recall": 0.8896103896103896,
      "eval_ORGANIZATION-tp": 548.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7555555555555555,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9652265542676501,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 33.0,
      "eval_PERSON-precision": 0.9652265542676501,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.6571428571428571,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 17.0,
      "eval_PRODUCT-precision": 0.575,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8673708920187794,
      "eval_PROFESSION-fn": 114.0,
      "eval_PROFESSION-fp": 112.0,
      "eval_PROFESSION-precision": 0.8683901292596945,
      "eval_PROFESSION-recall": 0.8663540445486518,
      "eval_PROFESSION-tp": 739.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8969072164948454,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8135593220338984,
      "eval_TIME-fn": 5.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8,
      "eval_TIME-recall": 0.8275862068965517,
      "eval_TIME-tp": 24.0,
      "eval_WORK_OF_ART-f1": 0.8815165876777251,
      "eval_WORK_OF_ART-fn": 11.0,
      "eval_WORK_OF_ART-fp": 14.0,
      "eval_WORK_OF_ART-precision": 0.8691588785046729,
      "eval_WORK_OF_ART-recall": 0.8942307692307693,
      "eval_WORK_OF_ART-tp": 93.0,
      "eval_f1": 0.7636234907124112,
      "eval_macro-f1": 0.7636234907124112,
      "eval_macro-precision": 0.7824509755225937,
      "eval_macro-recall": 0.7537781203861658,
      "eval_micro-f1": 0.8438471384165296,
      "eval_micro-precision": 0.8544713941862618,
      "eval_micro-recall": 0.833483836012281,
      "eval_precision": 0.7824509755225937,
      "eval_recall": 0.7537781203861658,
      "step": 3000
    },
    {
      "epoch": 30.4,
      "learning_rate": 1.5762310606060606e-05,
      "loss": 0.0414,
      "step": 3010
    },
    {
      "epoch": 30.51,
      "learning_rate": 1.5714962121212123e-05,
      "loss": 0.0431,
      "step": 3020
    },
    {
      "epoch": 30.61,
      "learning_rate": 1.5667613636363637e-05,
      "loss": 0.0435,
      "step": 3030
    },
    {
      "epoch": 30.71,
      "learning_rate": 1.5620265151515154e-05,
      "loss": 0.0441,
      "step": 3040
    },
    {
      "epoch": 30.81,
      "learning_rate": 1.5572916666666668e-05,
      "loss": 0.0393,
      "step": 3050
    },
    {
      "epoch": 30.91,
      "learning_rate": 1.5525568181818185e-05,
      "loss": 0.0449,
      "step": 3060
    },
    {
      "epoch": 31.01,
      "learning_rate": 1.54782196969697e-05,
      "loss": 0.0388,
      "step": 3070
    },
    {
      "epoch": 31.11,
      "learning_rate": 1.5430871212121213e-05,
      "loss": 0.0408,
      "step": 3080
    },
    {
      "epoch": 31.21,
      "learning_rate": 1.5383522727272727e-05,
      "loss": 0.0405,
      "step": 3090
    },
    {
      "epoch": 31.31,
      "learning_rate": 1.533617424242424e-05,
      "loss": 0.0403,
      "step": 3100
    },
    {
      "epoch": 31.31,
      "eval_AGE-f1": 0.9202898550724637,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9136690647482014,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7380952380952381,
      "eval_AWARD-fn": 10.0,
      "eval_AWARD-fp": 12.0,
      "eval_AWARD-precision": 0.7209302325581395,
      "eval_AWARD-recall": 0.7560975609756098,
      "eval_AWARD-tp": 31.0,
      "eval_CITY-f1": 0.9125295508274232,
      "eval_CITY-fn": 15.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8976744186046511,
      "eval_CITY-recall": 0.9278846153846154,
      "eval_CITY-tp": 193.0,
      "eval_COUNTRY-f1": 0.9460227272727273,
      "eval_COUNTRY-fn": 22.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.9541547277936963,
      "eval_COUNTRY-recall": 0.9380281690140845,
      "eval_COUNTRY-tp": 333.0,
      "eval_CRIME-f1": 0.4576271186440678,
      "eval_CRIME-fn": 28.0,
      "eval_CRIME-fp": 36.0,
      "eval_CRIME-precision": 0.42857142857142855,
      "eval_CRIME-recall": 0.4909090909090909,
      "eval_CRIME-tp": 27.0,
      "eval_DATE-f1": 0.896887159533074,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 43.0,
      "eval_DATE-precision": 0.9146825396825397,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.5217391304347826,
      "eval_DISEASE-fn": 58.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.5684210526315789,
      "eval_DISEASE-recall": 0.48214285714285715,
      "eval_DISEASE-tp": 54.0,
      "eval_DISTRICT-f1": 0.5789473684210527,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5238095238095238,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.655035685963521,
      "eval_EVENT-fn": 268.0,
      "eval_EVENT-fp": 167.0,
      "eval_EVENT-precision": 0.7120689655172414,
      "eval_EVENT-recall": 0.6064610866372981,
      "eval_EVENT-tp": 413.0,
      "eval_FACILITY-f1": 0.6035502958579881,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 34.0,
      "eval_FACILITY-precision": 0.6,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7114093959731543,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.803030303030303,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7933884297520661,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8421052631578947,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.847457627118644,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8333333333333334,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8099173553719008,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 14.0,
      "eval_NATIONALITY-precision": 0.7777777777777778,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.899135446685879,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9570552147239264,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8223350253807107,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 15.0,
      "eval_ORDINAL-precision": 0.84375,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8628072957969866,
      "eval_ORGANIZATION-fn": 72.0,
      "eval_ORGANIZATION-fp": 101.0,
      "eval_ORGANIZATION-precision": 0.8434108527131783,
      "eval_ORGANIZATION-recall": 0.8831168831168831,
      "eval_ORGANIZATION-tp": 544.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7555555555555555,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9657353716394307,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9662447257383966,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.5925925925925926,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 27.0,
      "eval_PRODUCT-precision": 0.47058823529411764,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8650559811431938,
      "eval_PROFESSION-fn": 119.0,
      "eval_PROFESSION-fp": 110.0,
      "eval_PROFESSION-precision": 0.8696682464454977,
      "eval_PROFESSION-recall": 0.8604923798358733,
      "eval_PROFESSION-tp": 734.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8762886597938144,
      "eval_STATE_OR_PROVINCE-fn": 14.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8947368421052632,
      "eval_STATE_OR_PROVINCE-recall": 0.8585858585858586,
      "eval_STATE_OR_PROVINCE-tp": 85.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8544600938967136,
      "eval_WORK_OF_ART-fn": 13.0,
      "eval_WORK_OF_ART-fp": 18.0,
      "eval_WORK_OF_ART-precision": 0.8348623853211009,
      "eval_WORK_OF_ART-recall": 0.875,
      "eval_WORK_OF_ART-tp": 91.0,
      "eval_f1": 0.7647501227648413,
      "eval_macro-f1": 0.7647501227648413,
      "eval_macro-precision": 0.7800148651688056,
      "eval_macro-recall": 0.7595242273377325,
      "eval_micro-f1": 0.8438671910728985,
      "eval_micro-precision": 0.8548925129725723,
      "eval_micro-recall": 0.8331226295828066,
      "eval_precision": 0.7800148651688056,
      "eval_recall": 0.7595242273377325,
      "step": 3100
    },
    {
      "epoch": 31.41,
      "learning_rate": 1.5288825757575758e-05,
      "loss": 0.0425,
      "step": 3110
    },
    {
      "epoch": 31.52,
      "learning_rate": 1.5241477272727274e-05,
      "loss": 0.0417,
      "step": 3120
    },
    {
      "epoch": 31.62,
      "learning_rate": 1.5194128787878788e-05,
      "loss": 0.0373,
      "step": 3130
    },
    {
      "epoch": 31.72,
      "learning_rate": 1.5146780303030305e-05,
      "loss": 0.0444,
      "step": 3140
    },
    {
      "epoch": 31.82,
      "learning_rate": 1.5099431818181819e-05,
      "loss": 0.0416,
      "step": 3150
    },
    {
      "epoch": 31.92,
      "learning_rate": 1.5052083333333334e-05,
      "loss": 0.0409,
      "step": 3160
    },
    {
      "epoch": 32.02,
      "learning_rate": 1.5004734848484848e-05,
      "loss": 0.0428,
      "step": 3170
    },
    {
      "epoch": 32.12,
      "learning_rate": 1.4957386363636364e-05,
      "loss": 0.0376,
      "step": 3180
    },
    {
      "epoch": 32.22,
      "learning_rate": 1.491003787878788e-05,
      "loss": 0.0393,
      "step": 3190
    },
    {
      "epoch": 32.32,
      "learning_rate": 1.4862689393939393e-05,
      "loss": 0.0409,
      "step": 3200
    },
    {
      "epoch": 32.32,
      "eval_AGE-f1": 0.9175627240143369,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.9014084507042254,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7058823529411765,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6818181818181818,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9125295508274232,
      "eval_CITY-fn": 15.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8976744186046511,
      "eval_CITY-recall": 0.9278846153846154,
      "eval_CITY-tp": 193.0,
      "eval_COUNTRY-f1": 0.9451476793248945,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 20.0,
      "eval_COUNTRY-precision": 0.9438202247191011,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.4793388429752066,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 37.0,
      "eval_CRIME-precision": 0.4393939393939394,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8995121951219512,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 40.0,
      "eval_DATE-precision": 0.9201596806387226,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.5170731707317073,
      "eval_DISEASE-fn": 59.0,
      "eval_DISEASE-fp": 40.0,
      "eval_DISEASE-precision": 0.5698924731182796,
      "eval_DISEASE-recall": 0.4732142857142857,
      "eval_DISEASE-tp": 53.0,
      "eval_DISTRICT-f1": 0.5405405405405406,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6485647788983708,
      "eval_EVENT-fn": 263.0,
      "eval_EVENT-fp": 190.0,
      "eval_EVENT-precision": 0.6875,
      "eval_EVENT-recall": 0.6138032305433186,
      "eval_EVENT-tp": 418.0,
      "eval_FACILITY-f1": 0.6024096385542169,
      "eval_FACILITY-fn": 34.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6097560975609756,
      "eval_FACILITY-recall": 0.5952380952380952,
      "eval_FACILITY-tp": 50.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6967741935483871,
      "eval_LAW-fn": 29.0,
      "eval_LAW-fp": 18.0,
      "eval_LAW-precision": 0.75,
      "eval_LAW-recall": 0.6506024096385542,
      "eval_LAW-tp": 54.0,
      "eval_LOCATION-f1": 0.773109243697479,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8363636363636363,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.8387096774193549,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.7878787878787878,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8173913043478261,
      "eval_NATIONALITY-fn": 11.0,
      "eval_NATIONALITY-fp": 10.0,
      "eval_NATIONALITY-precision": 0.8245614035087719,
      "eval_NATIONALITY-recall": 0.8103448275862069,
      "eval_NATIONALITY-tp": 47.0,
      "eval_NUMBER-f1": 0.8927536231884058,
      "eval_NUMBER-fn": 30.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9565217391304348,
      "eval_NUMBER-recall": 0.8369565217391305,
      "eval_NUMBER-tp": 154.0,
      "eval_ORDINAL-f1": 0.8393782383419689,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8804347826086957,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8610223642172524,
      "eval_ORGANIZATION-fn": 77.0,
      "eval_ORGANIZATION-fp": 97.0,
      "eval_ORGANIZATION-precision": 0.8474842767295597,
      "eval_ORGANIZATION-recall": 0.875,
      "eval_ORGANIZATION-tp": 539.0,
      "eval_PENALTY-f1": 0.6601941747572816,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.7391304347826086,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.965662968832541,
      "eval_PERSON-fn": 35.0,
      "eval_PERSON-fp": 30.0,
      "eval_PERSON-precision": 0.9682203389830508,
      "eval_PERSON-recall": 0.9631190727081138,
      "eval_PERSON-tp": 914.0,
      "eval_PRODUCT-f1": 0.5897435897435898,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 25.0,
      "eval_PRODUCT-precision": 0.4791666666666667,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8598351001177856,
      "eval_PROFESSION-fn": 123.0,
      "eval_PROFESSION-fp": 115.0,
      "eval_PROFESSION-precision": 0.863905325443787,
      "eval_PROFESSION-recall": 0.8558030480656507,
      "eval_PROFESSION-tp": 730.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8775510204081632,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8865979381443299,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.8275862068965517,
      "eval_TIME-fn": 5.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8275862068965517,
      "eval_TIME-recall": 0.8275862068965517,
      "eval_TIME-tp": 24.0,
      "eval_WORK_OF_ART-f1": 0.8584474885844748,
      "eval_WORK_OF_ART-fn": 10.0,
      "eval_WORK_OF_ART-fp": 21.0,
      "eval_WORK_OF_ART-precision": 0.8173913043478261,
      "eval_WORK_OF_ART-recall": 0.9038461538461539,
      "eval_WORK_OF_ART-tp": 94.0,
      "eval_f1": 0.7607724405998347,
      "eval_macro-f1": 0.7607724405998347,
      "eval_macro-precision": 0.7752197307033009,
      "eval_macro-recall": 0.7554399049591345,
      "eval_micro-f1": 0.841153916377579,
      "eval_micro-precision": 0.8504707402621378,
      "eval_micro-recall": 0.8320390102943832,
      "eval_precision": 0.7752197307033009,
      "eval_recall": 0.7554399049591345,
      "step": 3200
    },
    {
      "epoch": 32.42,
      "learning_rate": 1.4815340909090909e-05,
      "loss": 0.0428,
      "step": 3210
    },
    {
      "epoch": 32.53,
      "learning_rate": 1.4767992424242425e-05,
      "loss": 0.0381,
      "step": 3220
    },
    {
      "epoch": 32.63,
      "learning_rate": 1.472064393939394e-05,
      "loss": 0.0406,
      "step": 3230
    },
    {
      "epoch": 32.73,
      "learning_rate": 1.4673295454545456e-05,
      "loss": 0.039,
      "step": 3240
    },
    {
      "epoch": 32.83,
      "learning_rate": 1.462594696969697e-05,
      "loss": 0.0448,
      "step": 3250
    },
    {
      "epoch": 32.93,
      "learning_rate": 1.4578598484848485e-05,
      "loss": 0.0389,
      "step": 3260
    },
    {
      "epoch": 33.03,
      "learning_rate": 1.453125e-05,
      "loss": 0.0402,
      "step": 3270
    },
    {
      "epoch": 33.13,
      "learning_rate": 1.4483901515151516e-05,
      "loss": 0.0417,
      "step": 3280
    },
    {
      "epoch": 33.23,
      "learning_rate": 1.4436553030303032e-05,
      "loss": 0.0373,
      "step": 3290
    },
    {
      "epoch": 33.33,
      "learning_rate": 1.4389204545454546e-05,
      "loss": 0.0382,
      "step": 3300
    },
    {
      "epoch": 33.33,
      "eval_AGE-f1": 0.924187725631769,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9142857142857143,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7191011235955056,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 16.0,
      "eval_AWARD-precision": 0.6666666666666666,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9154929577464789,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8944954128440367,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9478138222849083,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9491525423728814,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.45901639344262296,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 39.0,
      "eval_CRIME-precision": 0.417910447761194,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.896887159533074,
      "eval_DATE-fn": 63.0,
      "eval_DATE-fp": 43.0,
      "eval_DATE-precision": 0.9146825396825397,
      "eval_DATE-recall": 0.8797709923664122,
      "eval_DATE-tp": 461.0,
      "eval_DISEASE-f1": 0.5570776255707762,
      "eval_DISEASE-fn": 51.0,
      "eval_DISEASE-fp": 46.0,
      "eval_DISEASE-precision": 0.5700934579439252,
      "eval_DISEASE-recall": 0.5446428571428571,
      "eval_DISEASE-tp": 61.0,
      "eval_DISTRICT-f1": 0.5641025641025641,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6605504587155964,
      "eval_EVENT-fn": 249.0,
      "eval_EVENT-fp": 195.0,
      "eval_EVENT-precision": 0.6889952153110048,
      "eval_EVENT-recall": 0.6343612334801763,
      "eval_EVENT-tp": 432.0,
      "eval_FACILITY-f1": 0.6153846153846154,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 33.0,
      "eval_FACILITY-precision": 0.611764705882353,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7323943661971831,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 9.0,
      "eval_IDEOLOGY-precision": 0.7428571428571429,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7239263803680982,
      "eval_LAW-fn": 24.0,
      "eval_LAW-fp": 21.0,
      "eval_LAW-precision": 0.7375,
      "eval_LAW-recall": 0.7108433734939759,
      "eval_LAW-tp": 59.0,
      "eval_LOCATION-f1": 0.7967479674796748,
      "eval_LOCATION-fn": 15.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8305084745762712,
      "eval_LOCATION-recall": 0.765625,
      "eval_LOCATION-tp": 49.0,
      "eval_MONEY-f1": 0.8524590163934426,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8125,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.7894736842105263,
      "eval_NATIONALITY-fn": 13.0,
      "eval_NATIONALITY-fp": 11.0,
      "eval_NATIONALITY-precision": 0.8035714285714286,
      "eval_NATIONALITY-recall": 0.7758620689655172,
      "eval_NATIONALITY-tp": 45.0,
      "eval_NUMBER-f1": 0.8914956011730205,
      "eval_NUMBER-fn": 32.0,
      "eval_NUMBER-fp": 5.0,
      "eval_NUMBER-precision": 0.9681528662420382,
      "eval_NUMBER-recall": 0.8260869565217391,
      "eval_NUMBER-tp": 152.0,
      "eval_ORDINAL-f1": 0.8367346938775511,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 13.0,
      "eval_ORDINAL-precision": 0.8631578947368421,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8717131474103585,
      "eval_ORGANIZATION-fn": 69.0,
      "eval_ORGANIZATION-fp": 92.0,
      "eval_ORGANIZATION-precision": 0.8560250391236307,
      "eval_ORGANIZATION-recall": 0.887987012987013,
      "eval_ORGANIZATION-tp": 547.0,
      "eval_PENALTY-f1": 0.6796116504854369,
      "eval_PENALTY-fn": 22.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7608695652173914,
      "eval_PENALTY-recall": 0.6140350877192983,
      "eval_PENALTY-tp": 35.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.96723044397463,
      "eval_PERSON-fn": 34.0,
      "eval_PERSON-fp": 28.0,
      "eval_PERSON-precision": 0.9703075291622482,
      "eval_PERSON-recall": 0.964172813487882,
      "eval_PERSON-tp": 915.0,
      "eval_PRODUCT-f1": 0.5333333333333333,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 36.0,
      "eval_PRODUCT-precision": 0.4,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8619102416570771,
      "eval_PROFESSION-fn": 104.0,
      "eval_PROFESSION-fp": 136.0,
      "eval_PROFESSION-precision": 0.8463276836158192,
      "eval_PROFESSION-recall": 0.8780773739742087,
      "eval_PROFESSION-tp": 749.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8775510204081632,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8865979381443299,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8430493273542601,
      "eval_WORK_OF_ART-fn": 10.0,
      "eval_WORK_OF_ART-fp": 25.0,
      "eval_WORK_OF_ART-precision": 0.7899159663865546,
      "eval_WORK_OF_ART-recall": 0.9038461538461539,
      "eval_WORK_OF_ART-tp": 94.0,
      "eval_f1": 0.7590369437414463,
      "eval_macro-f1": 0.7590369437414463,
      "eval_macro-precision": 0.7665403987833568,
      "eval_macro-recall": 0.7637677213920079,
      "eval_micro-f1": 0.8439504834191741,
      "eval_micro-precision": 0.8444846292947559,
      "eval_micro-recall": 0.8434170128228282,
      "eval_precision": 0.7665403987833568,
      "eval_recall": 0.7637677213920079,
      "step": 3300
    },
    {
      "epoch": 33.43,
      "learning_rate": 1.434185606060606e-05,
      "loss": 0.0388,
      "step": 3310
    },
    {
      "epoch": 33.54,
      "learning_rate": 1.4294507575757575e-05,
      "loss": 0.0414,
      "step": 3320
    },
    {
      "epoch": 33.64,
      "learning_rate": 1.4247159090909091e-05,
      "loss": 0.0372,
      "step": 3330
    },
    {
      "epoch": 33.74,
      "learning_rate": 1.4199810606060607e-05,
      "loss": 0.0382,
      "step": 3340
    },
    {
      "epoch": 33.84,
      "learning_rate": 1.415246212121212e-05,
      "loss": 0.0406,
      "step": 3350
    },
    {
      "epoch": 33.94,
      "learning_rate": 1.4105113636363636e-05,
      "loss": 0.0366,
      "step": 3360
    },
    {
      "epoch": 34.04,
      "learning_rate": 1.4057765151515152e-05,
      "loss": 0.036,
      "step": 3370
    },
    {
      "epoch": 34.14,
      "learning_rate": 1.4010416666666667e-05,
      "loss": 0.0396,
      "step": 3380
    },
    {
      "epoch": 34.24,
      "learning_rate": 1.3963068181818183e-05,
      "loss": 0.0374,
      "step": 3390
    },
    {
      "epoch": 34.34,
      "learning_rate": 1.3915719696969698e-05,
      "loss": 0.0378,
      "step": 3400
    },
    {
      "epoch": 34.34,
      "eval_AGE-f1": 0.9264705882352942,
      "eval_AGE-fn": 11.0,
      "eval_AGE-fp": 9.0,
      "eval_AGE-precision": 0.9333333333333333,
      "eval_AGE-recall": 0.9197080291970803,
      "eval_AGE-tp": 126.0,
      "eval_AWARD-f1": 0.6904761904761905,
      "eval_AWARD-fn": 12.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6744186046511628,
      "eval_AWARD-recall": 0.7073170731707317,
      "eval_AWARD-tp": 29.0,
      "eval_CITY-f1": 0.9150943396226415,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8981481481481481,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9449929478138223,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 19.0,
      "eval_COUNTRY-precision": 0.9463276836158192,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.4918032786885246,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 37.0,
      "eval_CRIME-precision": 0.44776119402985076,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8962172647914646,
      "eval_DATE-fn": 62.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9112426035502958,
      "eval_DATE-recall": 0.8816793893129771,
      "eval_DATE-tp": 462.0,
      "eval_DISEASE-f1": 0.5480769230769231,
      "eval_DISEASE-fn": 55.0,
      "eval_DISEASE-fp": 39.0,
      "eval_DISEASE-precision": 0.59375,
      "eval_DISEASE-recall": 0.5089285714285714,
      "eval_DISEASE-tp": 57.0,
      "eval_DISTRICT-f1": 0.5882352941176471,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 7.0,
      "eval_DISTRICT-precision": 0.5882352941176471,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6570281124497992,
      "eval_EVENT-fn": 272.0,
      "eval_EVENT-fp": 155.0,
      "eval_EVENT-precision": 0.725177304964539,
      "eval_EVENT-recall": 0.6005873715124816,
      "eval_EVENT-tp": 409.0,
      "eval_FACILITY-f1": 0.6071428571428571,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 33.0,
      "eval_FACILITY-precision": 0.6071428571428571,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7761194029850746,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.8387096774193549,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.6938775510204082,
      "eval_LAW-fn": 32.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.796875,
      "eval_LAW-recall": 0.6144578313253012,
      "eval_LAW-tp": 51.0,
      "eval_LOCATION-f1": 0.7933884297520661,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8421052631578947,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8813559322033898,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8666666666666667,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8347826086956521,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 9.0,
      "eval_NATIONALITY-precision": 0.8421052631578947,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.8985507246376812,
      "eval_NUMBER-fn": 29.0,
      "eval_NUMBER-fp": 6.0,
      "eval_NUMBER-precision": 0.9627329192546584,
      "eval_NUMBER-recall": 0.842391304347826,
      "eval_NUMBER-tp": 155.0,
      "eval_ORDINAL-f1": 0.8290155440414507,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 12.0,
      "eval_ORDINAL-precision": 0.8695652173913043,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8665594855305466,
      "eval_ORGANIZATION-fn": 77.0,
      "eval_ORGANIZATION-fp": 89.0,
      "eval_ORGANIZATION-precision": 0.85828025477707,
      "eval_ORGANIZATION-recall": 0.875,
      "eval_ORGANIZATION-tp": 539.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7555555555555555,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9676735559088501,
      "eval_PERSON-fn": 36.0,
      "eval_PERSON-fp": 25.0,
      "eval_PERSON-precision": 0.9733475479744137,
      "eval_PERSON-recall": 0.9620653319283456,
      "eval_PERSON-tp": 913.0,
      "eval_PRODUCT-f1": 0.5411764705882353,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 32.0,
      "eval_PRODUCT-precision": 0.41818181818181815,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8631090487238979,
      "eval_PROFESSION-fn": 109.0,
      "eval_PROFESSION-fp": 127.0,
      "eval_PROFESSION-precision": 0.8541905855338691,
      "eval_PROFESSION-recall": 0.8722157092614302,
      "eval_PROFESSION-tp": 744.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.882051282051282,
      "eval_STATE_OR_PROVINCE-fn": 13.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8958333333333334,
      "eval_STATE_OR_PROVINCE-recall": 0.8686868686868687,
      "eval_STATE_OR_PROVINCE-tp": 86.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8597285067873304,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 22.0,
      "eval_WORK_OF_ART-precision": 0.811965811965812,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7625661742820334,
      "eval_macro-f1": 0.7625661742820334,
      "eval_macro-precision": 0.784309836939884,
      "eval_macro-recall": 0.7526180567198104,
      "eval_micro-f1": 0.8456535678299899,
      "eval_micro-precision": 0.857992565055762,
      "eval_micro-recall": 0.8336644392270183,
      "eval_precision": 0.784309836939884,
      "eval_recall": 0.7526180567198104,
      "step": 3400
    },
    {
      "epoch": 34.44,
      "learning_rate": 1.3868371212121212e-05,
      "loss": 0.0365,
      "step": 3410
    },
    {
      "epoch": 34.55,
      "learning_rate": 1.3821022727272728e-05,
      "loss": 0.042,
      "step": 3420
    },
    {
      "epoch": 34.65,
      "learning_rate": 1.3773674242424244e-05,
      "loss": 0.0407,
      "step": 3430
    },
    {
      "epoch": 34.75,
      "learning_rate": 1.3726325757575759e-05,
      "loss": 0.0377,
      "step": 3440
    },
    {
      "epoch": 34.85,
      "learning_rate": 1.3678977272727273e-05,
      "loss": 0.0377,
      "step": 3450
    },
    {
      "epoch": 34.95,
      "learning_rate": 1.3631628787878787e-05,
      "loss": 0.0379,
      "step": 3460
    },
    {
      "epoch": 35.05,
      "learning_rate": 1.3584280303030303e-05,
      "loss": 0.0379,
      "step": 3470
    },
    {
      "epoch": 35.15,
      "learning_rate": 1.3536931818181818e-05,
      "loss": 0.035,
      "step": 3480
    },
    {
      "epoch": 35.25,
      "learning_rate": 1.3489583333333334e-05,
      "loss": 0.0367,
      "step": 3490
    },
    {
      "epoch": 35.35,
      "learning_rate": 1.344223484848485e-05,
      "loss": 0.0358,
      "step": 3500
    },
    {
      "epoch": 35.35,
      "eval_AGE-f1": 0.920863309352518,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 13.0,
      "eval_AGE-precision": 0.9078014184397163,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.6746987951807228,
      "eval_AWARD-fn": 13.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6666666666666666,
      "eval_AWARD-recall": 0.6829268292682927,
      "eval_AWARD-tp": 28.0,
      "eval_CITY-f1": 0.9205607476635514,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8954545454545455,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.9490084985835694,
      "eval_COUNTRY-fn": 20.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.9544159544159544,
      "eval_COUNTRY-recall": 0.9436619718309859,
      "eval_COUNTRY-tp": 335.0,
      "eval_CRIME-f1": 0.4715447154471545,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 39.0,
      "eval_CRIME-precision": 0.4264705882352941,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.9000969932104753,
      "eval_DATE-fn": 60.0,
      "eval_DATE-fp": 43.0,
      "eval_DATE-precision": 0.9151873767258383,
      "eval_DATE-recall": 0.8854961832061069,
      "eval_DATE-tp": 464.0,
      "eval_DISEASE-f1": 0.5096153846153846,
      "eval_DISEASE-fn": 59.0,
      "eval_DISEASE-fp": 43.0,
      "eval_DISEASE-precision": 0.5520833333333334,
      "eval_DISEASE-recall": 0.4732142857142857,
      "eval_DISEASE-tp": 53.0,
      "eval_DISTRICT-f1": 0.5882352941176471,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 7.0,
      "eval_DISTRICT-precision": 0.5882352941176471,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.6651090342679128,
      "eval_EVENT-fn": 254.0,
      "eval_EVENT-fp": 176.0,
      "eval_EVENT-precision": 0.7081260364842454,
      "eval_EVENT-recall": 0.6270190895741556,
      "eval_EVENT-tp": 427.0,
      "eval_FACILITY-f1": 0.6012269938650306,
      "eval_FACILITY-fn": 35.0,
      "eval_FACILITY-fp": 30.0,
      "eval_FACILITY-precision": 0.620253164556962,
      "eval_FACILITY-recall": 0.5833333333333334,
      "eval_FACILITY-tp": 49.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7647058823529411,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 6.0,
      "eval_IDEOLOGY-precision": 0.8125,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7066666666666667,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.7910447761194029,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7868852459016393,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8275862068965517,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8620689655172413,
      "eval_MONEY-fn": 4.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8620689655172413,
      "eval_MONEY-recall": 0.8620689655172413,
      "eval_MONEY-tp": 25.0,
      "eval_NATIONALITY-f1": 0.8205128205128205,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 11.0,
      "eval_NATIONALITY-precision": 0.8135593220338984,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.9048991354466859,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 6.0,
      "eval_NUMBER-precision": 0.9631901840490797,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.837696335078534,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 10.0,
      "eval_ORDINAL-precision": 0.8888888888888888,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8635275339185954,
      "eval_ORGANIZATION-fn": 75.0,
      "eval_ORGANIZATION-fp": 96.0,
      "eval_ORGANIZATION-precision": 0.8492935635792779,
      "eval_ORGANIZATION-recall": 0.8782467532467533,
      "eval_ORGANIZATION-tp": 541.0,
      "eval_PENALTY-f1": 0.6732673267326733,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.7727272727272727,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9661733615221987,
      "eval_PERSON-fn": 35.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9692470837751855,
      "eval_PERSON-recall": 0.9631190727081138,
      "eval_PERSON-tp": 914.0,
      "eval_PRODUCT-f1": 0.5274725274725275,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 37.0,
      "eval_PRODUCT-precision": 0.39344262295081966,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8653061224489796,
      "eval_PROFESSION-fn": 111.0,
      "eval_PROFESSION-fp": 120.0,
      "eval_PROFESSION-precision": 0.8607888631090487,
      "eval_PROFESSION-recall": 0.8698710433763188,
      "eval_PROFESSION-tp": 742.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8969072164948454,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8720379146919431,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 15.0,
      "eval_WORK_OF_ART-precision": 0.8598130841121495,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7598193363717071,
      "eval_macro-f1": 0.7598193363717071,
      "eval_macro-precision": 0.7803133021385242,
      "eval_macro-recall": 0.751728452143406,
      "eval_micro-f1": 0.8455996352029184,
      "eval_micro-precision": 0.8540899042004422,
      "eval_micro-recall": 0.8372765035217626,
      "eval_precision": 0.7803133021385242,
      "eval_recall": 0.751728452143406,
      "step": 3500
    },
    {
      "epoch": 35.45,
      "learning_rate": 1.3394886363636363e-05,
      "loss": 0.0381,
      "step": 3510
    },
    {
      "epoch": 35.56,
      "learning_rate": 1.3347537878787879e-05,
      "loss": 0.036,
      "step": 3520
    },
    {
      "epoch": 35.66,
      "learning_rate": 1.3300189393939394e-05,
      "loss": 0.0389,
      "step": 3530
    },
    {
      "epoch": 35.76,
      "learning_rate": 1.325284090909091e-05,
      "loss": 0.039,
      "step": 3540
    },
    {
      "epoch": 35.86,
      "learning_rate": 1.3205492424242426e-05,
      "loss": 0.0339,
      "step": 3550
    },
    {
      "epoch": 35.96,
      "learning_rate": 1.315814393939394e-05,
      "loss": 0.0384,
      "step": 3560
    },
    {
      "epoch": 36.06,
      "learning_rate": 1.3110795454545455e-05,
      "loss": 0.0369,
      "step": 3570
    },
    {
      "epoch": 36.16,
      "learning_rate": 1.306344696969697e-05,
      "loss": 0.037,
      "step": 3580
    },
    {
      "epoch": 36.26,
      "learning_rate": 1.3016098484848486e-05,
      "loss": 0.0367,
      "step": 3590
    },
    {
      "epoch": 36.36,
      "learning_rate": 1.296875e-05,
      "loss": 0.0374,
      "step": 3600
    },
    {
      "epoch": 36.36,
      "eval_AGE-f1": 0.9236363636363636,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 11.0,
      "eval_AGE-precision": 0.9202898550724637,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7228915662650602,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 12.0,
      "eval_AWARD-precision": 0.7142857142857143,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9205607476635514,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8954545454545455,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.9478138222849083,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 18.0,
      "eval_COUNTRY-precision": 0.9491525423728814,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.5,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 35.0,
      "eval_CRIME-precision": 0.46153846153846156,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.9022265246853823,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 43.0,
      "eval_DATE-precision": 0.9155206286836935,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5074626865671642,
      "eval_DISEASE-fn": 61.0,
      "eval_DISEASE-fp": 38.0,
      "eval_DISEASE-precision": 0.5730337078651685,
      "eval_DISEASE-recall": 0.45535714285714285,
      "eval_DISEASE-tp": 51.0,
      "eval_DISTRICT-f1": 0.5945945945945946,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 9.0,
      "eval_DISTRICT-precision": 0.55,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.656832298136646,
      "eval_EVENT-fn": 258.0,
      "eval_EVENT-fp": 184.0,
      "eval_EVENT-precision": 0.6968698517298187,
      "eval_EVENT-recall": 0.6211453744493393,
      "eval_EVENT-tp": 423.0,
      "eval_FACILITY-f1": 0.6219512195121951,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 29.0,
      "eval_FACILITY-precision": 0.6375,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7323943661971831,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 9.0,
      "eval_IDEOLOGY-precision": 0.7428571428571429,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7261146496815286,
      "eval_LAW-fn": 26.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.7702702702702703,
      "eval_LAW-recall": 0.6867469879518072,
      "eval_LAW-tp": 57.0,
      "eval_LOCATION-f1": 0.7933884297520661,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8421052631578947,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8813559322033898,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8666666666666667,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8135593220338984,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.8,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.899135446685879,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9570552147239264,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8393782383419689,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8804347826086957,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8653846153846154,
      "eval_ORGANIZATION-fn": 76.0,
      "eval_ORGANIZATION-fp": 92.0,
      "eval_ORGANIZATION-precision": 0.8544303797468354,
      "eval_ORGANIZATION-recall": 0.8766233766233766,
      "eval_ORGANIZATION-tp": 540.0,
      "eval_PENALTY-f1": 0.6732673267326733,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.7727272727272727,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9651898734177216,
      "eval_PERSON-fn": 34.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9662090813093981,
      "eval_PERSON-recall": 0.964172813487882,
      "eval_PERSON-tp": 915.0,
      "eval_PRODUCT-f1": 0.5274725274725275,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 37.0,
      "eval_PRODUCT-precision": 0.39344262295081966,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8627906976744186,
      "eval_PROFESSION-fn": 111.0,
      "eval_PROFESSION-fp": 125.0,
      "eval_PROFESSION-precision": 0.8558246828143022,
      "eval_PROFESSION-recall": 0.8698710433763188,
      "eval_PROFESSION-tp": 742.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883248730964467,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.847457627118644,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 5.0,
      "eval_TIME-precision": 0.8333333333333334,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8571428571428571,
      "eval_WORK_OF_ART-fn": 8.0,
      "eval_WORK_OF_ART-fp": 24.0,
      "eval_WORK_OF_ART-precision": 0.8,
      "eval_WORK_OF_ART-recall": 0.9230769230769231,
      "eval_WORK_OF_ART-tp": 96.0,
      "eval_f1": 0.7625040994897355,
      "eval_macro-f1": 0.7625040994897355,
      "eval_macro-precision": 0.77712955593828,
      "eval_macro-recall": 0.7603571613250573,
      "eval_micro-f1": 0.84521644234267,
      "eval_micro-precision": 0.8512548085729987,
      "eval_micro-recall": 0.8392631388838722,
      "eval_precision": 0.77712955593828,
      "eval_recall": 0.7603571613250573,
      "step": 3600
    },
    {
      "epoch": 36.46,
      "learning_rate": 1.2921401515151514e-05,
      "loss": 0.037,
      "step": 3610
    },
    {
      "epoch": 36.57,
      "learning_rate": 1.287405303030303e-05,
      "loss": 0.0357,
      "step": 3620
    },
    {
      "epoch": 36.67,
      "learning_rate": 1.2826704545454545e-05,
      "loss": 0.0361,
      "step": 3630
    },
    {
      "epoch": 36.77,
      "learning_rate": 1.277935606060606e-05,
      "loss": 0.0347,
      "step": 3640
    },
    {
      "epoch": 36.87,
      "learning_rate": 1.2732007575757576e-05,
      "loss": 0.0328,
      "step": 3650
    },
    {
      "epoch": 36.97,
      "learning_rate": 1.2684659090909092e-05,
      "loss": 0.0377,
      "step": 3660
    },
    {
      "epoch": 37.07,
      "learning_rate": 1.2637310606060606e-05,
      "loss": 0.0373,
      "step": 3670
    },
    {
      "epoch": 37.17,
      "learning_rate": 1.2589962121212121e-05,
      "loss": 0.0388,
      "step": 3680
    },
    {
      "epoch": 37.27,
      "learning_rate": 1.2542613636363637e-05,
      "loss": 0.034,
      "step": 3690
    },
    {
      "epoch": 37.37,
      "learning_rate": 1.2495265151515153e-05,
      "loss": 0.0364,
      "step": 3700
    },
    {
      "epoch": 37.37,
      "eval_AGE-f1": 0.927536231884058,
      "eval_AGE-fn": 9.0,
      "eval_AGE-fp": 11.0,
      "eval_AGE-precision": 0.920863309352518,
      "eval_AGE-recall": 0.9343065693430657,
      "eval_AGE-tp": 128.0,
      "eval_AWARD-f1": 0.7058823529411765,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6818181818181818,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9129411764705883,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8940092165898618,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9461756373937678,
      "eval_COUNTRY-fn": 21.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9515669515669516,
      "eval_COUNTRY-recall": 0.9408450704225352,
      "eval_COUNTRY-tp": 334.0,
      "eval_CRIME-f1": 0.46875,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 43.0,
      "eval_CRIME-precision": 0.410958904109589,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.9013539651837524,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 44.0,
      "eval_DATE-precision": 0.9137254901960784,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5238095238095238,
      "eval_DISEASE-fn": 57.0,
      "eval_DISEASE-fp": 43.0,
      "eval_DISEASE-precision": 0.5612244897959183,
      "eval_DISEASE-recall": 0.49107142857142855,
      "eval_DISEASE-tp": 55.0,
      "eval_DISTRICT-f1": 0.5641025641025641,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 11.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6593406593406593,
      "eval_EVENT-fn": 261.0,
      "eval_EVENT-fp": 173.0,
      "eval_EVENT-precision": 0.7082630691399663,
      "eval_EVENT-recall": 0.6167400881057269,
      "eval_EVENT-tp": 420.0,
      "eval_FACILITY-f1": 0.611764705882353,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 34.0,
      "eval_FACILITY-precision": 0.6046511627906976,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7761194029850746,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 5.0,
      "eval_IDEOLOGY-precision": 0.8387096774193549,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7074829931972789,
      "eval_LAW-fn": 31.0,
      "eval_LAW-fp": 12.0,
      "eval_LAW-precision": 0.8125,
      "eval_LAW-recall": 0.6265060240963856,
      "eval_LAW-tp": 52.0,
      "eval_LOCATION-f1": 0.7868852459016393,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8275862068965517,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8813559322033898,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8666666666666667,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8235294117647058,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.8032786885245902,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.9022988505747126,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9573170731707317,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8282828282828283,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 15.0,
      "eval_ORDINAL-precision": 0.845360824742268,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.8635275339185954,
      "eval_ORGANIZATION-fn": 75.0,
      "eval_ORGANIZATION-fp": 96.0,
      "eval_ORGANIZATION-precision": 0.8492935635792779,
      "eval_ORGANIZATION-recall": 0.8782467532467533,
      "eval_ORGANIZATION-tp": 541.0,
      "eval_PENALTY-f1": 0.6666666666666666,
      "eval_PENALTY-fn": 22.0,
      "eval_PENALTY-fp": 13.0,
      "eval_PENALTY-precision": 0.7291666666666666,
      "eval_PENALTY-recall": 0.6140350877192983,
      "eval_PENALTY-tp": 35.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.965662968832541,
      "eval_PERSON-fn": 35.0,
      "eval_PERSON-fp": 30.0,
      "eval_PERSON-precision": 0.9682203389830508,
      "eval_PERSON-recall": 0.9631190727081138,
      "eval_PERSON-tp": 914.0,
      "eval_PRODUCT-f1": 0.5925925925925926,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 27.0,
      "eval_PRODUCT-precision": 0.47058823529411764,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8625146886016452,
      "eval_PROFESSION-fn": 119.0,
      "eval_PROFESSION-fp": 115.0,
      "eval_PROFESSION-precision": 0.8645465253239105,
      "eval_PROFESSION-recall": 0.8604923798358733,
      "eval_PROFESSION-tp": 734.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8969072164948454,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.832579185520362,
      "eval_WORK_OF_ART-fn": 12.0,
      "eval_WORK_OF_ART-fp": 25.0,
      "eval_WORK_OF_ART-precision": 0.7863247863247863,
      "eval_WORK_OF_ART-recall": 0.8846153846153846,
      "eval_WORK_OF_ART-tp": 92.0,
      "eval_f1": 0.7663816041355794,
      "eval_macro-f1": 0.7663816041355794,
      "eval_macro-precision": 0.7782758227017176,
      "eval_macro-recall": 0.7651755164950051,
      "eval_micro-f1": 0.8442824601366743,
      "eval_micro-precision": 0.8519676351599853,
      "eval_micro-recall": 0.8367346938775511,
      "eval_precision": 0.7782758227017176,
      "eval_recall": 0.7651755164950051,
      "step": 3700
    },
    {
      "epoch": 37.47,
      "learning_rate": 1.2447916666666668e-05,
      "loss": 0.0349,
      "step": 3710
    },
    {
      "epoch": 37.58,
      "learning_rate": 1.2400568181818182e-05,
      "loss": 0.0362,
      "step": 3720
    },
    {
      "epoch": 37.68,
      "learning_rate": 1.2353219696969698e-05,
      "loss": 0.0377,
      "step": 3730
    },
    {
      "epoch": 37.78,
      "learning_rate": 1.2305871212121212e-05,
      "loss": 0.0349,
      "step": 3740
    },
    {
      "epoch": 37.88,
      "learning_rate": 1.2258522727272727e-05,
      "loss": 0.0345,
      "step": 3750
    },
    {
      "epoch": 37.98,
      "learning_rate": 1.2211174242424243e-05,
      "loss": 0.0363,
      "step": 3760
    },
    {
      "epoch": 38.08,
      "learning_rate": 1.2163825757575757e-05,
      "loss": 0.0337,
      "step": 3770
    },
    {
      "epoch": 38.18,
      "learning_rate": 1.2116477272727272e-05,
      "loss": 0.0337,
      "step": 3780
    },
    {
      "epoch": 38.28,
      "learning_rate": 1.2069128787878788e-05,
      "loss": 0.0352,
      "step": 3790
    },
    {
      "epoch": 38.38,
      "learning_rate": 1.2021780303030304e-05,
      "loss": 0.0384,
      "step": 3800
    },
    {
      "epoch": 38.38,
      "eval_AGE-f1": 0.9169675090252708,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 13.0,
      "eval_AGE-precision": 0.9071428571428571,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6818181818181818,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 17.0,
      "eval_AWARD-precision": 0.6382978723404256,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.92018779342723,
      "eval_CITY-fn": 12.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8990825688073395,
      "eval_CITY-recall": 0.9423076923076923,
      "eval_CITY-tp": 196.0,
      "eval_COUNTRY-f1": 0.9460227272727273,
      "eval_COUNTRY-fn": 22.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.9541547277936963,
      "eval_COUNTRY-recall": 0.9380281690140845,
      "eval_COUNTRY-tp": 333.0,
      "eval_CRIME-f1": 0.48333333333333334,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 36.0,
      "eval_CRIME-precision": 0.4461538461538462,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8996138996138996,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 46.0,
      "eval_DATE-precision": 0.91015625,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5377358490566038,
      "eval_DISEASE-fn": 55.0,
      "eval_DISEASE-fp": 43.0,
      "eval_DISEASE-precision": 0.57,
      "eval_DISEASE-recall": 0.5089285714285714,
      "eval_DISEASE-tp": 57.0,
      "eval_DISTRICT-f1": 0.5945945945945946,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 9.0,
      "eval_DISTRICT-precision": 0.55,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6666666666666666,
      "eval_EVENT-fn": 236.0,
      "eval_EVENT-fp": 209.0,
      "eval_EVENT-precision": 0.6804281345565749,
      "eval_EVENT-recall": 0.6534508076358296,
      "eval_EVENT-tp": 445.0,
      "eval_FACILITY-f1": 0.6024096385542169,
      "eval_FACILITY-fn": 34.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6097560975609756,
      "eval_FACILITY-recall": 0.5952380952380952,
      "eval_FACILITY-tp": 50.0,
      "eval_FAMILY-f1": 0.6666666666666666,
      "eval_FAMILY-fn": 2.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6666666666666666,
      "eval_FAMILY-recall": 0.6666666666666666,
      "eval_FAMILY-tp": 4.0,
      "eval_IDEOLOGY-f1": 0.7323943661971831,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 9.0,
      "eval_IDEOLOGY-precision": 0.7428571428571429,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.72,
      "eval_LAW-fn": 29.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.8059701492537313,
      "eval_LAW-recall": 0.6506024096385542,
      "eval_LAW-tp": 54.0,
      "eval_LOCATION-f1": 0.7768595041322314,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8245614035087719,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.8666666666666667,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8387096774193549,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.784,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 18.0,
      "eval_NATIONALITY-precision": 0.7313432835820896,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.9054441260744985,
      "eval_NUMBER-fn": 26.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9575757575757575,
      "eval_NUMBER-recall": 0.8586956521739131,
      "eval_NUMBER-tp": 158.0,
      "eval_ORDINAL-f1": 0.8205128205128205,
      "eval_ORDINAL-fn": 21.0,
      "eval_ORDINAL-fp": 14.0,
      "eval_ORDINAL-precision": 0.851063829787234,
      "eval_ORDINAL-recall": 0.7920792079207921,
      "eval_ORDINAL-tp": 80.0,
      "eval_ORGANIZATION-f1": 0.8557993730407524,
      "eval_ORGANIZATION-fn": 70.0,
      "eval_ORGANIZATION-fp": 114.0,
      "eval_ORGANIZATION-precision": 0.8272727272727273,
      "eval_ORGANIZATION-recall": 0.8863636363636364,
      "eval_ORGANIZATION-tp": 546.0,
      "eval_PENALTY-f1": 0.6857142857142857,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.75,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9667194928684627,
      "eval_PERSON-fn": 34.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9692796610169492,
      "eval_PERSON-recall": 0.964172813487882,
      "eval_PERSON-tp": 915.0,
      "eval_PRODUCT-f1": 0.5853658536585366,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 28.0,
      "eval_PRODUCT-precision": 0.46153846153846156,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8579676674364896,
      "eval_PROFESSION-fn": 110.0,
      "eval_PROFESSION-fp": 136.0,
      "eval_PROFESSION-precision": 0.8452787258248009,
      "eval_PROFESSION-recall": 0.8710433763188745,
      "eval_PROFESSION-tp": 743.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883248730964467,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8755760368663594,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 18.0,
      "eval_WORK_OF_ART-precision": 0.8407079646017699,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7694133633982108,
      "eval_macro-f1": 0.7694133633982108,
      "eval_macro-precision": 0.7749036041450075,
      "eval_macro-recall": 0.7734154551854978,
      "eval_micro-f1": 0.8433104940497655,
      "eval_micro-precision": 0.8419441944194419,
      "eval_micro-recall": 0.8446812353259888,
      "eval_precision": 0.7749036041450075,
      "eval_recall": 0.7734154551854978,
      "step": 3800
    },
    {
      "epoch": 38.48,
      "learning_rate": 1.1974431818181819e-05,
      "loss": 0.0346,
      "step": 3810
    },
    {
      "epoch": 38.59,
      "learning_rate": 1.1927083333333333e-05,
      "loss": 0.036,
      "step": 3820
    },
    {
      "epoch": 38.69,
      "learning_rate": 1.1879734848484849e-05,
      "loss": 0.0366,
      "step": 3830
    },
    {
      "epoch": 38.79,
      "learning_rate": 1.1832386363636364e-05,
      "loss": 0.0344,
      "step": 3840
    },
    {
      "epoch": 38.89,
      "learning_rate": 1.178503787878788e-05,
      "loss": 0.0346,
      "step": 3850
    },
    {
      "epoch": 38.99,
      "learning_rate": 1.1737689393939395e-05,
      "loss": 0.035,
      "step": 3860
    },
    {
      "epoch": 39.09,
      "learning_rate": 1.169034090909091e-05,
      "loss": 0.0386,
      "step": 3870
    },
    {
      "epoch": 39.19,
      "learning_rate": 1.1642992424242425e-05,
      "loss": 0.0366,
      "step": 3880
    },
    {
      "epoch": 39.29,
      "learning_rate": 1.1595643939393939e-05,
      "loss": 0.031,
      "step": 3890
    },
    {
      "epoch": 39.39,
      "learning_rate": 1.1548295454545454e-05,
      "loss": 0.0357,
      "step": 3900
    },
    {
      "epoch": 39.39,
      "eval_AGE-f1": 0.9202898550724637,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9136690647482014,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7209302325581395,
      "eval_AWARD-fn": 10.0,
      "eval_AWARD-fp": 14.0,
      "eval_AWARD-precision": 0.6888888888888889,
      "eval_AWARD-recall": 0.7560975609756098,
      "eval_AWARD-tp": 31.0,
      "eval_CITY-f1": 0.9129411764705883,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8940092165898618,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9506346967559943,
      "eval_COUNTRY-fn": 18.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9519774011299436,
      "eval_COUNTRY-recall": 0.9492957746478873,
      "eval_COUNTRY-tp": 337.0,
      "eval_CRIME-f1": 0.48,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 40.0,
      "eval_CRIME-precision": 0.42857142857142855,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8994197292069632,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9117647058823529,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.5675675675675675,
      "eval_DISEASE-fn": 49.0,
      "eval_DISEASE-fp": 47.0,
      "eval_DISEASE-precision": 0.5727272727272728,
      "eval_DISEASE-recall": 0.5625,
      "eval_DISEASE-tp": 63.0,
      "eval_DISTRICT-f1": 0.5945945945945946,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 9.0,
      "eval_DISTRICT-precision": 0.55,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6519421172886519,
      "eval_EVENT-fn": 253.0,
      "eval_EVENT-fp": 204.0,
      "eval_EVENT-precision": 0.6772151898734177,
      "eval_EVENT-recall": 0.6284875183553598,
      "eval_EVENT-tp": 428.0,
      "eval_FACILITY-f1": 0.6181818181818182,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 30.0,
      "eval_FACILITY-precision": 0.6296296296296297,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.4,
      "eval_FAMILY-fn": 4.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.5,
      "eval_FAMILY-recall": 0.3333333333333333,
      "eval_FAMILY-tp": 2.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7225806451612903,
      "eval_LAW-fn": 27.0,
      "eval_LAW-fp": 16.0,
      "eval_LAW-precision": 0.7777777777777778,
      "eval_LAW-recall": 0.6746987951807228,
      "eval_LAW-tp": 56.0,
      "eval_LOCATION-f1": 0.7563025210084033,
      "eval_LOCATION-fn": 19.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8181818181818182,
      "eval_LOCATION-recall": 0.703125,
      "eval_LOCATION-tp": 45.0,
      "eval_MONEY-f1": 0.8524590163934426,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8125,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.7967479674796748,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 16.0,
      "eval_NATIONALITY-precision": 0.7538461538461538,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.896551724137931,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 8.0,
      "eval_NUMBER-precision": 0.9512195121951219,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8350515463917526,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 12.0,
      "eval_ORDINAL-precision": 0.8709677419354839,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8621513944223107,
      "eval_ORGANIZATION-fn": 75.0,
      "eval_ORGANIZATION-fp": 98.0,
      "eval_ORGANIZATION-precision": 0.8466353677621283,
      "eval_ORGANIZATION-recall": 0.8782467532467533,
      "eval_ORGANIZATION-tp": 541.0,
      "eval_PENALTY-f1": 0.6796116504854369,
      "eval_PENALTY-fn": 22.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7608695652173914,
      "eval_PENALTY-recall": 0.6140350877192983,
      "eval_PENALTY-tp": 35.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9657353716394307,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9662447257383966,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.6153846153846154,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 24.0,
      "eval_PRODUCT-precision": 0.5,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8578034682080925,
      "eval_PROFESSION-fn": 111.0,
      "eval_PROFESSION-fp": 135.0,
      "eval_PROFESSION-precision": 0.8460661345496009,
      "eval_PROFESSION-recall": 0.8698710433763188,
      "eval_PROFESSION-tp": 742.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883248730964467,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8506787330316742,
      "eval_WORK_OF_ART-fn": 10.0,
      "eval_WORK_OF_ART-fp": 23.0,
      "eval_WORK_OF_ART-precision": 0.8034188034188035,
      "eval_WORK_OF_ART-recall": 0.9038461538461539,
      "eval_WORK_OF_ART-tp": 94.0,
      "eval_f1": 0.7629356591447263,
      "eval_macro-f1": 0.7629356591447263,
      "eval_macro-precision": 0.7726988241891898,
      "eval_macro-recall": 0.7632767843199154,
      "eval_micro-f1": 0.8428287212877554,
      "eval_micro-precision": 0.8440499909436696,
      "eval_micro-recall": 0.841610980675456,
      "eval_precision": 0.7726988241891898,
      "eval_recall": 0.7632767843199154,
      "step": 3900
    },
    {
      "epoch": 39.49,
      "learning_rate": 1.150094696969697e-05,
      "loss": 0.0322,
      "step": 3910
    },
    {
      "epoch": 39.6,
      "learning_rate": 1.1453598484848486e-05,
      "loss": 0.0358,
      "step": 3920
    },
    {
      "epoch": 39.7,
      "learning_rate": 1.140625e-05,
      "loss": 0.0359,
      "step": 3930
    },
    {
      "epoch": 39.8,
      "learning_rate": 1.1358901515151515e-05,
      "loss": 0.0351,
      "step": 3940
    },
    {
      "epoch": 39.9,
      "learning_rate": 1.131155303030303e-05,
      "loss": 0.0345,
      "step": 3950
    },
    {
      "epoch": 40.0,
      "learning_rate": 1.1264204545454546e-05,
      "loss": 0.0345,
      "step": 3960
    },
    {
      "epoch": 40.1,
      "learning_rate": 1.1216856060606062e-05,
      "loss": 0.0334,
      "step": 3970
    },
    {
      "epoch": 40.2,
      "learning_rate": 1.1169507575757576e-05,
      "loss": 0.0363,
      "step": 3980
    },
    {
      "epoch": 40.3,
      "learning_rate": 1.1122159090909091e-05,
      "loss": 0.0369,
      "step": 3990
    },
    {
      "epoch": 40.4,
      "learning_rate": 1.1074810606060607e-05,
      "loss": 0.0333,
      "step": 4000
    },
    {
      "epoch": 40.4,
      "eval_AGE-f1": 0.927007299270073,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 10.0,
      "eval_AGE-precision": 0.927007299270073,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7142857142857143,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 13.0,
      "eval_AWARD-precision": 0.6976744186046512,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9129411764705883,
      "eval_CITY-fn": 14.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8940092165898618,
      "eval_CITY-recall": 0.9326923076923077,
      "eval_CITY-tp": 194.0,
      "eval_COUNTRY-f1": 0.9504950495049505,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.9545454545454546,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.4745762711864407,
      "eval_CRIME-fn": 27.0,
      "eval_CRIME-fp": 35.0,
      "eval_CRIME-precision": 0.4444444444444444,
      "eval_CRIME-recall": 0.509090909090909,
      "eval_CRIME-tp": 28.0,
      "eval_DATE-f1": 0.9004830917874396,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9119373776908023,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5142857142857142,
      "eval_DISEASE-fn": 58.0,
      "eval_DISEASE-fp": 44.0,
      "eval_DISEASE-precision": 0.5510204081632653,
      "eval_DISEASE-recall": 0.48214285714285715,
      "eval_DISEASE-tp": 54.0,
      "eval_DISTRICT-f1": 0.6111111111111112,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 8.0,
      "eval_DISTRICT-precision": 0.5789473684210527,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6656151419558359,
      "eval_EVENT-fn": 259.0,
      "eval_EVENT-fp": 165.0,
      "eval_EVENT-precision": 0.7189097103918228,
      "eval_EVENT-recall": 0.6196769456681351,
      "eval_EVENT-tp": 422.0,
      "eval_FACILITY-f1": 0.6125,
      "eval_FACILITY-fn": 35.0,
      "eval_FACILITY-fp": 27.0,
      "eval_FACILITY-precision": 0.6447368421052632,
      "eval_FACILITY-recall": 0.5833333333333334,
      "eval_FACILITY-tp": 49.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.72,
      "eval_LAW-fn": 29.0,
      "eval_LAW-fp": 13.0,
      "eval_LAW-precision": 0.8059701492537313,
      "eval_LAW-recall": 0.6506024096385542,
      "eval_LAW-tp": 54.0,
      "eval_LOCATION-f1": 0.7666666666666667,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8214285714285714,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.8524590163934426,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 6.0,
      "eval_MONEY-precision": 0.8125,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8347826086956521,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 9.0,
      "eval_NATIONALITY-precision": 0.8421052631578947,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.899135446685879,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9570552147239264,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8210526315789474,
      "eval_ORDINAL-fn": 23.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8764044943820225,
      "eval_ORDINAL-recall": 0.7722772277227723,
      "eval_ORDINAL-tp": 78.0,
      "eval_ORGANIZATION-f1": 0.8637083993660856,
      "eval_ORGANIZATION-fn": 71.0,
      "eval_ORGANIZATION-fp": 101.0,
      "eval_ORGANIZATION-precision": 0.8436532507739938,
      "eval_ORGANIZATION-recall": 0.8847402597402597,
      "eval_ORGANIZATION-tp": 545.0,
      "eval_PENALTY-f1": 0.6923076923076923,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7659574468085106,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9651162790697675,
      "eval_PERSON-fn": 36.0,
      "eval_PERSON-fp": 30.0,
      "eval_PERSON-precision": 0.968186638388123,
      "eval_PERSON-recall": 0.9620653319283456,
      "eval_PERSON-tp": 913.0,
      "eval_PRODUCT-f1": 0.6233766233766234,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 23.0,
      "eval_PRODUCT-precision": 0.5106382978723404,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8624708624708625,
      "eval_PROFESSION-fn": 113.0,
      "eval_PROFESSION-fp": 123.0,
      "eval_PROFESSION-precision": 0.8574739281575898,
      "eval_PROFESSION-recall": 0.8675263774912075,
      "eval_PROFESSION-tp": 740.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 10.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8969072164948454,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8482142857142857,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 25.0,
      "eval_WORK_OF_ART-precision": 0.7916666666666666,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7689698507748586,
      "eval_macro-f1": 0.7689698507748586,
      "eval_macro-precision": 0.7850865544523076,
      "eval_macro-recall": 0.7620615488016004,
      "eval_micro-f1": 0.8463995619238843,
      "eval_micro-precision": 0.8555350553505535,
      "eval_micro-recall": 0.8374571067364999,
      "eval_precision": 0.7850865544523076,
      "eval_recall": 0.7620615488016004,
      "step": 4000
    },
    {
      "epoch": 40.51,
      "learning_rate": 1.1027462121212122e-05,
      "loss": 0.0376,
      "step": 4010
    },
    {
      "epoch": 40.61,
      "learning_rate": 1.0980113636363638e-05,
      "loss": 0.033,
      "step": 4020
    },
    {
      "epoch": 40.71,
      "learning_rate": 1.093276515151515e-05,
      "loss": 0.0342,
      "step": 4030
    },
    {
      "epoch": 40.81,
      "learning_rate": 1.0885416666666666e-05,
      "loss": 0.0308,
      "step": 4040
    },
    {
      "epoch": 40.91,
      "learning_rate": 1.0838068181818181e-05,
      "loss": 0.033,
      "step": 4050
    },
    {
      "epoch": 41.01,
      "learning_rate": 1.0790719696969697e-05,
      "loss": 0.0325,
      "step": 4060
    },
    {
      "epoch": 41.11,
      "learning_rate": 1.0743371212121213e-05,
      "loss": 0.032,
      "step": 4070
    },
    {
      "epoch": 41.21,
      "learning_rate": 1.0696022727272727e-05,
      "loss": 0.0325,
      "step": 4080
    },
    {
      "epoch": 41.31,
      "learning_rate": 1.0648674242424242e-05,
      "loss": 0.0345,
      "step": 4090
    },
    {
      "epoch": 41.41,
      "learning_rate": 1.0601325757575758e-05,
      "loss": 0.0344,
      "step": 4100
    },
    {
      "epoch": 41.41,
      "eval_AGE-f1": 0.9136690647482014,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.900709219858156,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7191011235955056,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 16.0,
      "eval_AWARD-precision": 0.6666666666666666,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9158878504672897,
      "eval_CITY-fn": 12.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8909090909090909,
      "eval_CITY-recall": 0.9423076923076923,
      "eval_CITY-tp": 196.0,
      "eval_COUNTRY-f1": 0.9506346967559943,
      "eval_COUNTRY-fn": 18.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9519774011299436,
      "eval_COUNTRY-recall": 0.9492957746478873,
      "eval_COUNTRY-tp": 337.0,
      "eval_CRIME-f1": 0.47540983606557374,
      "eval_CRIME-fn": 26.0,
      "eval_CRIME-fp": 38.0,
      "eval_CRIME-precision": 0.43283582089552236,
      "eval_CRIME-recall": 0.5272727272727272,
      "eval_CRIME-tp": 29.0,
      "eval_DATE-f1": 0.8987463837994214,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 47.0,
      "eval_DATE-precision": 0.9083820662768031,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5288461538461539,
      "eval_DISEASE-fn": 57.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.5729166666666666,
      "eval_DISEASE-recall": 0.49107142857142855,
      "eval_DISEASE-tp": 55.0,
      "eval_DISTRICT-f1": 0.5789473684210527,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5238095238095238,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6640986132511556,
      "eval_EVENT-fn": 250.0,
      "eval_EVENT-fp": 186.0,
      "eval_EVENT-precision": 0.6985413290113452,
      "eval_EVENT-recall": 0.6328928046989721,
      "eval_EVENT-tp": 431.0,
      "eval_FACILITY-f1": 0.6190476190476191,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6190476190476191,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7261146496815286,
      "eval_LAW-fn": 26.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.7702702702702703,
      "eval_LAW-recall": 0.6867469879518072,
      "eval_LAW-tp": 57.0,
      "eval_LOCATION-f1": 0.7666666666666667,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8214285714285714,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.8387096774193549,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 7.0,
      "eval_MONEY-precision": 0.7878787878787878,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.7903225806451613,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 17.0,
      "eval_NATIONALITY-precision": 0.7424242424242424,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.899135446685879,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9570552147239264,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.841025641025641,
      "eval_ORDINAL-fn": 19.0,
      "eval_ORDINAL-fp": 12.0,
      "eval_ORDINAL-precision": 0.8723404255319149,
      "eval_ORDINAL-recall": 0.8118811881188119,
      "eval_ORDINAL-tp": 82.0,
      "eval_ORGANIZATION-f1": 0.865506329113924,
      "eval_ORGANIZATION-fn": 69.0,
      "eval_ORGANIZATION-fp": 101.0,
      "eval_ORGANIZATION-precision": 0.8441358024691358,
      "eval_ORGANIZATION-recall": 0.887987012987013,
      "eval_ORGANIZATION-tp": 547.0,
      "eval_PENALTY-f1": 0.6857142857142857,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.75,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9662447257383966,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 31.0,
      "eval_PERSON-precision": 0.9672650475184794,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.5333333333333333,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 36.0,
      "eval_PRODUCT-precision": 0.4,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.86090440755581,
      "eval_PROFESSION-fn": 101.0,
      "eval_PROFESSION-fp": 142.0,
      "eval_PROFESSION-precision": 0.8411633109619687,
      "eval_PROFESSION-recall": 0.8815943728018757,
      "eval_PROFESSION-tp": 752.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8444444444444444,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 26.0,
      "eval_WORK_OF_ART-precision": 0.7851239669421488,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.763485457415744,
      "eval_macro-f1": 0.763485457415744,
      "eval_macro-precision": 0.7682068732410579,
      "eval_macro-recall": 0.7707070383567932,
      "eval_micro-f1": 0.8441078351816789,
      "eval_micro-precision": 0.8428159884767735,
      "eval_micro-recall": 0.8454036481849377,
      "eval_precision": 0.7682068732410579,
      "eval_recall": 0.7707070383567932,
      "step": 4100
    },
    {
      "epoch": 41.52,
      "learning_rate": 1.0553977272727273e-05,
      "loss": 0.0319,
      "step": 4110
    },
    {
      "epoch": 41.62,
      "learning_rate": 1.0506628787878789e-05,
      "loss": 0.0356,
      "step": 4120
    },
    {
      "epoch": 41.72,
      "learning_rate": 1.0459280303030303e-05,
      "loss": 0.0336,
      "step": 4130
    },
    {
      "epoch": 41.82,
      "learning_rate": 1.0411931818181818e-05,
      "loss": 0.0342,
      "step": 4140
    },
    {
      "epoch": 41.92,
      "learning_rate": 1.0364583333333334e-05,
      "loss": 0.0315,
      "step": 4150
    },
    {
      "epoch": 42.02,
      "learning_rate": 1.031723484848485e-05,
      "loss": 0.0354,
      "step": 4160
    },
    {
      "epoch": 42.12,
      "learning_rate": 1.0269886363636365e-05,
      "loss": 0.0334,
      "step": 4170
    },
    {
      "epoch": 42.22,
      "learning_rate": 1.0222537878787879e-05,
      "loss": 0.036,
      "step": 4180
    },
    {
      "epoch": 42.32,
      "learning_rate": 1.0175189393939393e-05,
      "loss": 0.0337,
      "step": 4190
    },
    {
      "epoch": 42.42,
      "learning_rate": 1.0127840909090909e-05,
      "loss": 0.0323,
      "step": 4200
    },
    {
      "epoch": 42.42,
      "eval_AGE-f1": 0.9169675090252708,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 13.0,
      "eval_AGE-precision": 0.9071428571428571,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7142857142857143,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 13.0,
      "eval_AWARD-precision": 0.6976744186046512,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.9180327868852459,
      "eval_CITY-fn": 12.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8949771689497716,
      "eval_CITY-recall": 0.9423076923076923,
      "eval_CITY-tp": 196.0,
      "eval_COUNTRY-f1": 0.9445234708392604,
      "eval_COUNTRY-fn": 23.0,
      "eval_COUNTRY-fp": 16.0,
      "eval_COUNTRY-precision": 0.9540229885057471,
      "eval_COUNTRY-recall": 0.9352112676056338,
      "eval_COUNTRY-tp": 332.0,
      "eval_CRIME-f1": 0.4918032786885246,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 37.0,
      "eval_CRIME-precision": 0.44776119402985076,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8994197292069632,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9117647058823529,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.5242718446601942,
      "eval_DISEASE-fn": 58.0,
      "eval_DISEASE-fp": 40.0,
      "eval_DISEASE-precision": 0.574468085106383,
      "eval_DISEASE-recall": 0.48214285714285715,
      "eval_DISEASE-tp": 54.0,
      "eval_DISTRICT-f1": 0.5405405405405406,
      "eval_DISTRICT-fn": 7.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5,
      "eval_DISTRICT-recall": 0.5882352941176471,
      "eval_DISTRICT-tp": 10.0,
      "eval_EVENT-f1": 0.65642683912692,
      "eval_EVENT-fn": 275.0,
      "eval_EVENT-fp": 150.0,
      "eval_EVENT-precision": 0.7302158273381295,
      "eval_EVENT-recall": 0.5961820851688693,
      "eval_EVENT-tp": 406.0,
      "eval_FACILITY-f1": 0.5988023952095808,
      "eval_FACILITY-fn": 34.0,
      "eval_FACILITY-fp": 33.0,
      "eval_FACILITY-precision": 0.6024096385542169,
      "eval_FACILITY-recall": 0.5952380952380952,
      "eval_FACILITY-tp": 50.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7320261437908496,
      "eval_LAW-fn": 27.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.8,
      "eval_LAW-recall": 0.6746987951807228,
      "eval_LAW-tp": 56.0,
      "eval_LOCATION-f1": 0.7666666666666667,
      "eval_LOCATION-fn": 18.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8214285714285714,
      "eval_LOCATION-recall": 0.71875,
      "eval_LOCATION-tp": 46.0,
      "eval_MONEY-f1": 0.8666666666666667,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8387096774193549,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8235294117647058,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.8032786885245902,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.9022988505747126,
      "eval_NUMBER-fn": 27.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9573170731707317,
      "eval_NUMBER-recall": 0.8532608695652174,
      "eval_NUMBER-tp": 157.0,
      "eval_ORDINAL-f1": 0.8393782383419689,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8804347826086957,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8598277212216131,
      "eval_ORGANIZATION-fn": 67.0,
      "eval_ORGANIZATION-fp": 112.0,
      "eval_ORGANIZATION-precision": 0.8305597579425114,
      "eval_ORGANIZATION-recall": 0.8912337662337663,
      "eval_ORGANIZATION-tp": 549.0,
      "eval_PENALTY-f1": 0.6923076923076923,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7659574468085106,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9646810753821824,
      "eval_PERSON-fn": 34.0,
      "eval_PERSON-fp": 33.0,
      "eval_PERSON-precision": 0.9651898734177216,
      "eval_PERSON-recall": 0.964172813487882,
      "eval_PERSON-tp": 915.0,
      "eval_PRODUCT-f1": 0.5609756097560976,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 29.0,
      "eval_PRODUCT-precision": 0.4423076923076923,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8601156069364162,
      "eval_PROFESSION-fn": 109.0,
      "eval_PROFESSION-fp": 133.0,
      "eval_PROFESSION-precision": 0.8483466362599772,
      "eval_PROFESSION-recall": 0.8722157092614302,
      "eval_PROFESSION-tp": 744.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883248730964467,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8796296296296297,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 17.0,
      "eval_WORK_OF_ART-precision": 0.8482142857142857,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7660760565764894,
      "eval_macro-f1": 0.7660760565764894,
      "eval_macro-precision": 0.7794574783634288,
      "eval_macro-recall": 0.7627105796512749,
      "eval_micro-f1": 0.8447521865889213,
      "eval_micro-precision": 0.8523625666482809,
      "eval_micro-recall": 0.8372765035217626,
      "eval_precision": 0.7794574783634288,
      "eval_recall": 0.7627105796512749,
      "step": 4200
    },
    {
      "epoch": 42.53,
      "learning_rate": 1.0080492424242424e-05,
      "loss": 0.0324,
      "step": 4210
    },
    {
      "epoch": 42.63,
      "learning_rate": 1.003314393939394e-05,
      "loss": 0.0325,
      "step": 4220
    },
    {
      "epoch": 42.73,
      "learning_rate": 9.985795454545455e-06,
      "loss": 0.0343,
      "step": 4230
    },
    {
      "epoch": 42.83,
      "learning_rate": 9.93844696969697e-06,
      "loss": 0.0338,
      "step": 4240
    },
    {
      "epoch": 42.93,
      "learning_rate": 9.891098484848485e-06,
      "loss": 0.0333,
      "step": 4250
    },
    {
      "epoch": 43.03,
      "learning_rate": 9.84375e-06,
      "loss": 0.032,
      "step": 4260
    },
    {
      "epoch": 43.13,
      "learning_rate": 9.796401515151516e-06,
      "loss": 0.0336,
      "step": 4270
    },
    {
      "epoch": 43.23,
      "learning_rate": 9.749053030303032e-06,
      "loss": 0.0346,
      "step": 4280
    },
    {
      "epoch": 43.33,
      "learning_rate": 9.701704545454545e-06,
      "loss": 0.0334,
      "step": 4290
    },
    {
      "epoch": 43.43,
      "learning_rate": 9.654356060606061e-06,
      "loss": 0.0289,
      "step": 4300
    },
    {
      "epoch": 43.43,
      "eval_AGE-f1": 0.9136690647482014,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 14.0,
      "eval_AGE-precision": 0.900709219858156,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7142857142857143,
      "eval_AWARD-fn": 11.0,
      "eval_AWARD-fp": 13.0,
      "eval_AWARD-precision": 0.6976744186046512,
      "eval_AWARD-recall": 0.7317073170731707,
      "eval_AWARD-tp": 30.0,
      "eval_CITY-f1": 0.92018779342723,
      "eval_CITY-fn": 12.0,
      "eval_CITY-fp": 22.0,
      "eval_CITY-precision": 0.8990825688073395,
      "eval_CITY-recall": 0.9423076923076923,
      "eval_CITY-tp": 196.0,
      "eval_COUNTRY-f1": 0.9491525423728814,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9518413597733711,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.4838709677419355,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 39.0,
      "eval_CRIME-precision": 0.43478260869565216,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8972868217054264,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9114173228346457,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.5566037735849056,
      "eval_DISEASE-fn": 53.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.59,
      "eval_DISEASE-recall": 0.5267857142857143,
      "eval_DISEASE-tp": 59.0,
      "eval_DISTRICT-f1": 0.5789473684210527,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5238095238095238,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6506584043377227,
      "eval_EVENT-fn": 261.0,
      "eval_EVENT-fp": 190.0,
      "eval_EVENT-precision": 0.6885245901639344,
      "eval_EVENT-recall": 0.6167400881057269,
      "eval_EVENT-tp": 420.0,
      "eval_FACILITY-f1": 0.6181818181818182,
      "eval_FACILITY-fn": 33.0,
      "eval_FACILITY-fp": 30.0,
      "eval_FACILITY-precision": 0.6296296296296297,
      "eval_FACILITY-recall": 0.6071428571428571,
      "eval_FACILITY-tp": 51.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7428571428571429,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 8.0,
      "eval_IDEOLOGY-precision": 0.7647058823529411,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7248322147651006,
      "eval_LAW-fn": 29.0,
      "eval_LAW-fp": 12.0,
      "eval_LAW-precision": 0.8181818181818182,
      "eval_LAW-recall": 0.6506024096385542,
      "eval_LAW-tp": 54.0,
      "eval_LOCATION-f1": 0.7768595041322314,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8245614035087719,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.8813559322033898,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8666666666666667,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8135593220338984,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.8,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.899135446685879,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9570552147239264,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8469387755102041,
      "eval_ORDINAL-fn": 18.0,
      "eval_ORDINAL-fp": 12.0,
      "eval_ORDINAL-precision": 0.8736842105263158,
      "eval_ORDINAL-recall": 0.8217821782178217,
      "eval_ORDINAL-tp": 83.0,
      "eval_ORGANIZATION-f1": 0.860015467904099,
      "eval_ORGANIZATION-fn": 60.0,
      "eval_ORGANIZATION-fp": 121.0,
      "eval_ORGANIZATION-precision": 0.8212703101920237,
      "eval_ORGANIZATION-recall": 0.9025974025974026,
      "eval_ORGANIZATION-tp": 556.0,
      "eval_PENALTY-f1": 0.6601941747572816,
      "eval_PENALTY-fn": 23.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.7391304347826086,
      "eval_PENALTY-recall": 0.5964912280701754,
      "eval_PENALTY-tp": 34.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9673340358271865,
      "eval_PERSON-fn": 31.0,
      "eval_PERSON-fp": 31.0,
      "eval_PERSON-precision": 0.9673340358271865,
      "eval_PERSON-recall": 0.9673340358271865,
      "eval_PERSON-tp": 918.0,
      "eval_PRODUCT-f1": 0.5111111111111111,
      "eval_PRODUCT-fn": 7.0,
      "eval_PRODUCT-fp": 37.0,
      "eval_PRODUCT-precision": 0.38333333333333336,
      "eval_PRODUCT-recall": 0.7666666666666667,
      "eval_PRODUCT-tp": 23.0,
      "eval_PROFESSION-f1": 0.8622478386167147,
      "eval_PROFESSION-fn": 105.0,
      "eval_PROFESSION-fp": 134.0,
      "eval_PROFESSION-precision": 0.8480725623582767,
      "eval_PROFESSION-recall": 0.876905041031653,
      "eval_PROFESSION-tp": 748.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883248730964467,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.892018779342723,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 14.0,
      "eval_WORK_OF_ART-precision": 0.8715596330275229,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7665761739778907,
      "eval_macro-f1": 0.7665761739778907,
      "eval_macro-precision": 0.77783563664146,
      "eval_macro-recall": 0.7667161267908832,
      "eval_micro-f1": 0.8441793203181489,
      "eval_micro-precision": 0.8449430070562692,
      "eval_micro-recall": 0.8434170128228282,
      "eval_precision": 0.77783563664146,
      "eval_recall": 0.7667161267908832,
      "step": 4300
    },
    {
      "epoch": 43.54,
      "learning_rate": 9.607007575757577e-06,
      "loss": 0.0333,
      "step": 4310
    },
    {
      "epoch": 43.64,
      "learning_rate": 9.55965909090909e-06,
      "loss": 0.0336,
      "step": 4320
    },
    {
      "epoch": 43.74,
      "learning_rate": 9.512310606060606e-06,
      "loss": 0.0311,
      "step": 4330
    },
    {
      "epoch": 43.84,
      "learning_rate": 9.46496212121212e-06,
      "loss": 0.0324,
      "step": 4340
    },
    {
      "epoch": 43.94,
      "learning_rate": 9.417613636363636e-06,
      "loss": 0.0309,
      "step": 4350
    },
    {
      "epoch": 44.04,
      "learning_rate": 9.370265151515151e-06,
      "loss": 0.0321,
      "step": 4360
    },
    {
      "epoch": 44.14,
      "learning_rate": 9.322916666666667e-06,
      "loss": 0.0332,
      "step": 4370
    },
    {
      "epoch": 44.24,
      "learning_rate": 9.275568181818182e-06,
      "loss": 0.0314,
      "step": 4380
    },
    {
      "epoch": 44.34,
      "learning_rate": 9.228219696969698e-06,
      "loss": 0.0316,
      "step": 4390
    },
    {
      "epoch": 44.44,
      "learning_rate": 9.180871212121212e-06,
      "loss": 0.0339,
      "step": 4400
    },
    {
      "epoch": 44.44,
      "eval_AGE-f1": 0.9163636363636364,
      "eval_AGE-fn": 11.0,
      "eval_AGE-fp": 12.0,
      "eval_AGE-precision": 0.9130434782608695,
      "eval_AGE-recall": 0.9197080291970803,
      "eval_AGE-tp": 126.0,
      "eval_AWARD-f1": 0.7441860465116279,
      "eval_AWARD-fn": 9.0,
      "eval_AWARD-fp": 13.0,
      "eval_AWARD-precision": 0.7111111111111111,
      "eval_AWARD-recall": 0.7804878048780488,
      "eval_AWARD-tp": 32.0,
      "eval_CITY-f1": 0.9154929577464789,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8944954128440367,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9491525423728814,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9518413597733711,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.46551724137931033,
      "eval_CRIME-fn": 28.0,
      "eval_CRIME-fp": 34.0,
      "eval_CRIME-precision": 0.4426229508196721,
      "eval_CRIME-recall": 0.4909090909090909,
      "eval_CRIME-tp": 27.0,
      "eval_DATE-f1": 0.8990291262135922,
      "eval_DATE-fn": 61.0,
      "eval_DATE-fp": 43.0,
      "eval_DATE-precision": 0.9150197628458498,
      "eval_DATE-recall": 0.8835877862595419,
      "eval_DATE-tp": 463.0,
      "eval_DISEASE-f1": 0.5025125628140703,
      "eval_DISEASE-fn": 62.0,
      "eval_DISEASE-fp": 37.0,
      "eval_DISEASE-precision": 0.5747126436781609,
      "eval_DISEASE-recall": 0.44642857142857145,
      "eval_DISEASE-tp": 50.0,
      "eval_DISTRICT-f1": 0.5789473684210527,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 10.0,
      "eval_DISTRICT-precision": 0.5238095238095238,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6547522339561332,
      "eval_EVENT-fn": 278.0,
      "eval_EVENT-fp": 147.0,
      "eval_EVENT-precision": 0.7327272727272728,
      "eval_EVENT-recall": 0.591776798825257,
      "eval_EVENT-tp": 403.0,
      "eval_FACILITY-f1": 0.6190476190476191,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6190476190476191,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7066666666666667,
      "eval_LAW-fn": 30.0,
      "eval_LAW-fp": 14.0,
      "eval_LAW-precision": 0.7910447761194029,
      "eval_LAW-recall": 0.6385542168674698,
      "eval_LAW-tp": 53.0,
      "eval_LOCATION-f1": 0.7627118644067796,
      "eval_LOCATION-fn": 19.0,
      "eval_LOCATION-fp": 9.0,
      "eval_LOCATION-precision": 0.8333333333333334,
      "eval_LOCATION-recall": 0.703125,
      "eval_LOCATION-tp": 45.0,
      "eval_MONEY-f1": 0.8666666666666667,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8387096774193549,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8347826086956521,
      "eval_NATIONALITY-fn": 10.0,
      "eval_NATIONALITY-fp": 9.0,
      "eval_NATIONALITY-precision": 0.8421052631578947,
      "eval_NATIONALITY-recall": 0.8275862068965517,
      "eval_NATIONALITY-tp": 48.0,
      "eval_NUMBER-f1": 0.9054441260744985,
      "eval_NUMBER-fn": 26.0,
      "eval_NUMBER-fp": 7.0,
      "eval_NUMBER-precision": 0.9575757575757575,
      "eval_NUMBER-recall": 0.8586956521739131,
      "eval_NUMBER-tp": 158.0,
      "eval_ORDINAL-f1": 0.8393782383419689,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8804347826086957,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8650355169692187,
      "eval_ORGANIZATION-fn": 68.0,
      "eval_ORGANIZATION-fp": 103.0,
      "eval_ORGANIZATION-precision": 0.8417818740399385,
      "eval_ORGANIZATION-recall": 0.8896103896103896,
      "eval_ORGANIZATION-tp": 548.0,
      "eval_PENALTY-f1": 0.66,
      "eval_PENALTY-fn": 24.0,
      "eval_PENALTY-fp": 10.0,
      "eval_PENALTY-precision": 0.7674418604651163,
      "eval_PENALTY-recall": 0.5789473684210527,
      "eval_PENALTY-tp": 33.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9672650475184794,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 29.0,
      "eval_PERSON-precision": 0.9693121693121693,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.6,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 26.0,
      "eval_PRODUCT-precision": 0.48,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8607888631090487,
      "eval_PROFESSION-fn": 111.0,
      "eval_PROFESSION-fp": 129.0,
      "eval_PROFESSION-precision": 0.851894374282434,
      "eval_PROFESSION-recall": 0.8698710433763188,
      "eval_PROFESSION-tp": 742.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 12.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.867579908675799,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 20.0,
      "eval_WORK_OF_ART-precision": 0.8260869565217391,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7668926968615644,
      "eval_macro-f1": 0.7668926968615644,
      "eval_macro-precision": 0.783836904804249,
      "eval_macro-recall": 0.7608589810797282,
      "eval_micro-f1": 0.8459286367795059,
      "eval_micro-precision": 0.8572223252364176,
      "eval_micro-recall": 0.8349286617301788,
      "eval_precision": 0.783836904804249,
      "eval_recall": 0.7608589810797282,
      "step": 4400
    },
    {
      "epoch": 44.55,
      "learning_rate": 9.133522727272728e-06,
      "loss": 0.0326,
      "step": 4410
    },
    {
      "epoch": 44.65,
      "learning_rate": 9.086174242424243e-06,
      "loss": 0.0357,
      "step": 4420
    },
    {
      "epoch": 44.75,
      "learning_rate": 9.038825757575759e-06,
      "loss": 0.0306,
      "step": 4430
    },
    {
      "epoch": 44.85,
      "learning_rate": 8.991477272727274e-06,
      "loss": 0.0317,
      "step": 4440
    },
    {
      "epoch": 44.95,
      "learning_rate": 8.944128787878788e-06,
      "loss": 0.0321,
      "step": 4450
    },
    {
      "epoch": 45.05,
      "learning_rate": 8.896780303030304e-06,
      "loss": 0.0324,
      "step": 4460
    },
    {
      "epoch": 45.15,
      "learning_rate": 8.849431818181818e-06,
      "loss": 0.0305,
      "step": 4470
    },
    {
      "epoch": 45.25,
      "learning_rate": 8.802083333333333e-06,
      "loss": 0.0304,
      "step": 4480
    },
    {
      "epoch": 45.35,
      "learning_rate": 8.754734848484849e-06,
      "loss": 0.033,
      "step": 4490
    },
    {
      "epoch": 45.45,
      "learning_rate": 8.707386363636363e-06,
      "loss": 0.0308,
      "step": 4500
    },
    {
      "epoch": 45.45,
      "eval_AGE-f1": 0.910394265232975,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 15.0,
      "eval_AGE-precision": 0.8943661971830986,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.7126436781609196,
      "eval_AWARD-fn": 10.0,
      "eval_AWARD-fp": 15.0,
      "eval_AWARD-precision": 0.6739130434782609,
      "eval_AWARD-recall": 0.7560975609756098,
      "eval_AWARD-tp": 31.0,
      "eval_CITY-f1": 0.9184149184149184,
      "eval_CITY-fn": 11.0,
      "eval_CITY-fp": 24.0,
      "eval_CITY-precision": 0.8914027149321267,
      "eval_CITY-recall": 0.9471153846153846,
      "eval_CITY-tp": 197.0,
      "eval_COUNTRY-f1": 0.9491525423728814,
      "eval_COUNTRY-fn": 19.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9518413597733711,
      "eval_COUNTRY-recall": 0.9464788732394366,
      "eval_COUNTRY-tp": 336.0,
      "eval_CRIME-f1": 0.49206349206349204,
      "eval_CRIME-fn": 24.0,
      "eval_CRIME-fp": 40.0,
      "eval_CRIME-precision": 0.43661971830985913,
      "eval_CRIME-recall": 0.5636363636363636,
      "eval_CRIME-tp": 31.0,
      "eval_DATE-f1": 0.8994197292069632,
      "eval_DATE-fn": 59.0,
      "eval_DATE-fp": 45.0,
      "eval_DATE-precision": 0.9117647058823529,
      "eval_DATE-recall": 0.8874045801526718,
      "eval_DATE-tp": 465.0,
      "eval_DISEASE-f1": 0.5358851674641149,
      "eval_DISEASE-fn": 56.0,
      "eval_DISEASE-fp": 41.0,
      "eval_DISEASE-precision": 0.5773195876288659,
      "eval_DISEASE-recall": 0.5,
      "eval_DISEASE-tp": 56.0,
      "eval_DISTRICT-f1": 0.5365853658536586,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 13.0,
      "eval_DISTRICT-precision": 0.4583333333333333,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6497622820919176,
      "eval_EVENT-fn": 271.0,
      "eval_EVENT-fp": 171.0,
      "eval_EVENT-precision": 0.7056798623063684,
      "eval_EVENT-recall": 0.6020558002936858,
      "eval_EVENT-tp": 410.0,
      "eval_FACILITY-f1": 0.6190476190476191,
      "eval_FACILITY-fn": 32.0,
      "eval_FACILITY-fp": 32.0,
      "eval_FACILITY-precision": 0.6190476190476191,
      "eval_FACILITY-recall": 0.6190476190476191,
      "eval_FACILITY-tp": 52.0,
      "eval_FAMILY-f1": 0.6666666666666666,
      "eval_FAMILY-fn": 2.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6666666666666666,
      "eval_FAMILY-recall": 0.6666666666666666,
      "eval_FAMILY-tp": 4.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7189542483660131,
      "eval_LAW-fn": 28.0,
      "eval_LAW-fp": 15.0,
      "eval_LAW-precision": 0.7857142857142857,
      "eval_LAW-recall": 0.6626506024096386,
      "eval_LAW-tp": 55.0,
      "eval_LOCATION-f1": 0.7804878048780488,
      "eval_LOCATION-fn": 16.0,
      "eval_LOCATION-fp": 11.0,
      "eval_LOCATION-precision": 0.8135593220338984,
      "eval_LOCATION-recall": 0.75,
      "eval_LOCATION-tp": 48.0,
      "eval_MONEY-f1": 0.8666666666666667,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 5.0,
      "eval_MONEY-precision": 0.8387096774193549,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8235294117647058,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 12.0,
      "eval_NATIONALITY-precision": 0.8032786885245902,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.896551724137931,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 8.0,
      "eval_NUMBER-precision": 0.9512195121951219,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8393782383419689,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 11.0,
      "eval_ORDINAL-precision": 0.8804347826086957,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.863849765258216,
      "eval_ORGANIZATION-fn": 64.0,
      "eval_ORGANIZATION-fp": 110.0,
      "eval_ORGANIZATION-precision": 0.8338368580060423,
      "eval_ORGANIZATION-recall": 0.8961038961038961,
      "eval_ORGANIZATION-tp": 552.0,
      "eval_PENALTY-f1": 0.6923076923076923,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 11.0,
      "eval_PENALTY-precision": 0.7659574468085106,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9683210137275607,
      "eval_PERSON-fn": 32.0,
      "eval_PERSON-fp": 28.0,
      "eval_PERSON-precision": 0.9703703703703703,
      "eval_PERSON-recall": 0.9662802950474183,
      "eval_PERSON-tp": 917.0,
      "eval_PRODUCT-f1": 0.5454545454545454,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 34.0,
      "eval_PRODUCT-precision": 0.41379310344827586,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8617698091382302,
      "eval_PROFESSION-fn": 108.0,
      "eval_PROFESSION-fp": 131.0,
      "eval_PROFESSION-precision": 0.8504566210045662,
      "eval_PROFESSION-recall": 0.8733880422039859,
      "eval_PROFESSION-tp": 745.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.8743718592964824,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 13.0,
      "eval_STATE_OR_PROVINCE-precision": 0.87,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8444444444444444,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 26.0,
      "eval_WORK_OF_ART-precision": 0.7851239669421488,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7689809618327722,
      "eval_macro-f1": 0.7689809618327722,
      "eval_macro-precision": 0.7739220635999928,
      "eval_macro-recall": 0.776052932762359,
      "eval_micro-f1": 0.8439735579099882,
      "eval_micro-precision": 0.8463494369778424,
      "eval_micro-recall": 0.841610980675456,
      "eval_precision": 0.7739220635999928,
      "eval_recall": 0.776052932762359,
      "step": 4500
    },
    {
      "epoch": 45.56,
      "learning_rate": 8.660037878787878e-06,
      "loss": 0.0315,
      "step": 4510
    },
    {
      "epoch": 45.66,
      "learning_rate": 8.612689393939394e-06,
      "loss": 0.0327,
      "step": 4520
    },
    {
      "epoch": 45.76,
      "learning_rate": 8.56534090909091e-06,
      "loss": 0.0312,
      "step": 4530
    },
    {
      "epoch": 45.86,
      "learning_rate": 8.517992424242425e-06,
      "loss": 0.0328,
      "step": 4540
    },
    {
      "epoch": 45.96,
      "learning_rate": 8.470643939393939e-06,
      "loss": 0.0325,
      "step": 4550
    },
    {
      "epoch": 46.06,
      "learning_rate": 8.423295454545455e-06,
      "loss": 0.0319,
      "step": 4560
    },
    {
      "epoch": 46.16,
      "learning_rate": 8.37594696969697e-06,
      "loss": 0.0304,
      "step": 4570
    },
    {
      "epoch": 46.26,
      "learning_rate": 8.328598484848486e-06,
      "loss": 0.0305,
      "step": 4580
    },
    {
      "epoch": 46.36,
      "learning_rate": 8.281250000000001e-06,
      "loss": 0.0307,
      "step": 4590
    },
    {
      "epoch": 46.46,
      "learning_rate": 8.233901515151515e-06,
      "loss": 0.0317,
      "step": 4600
    },
    {
      "epoch": 46.46,
      "eval_AGE-f1": 0.9169675090252708,
      "eval_AGE-fn": 10.0,
      "eval_AGE-fp": 13.0,
      "eval_AGE-precision": 0.9071428571428571,
      "eval_AGE-recall": 0.927007299270073,
      "eval_AGE-tp": 127.0,
      "eval_AWARD-f1": 0.6888888888888889,
      "eval_AWARD-fn": 10.0,
      "eval_AWARD-fp": 18.0,
      "eval_AWARD-precision": 0.6326530612244898,
      "eval_AWARD-recall": 0.7560975609756098,
      "eval_AWARD-tp": 31.0,
      "eval_CITY-f1": 0.9154929577464789,
      "eval_CITY-fn": 13.0,
      "eval_CITY-fp": 23.0,
      "eval_CITY-precision": 0.8944954128440367,
      "eval_CITY-recall": 0.9375,
      "eval_CITY-tp": 195.0,
      "eval_COUNTRY-f1": 0.9506346967559943,
      "eval_COUNTRY-fn": 18.0,
      "eval_COUNTRY-fp": 17.0,
      "eval_COUNTRY-precision": 0.9519774011299436,
      "eval_COUNTRY-recall": 0.9492957746478873,
      "eval_COUNTRY-tp": 337.0,
      "eval_CRIME-f1": 0.48,
      "eval_CRIME-fn": 25.0,
      "eval_CRIME-fp": 40.0,
      "eval_CRIME-precision": 0.42857142857142855,
      "eval_CRIME-recall": 0.5454545454545454,
      "eval_CRIME-tp": 30.0,
      "eval_DATE-f1": 0.8978805394990366,
      "eval_DATE-fn": 58.0,
      "eval_DATE-fp": 48.0,
      "eval_DATE-precision": 0.9066147859922179,
      "eval_DATE-recall": 0.8893129770992366,
      "eval_DATE-tp": 466.0,
      "eval_DISEASE-f1": 0.5253456221198156,
      "eval_DISEASE-fn": 55.0,
      "eval_DISEASE-fp": 48.0,
      "eval_DISEASE-precision": 0.5428571428571428,
      "eval_DISEASE-recall": 0.5089285714285714,
      "eval_DISEASE-tp": 57.0,
      "eval_DISTRICT-f1": 0.6111111111111112,
      "eval_DISTRICT-fn": 6.0,
      "eval_DISTRICT-fp": 8.0,
      "eval_DISTRICT-precision": 0.5789473684210527,
      "eval_DISTRICT-recall": 0.6470588235294118,
      "eval_DISTRICT-tp": 11.0,
      "eval_EVENT-f1": 0.6527455529775715,
      "eval_EVENT-fn": 259.0,
      "eval_EVENT-fp": 190.0,
      "eval_EVENT-precision": 0.6895424836601307,
      "eval_EVENT-recall": 0.6196769456681351,
      "eval_EVENT-tp": 422.0,
      "eval_FACILITY-f1": 0.6198830409356725,
      "eval_FACILITY-fn": 31.0,
      "eval_FACILITY-fp": 34.0,
      "eval_FACILITY-precision": 0.6091954022988506,
      "eval_FACILITY-recall": 0.6309523809523809,
      "eval_FACILITY-tp": 53.0,
      "eval_FAMILY-f1": 0.5454545454545454,
      "eval_FAMILY-fn": 3.0,
      "eval_FAMILY-fp": 2.0,
      "eval_FAMILY-precision": 0.6,
      "eval_FAMILY-recall": 0.5,
      "eval_FAMILY-tp": 3.0,
      "eval_IDEOLOGY-f1": 0.7536231884057971,
      "eval_IDEOLOGY-fn": 10.0,
      "eval_IDEOLOGY-fp": 7.0,
      "eval_IDEOLOGY-precision": 0.7878787878787878,
      "eval_IDEOLOGY-recall": 0.7222222222222222,
      "eval_IDEOLOGY-tp": 26.0,
      "eval_LANGUAGE-f1": 0.5,
      "eval_LANGUAGE-fn": 4.0,
      "eval_LANGUAGE-fp": 2.0,
      "eval_LANGUAGE-precision": 0.6,
      "eval_LANGUAGE-recall": 0.42857142857142855,
      "eval_LANGUAGE-tp": 3.0,
      "eval_LAW-f1": 0.7096774193548387,
      "eval_LAW-fn": 28.0,
      "eval_LAW-fp": 17.0,
      "eval_LAW-precision": 0.7638888888888888,
      "eval_LAW-recall": 0.6626506024096386,
      "eval_LAW-tp": 55.0,
      "eval_LOCATION-f1": 0.7768595041322314,
      "eval_LOCATION-fn": 17.0,
      "eval_LOCATION-fp": 10.0,
      "eval_LOCATION-precision": 0.8245614035087719,
      "eval_LOCATION-recall": 0.734375,
      "eval_LOCATION-tp": 47.0,
      "eval_MONEY-f1": 0.8813559322033898,
      "eval_MONEY-fn": 3.0,
      "eval_MONEY-fp": 4.0,
      "eval_MONEY-precision": 0.8666666666666667,
      "eval_MONEY-recall": 0.896551724137931,
      "eval_MONEY-tp": 26.0,
      "eval_NATIONALITY-f1": 0.8376068376068376,
      "eval_NATIONALITY-fn": 9.0,
      "eval_NATIONALITY-fp": 10.0,
      "eval_NATIONALITY-precision": 0.8305084745762712,
      "eval_NATIONALITY-recall": 0.8448275862068966,
      "eval_NATIONALITY-tp": 49.0,
      "eval_NUMBER-f1": 0.9017341040462428,
      "eval_NUMBER-fn": 28.0,
      "eval_NUMBER-fp": 6.0,
      "eval_NUMBER-precision": 0.9629629629629629,
      "eval_NUMBER-recall": 0.8478260869565217,
      "eval_NUMBER-tp": 156.0,
      "eval_ORDINAL-f1": 0.8350515463917526,
      "eval_ORDINAL-fn": 20.0,
      "eval_ORDINAL-fp": 12.0,
      "eval_ORDINAL-precision": 0.8709677419354839,
      "eval_ORDINAL-recall": 0.801980198019802,
      "eval_ORDINAL-tp": 81.0,
      "eval_ORGANIZATION-f1": 0.8665620094191523,
      "eval_ORGANIZATION-fn": 64.0,
      "eval_ORGANIZATION-fp": 106.0,
      "eval_ORGANIZATION-precision": 0.8389057750759878,
      "eval_ORGANIZATION-recall": 0.8961038961038961,
      "eval_ORGANIZATION-tp": 552.0,
      "eval_PENALTY-f1": 0.6857142857142857,
      "eval_PENALTY-fn": 21.0,
      "eval_PENALTY-fp": 12.0,
      "eval_PENALTY-precision": 0.75,
      "eval_PENALTY-recall": 0.631578947368421,
      "eval_PENALTY-tp": 36.0,
      "eval_PERCENT-f1": 0.9473684210526315,
      "eval_PERCENT-fn": 0.0,
      "eval_PERCENT-fp": 1.0,
      "eval_PERCENT-precision": 0.9,
      "eval_PERCENT-recall": 1.0,
      "eval_PERCENT-tp": 9.0,
      "eval_PERSON-f1": 0.9657353716394307,
      "eval_PERSON-fn": 33.0,
      "eval_PERSON-fp": 32.0,
      "eval_PERSON-precision": 0.9662447257383966,
      "eval_PERSON-recall": 0.9652265542676501,
      "eval_PERSON-tp": 916.0,
      "eval_PRODUCT-f1": 0.5714285714285714,
      "eval_PRODUCT-fn": 6.0,
      "eval_PRODUCT-fp": 30.0,
      "eval_PRODUCT-precision": 0.4444444444444444,
      "eval_PRODUCT-recall": 0.8,
      "eval_PRODUCT-tp": 24.0,
      "eval_PROFESSION-f1": 0.8587896253602305,
      "eval_PROFESSION-fn": 108.0,
      "eval_PROFESSION-fp": 137.0,
      "eval_PROFESSION-precision": 0.844671201814059,
      "eval_PROFESSION-recall": 0.8733880422039859,
      "eval_PROFESSION-tp": 745.0,
      "eval_RELIGION-f1": 0.8,
      "eval_RELIGION-fn": 3.0,
      "eval_RELIGION-fp": 0.0,
      "eval_RELIGION-precision": 1.0,
      "eval_RELIGION-recall": 0.6666666666666666,
      "eval_RELIGION-tp": 6.0,
      "eval_STATE_OR_PROVINCE-f1": 0.883248730964467,
      "eval_STATE_OR_PROVINCE-fn": 12.0,
      "eval_STATE_OR_PROVINCE-fp": 11.0,
      "eval_STATE_OR_PROVINCE-precision": 0.8877551020408163,
      "eval_STATE_OR_PROVINCE-recall": 0.8787878787878788,
      "eval_STATE_OR_PROVINCE-tp": 87.0,
      "eval_TIME-f1": 0.8333333333333334,
      "eval_TIME-fn": 4.0,
      "eval_TIME-fp": 6.0,
      "eval_TIME-precision": 0.8064516129032258,
      "eval_TIME-recall": 0.8620689655172413,
      "eval_TIME-tp": 25.0,
      "eval_WORK_OF_ART-f1": 0.8444444444444444,
      "eval_WORK_OF_ART-fn": 9.0,
      "eval_WORK_OF_ART-fp": 26.0,
      "eval_WORK_OF_ART-precision": 0.7851239669421488,
      "eval_WORK_OF_ART-recall": 0.9134615384615384,
      "eval_WORK_OF_ART-tp": 95.0,
      "eval_f1": 0.7674806134486905,
      "eval_macro-f1": 0.7674806134486905,
      "eval_macro-precision": 0.7749320379144504,
      "eval_macro-recall": 0.7702611109285371,
      "eval_micro-f1": 0.8431885889681322,
      "eval_micro-precision": 0.8429602888086642,
      "eval_micro-recall": 0.8434170128228282,
      "eval_precision": 0.7749320379144504,
      "eval_recall": 0.7702611109285371,
      "step": 4600
    },
    {
      "epoch": 46.46,
      "step": 4600,
      "total_flos": 1.4410703541491712e+16,
      "train_loss": 0.17724036476534347,
      "train_runtime": 4983.8518,
      "train_samples_per_second": 20.238,
      "train_steps_per_second": 1.271
    }
  ],
  "max_steps": 6336,
  "num_train_epochs": 64,
  "total_flos": 1.4410703541491712e+16,
  "trial_name": null,
  "trial_params": null
}
